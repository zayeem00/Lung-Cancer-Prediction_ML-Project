{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset1 = pd.read_excel('LUAD_clinical.xlsx',index_col=0)\n",
    "dataset2 = pd.read_excel('LUAD_flux.xlsx',index_col=0)\n",
    "dataset3 = pd.read_excel('LUAD_Genes.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis Age</th>\n",
       "      <th>Birth from Initial Pathologic Diagnosis Date</th>\n",
       "      <th>Last Alive Less Initial Pathologic Diagnosis Date Calculated Day Value</th>\n",
       "      <th>Fraction Genome Altered</th>\n",
       "      <th>Year Cancer Initial Diagnosis</th>\n",
       "      <th>Longest Dimension</th>\n",
       "      <th>Number of Samples Per Patient</th>\n",
       "      <th>Sample type id</th>\n",
       "      <th>Shortest Dimension</th>\n",
       "      <th>Specimen Second Longest Dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>Tissue Source Site_NJ</th>\n",
       "      <th>Tissue Source Site_O1</th>\n",
       "      <th>Tissue Source Site_S2</th>\n",
       "      <th>Person Neoplasm Status_TUMOR FREE</th>\n",
       "      <th>Person Neoplasm Status_WITH TUMOR</th>\n",
       "      <th>Vial number_A</th>\n",
       "      <th>Vial number_B</th>\n",
       "      <th>Patient's Vital Status_Alive</th>\n",
       "      <th>Patient's Vital Status_Dead</th>\n",
       "      <th>Overall Survival (Months)2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-05-4244-01</th>\n",
       "      <td>70.0</td>\n",
       "      <td>-25752.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456523</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-05-4249-01</th>\n",
       "      <td>67.0</td>\n",
       "      <td>-24532.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222128</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-05-4250-01</th>\n",
       "      <td>79.0</td>\n",
       "      <td>-29068.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-05-4382-01</th>\n",
       "      <td>68.0</td>\n",
       "      <td>-24868.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085449</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-05-4384-01</th>\n",
       "      <td>66.0</td>\n",
       "      <td>-24411.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066063</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 347 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Diagnosis Age  Birth from Initial Pathologic Diagnosis Date  \\\n",
       "Sample ID                                                                      \n",
       "TCGA-05-4244-01           70.0                                      -25752.0   \n",
       "TCGA-05-4249-01           67.0                                      -24532.0   \n",
       "TCGA-05-4250-01           79.0                                      -29068.0   \n",
       "TCGA-05-4382-01           68.0                                      -24868.0   \n",
       "TCGA-05-4384-01           66.0                                      -24411.0   \n",
       "\n",
       "                 Last Alive Less Initial Pathologic Diagnosis Date Calculated Day Value  \\\n",
       "Sample ID                                                                                 \n",
       "TCGA-05-4244-01                                                  0                        \n",
       "TCGA-05-4249-01                                                  0                        \n",
       "TCGA-05-4250-01                                                  0                        \n",
       "TCGA-05-4382-01                                                  0                        \n",
       "TCGA-05-4384-01                                                  0                        \n",
       "\n",
       "                 Fraction Genome Altered  Year Cancer Initial Diagnosis  \\\n",
       "Sample ID                                                                 \n",
       "TCGA-05-4244-01                 0.456523                         2009.0   \n",
       "TCGA-05-4249-01                 0.222128                         2007.0   \n",
       "TCGA-05-4250-01                 0.236200                         2007.0   \n",
       "TCGA-05-4382-01                 0.085449                         2009.0   \n",
       "TCGA-05-4384-01                 0.066063                         2009.0   \n",
       "\n",
       "                 Longest Dimension  Number of Samples Per Patient  \\\n",
       "Sample ID                                                           \n",
       "TCGA-05-4244-01                1.1                              1   \n",
       "TCGA-05-4249-01                1.4                              1   \n",
       "TCGA-05-4250-01                1.2                              1   \n",
       "TCGA-05-4382-01                0.9                              1   \n",
       "TCGA-05-4384-01                0.8                              1   \n",
       "\n",
       "                 Sample type id  Shortest Dimension  \\\n",
       "Sample ID                                             \n",
       "TCGA-05-4244-01               1                 0.3   \n",
       "TCGA-05-4249-01               1                 0.4   \n",
       "TCGA-05-4250-01               1                 0.3   \n",
       "TCGA-05-4382-01               1                 0.3   \n",
       "TCGA-05-4384-01               1                 0.4   \n",
       "\n",
       "                 Specimen Second Longest Dimension  ...  \\\n",
       "Sample ID                                           ...   \n",
       "TCGA-05-4244-01                                0.9  ...   \n",
       "TCGA-05-4249-01                                0.8  ...   \n",
       "TCGA-05-4250-01                                0.7  ...   \n",
       "TCGA-05-4382-01                                0.8  ...   \n",
       "TCGA-05-4384-01                                0.8  ...   \n",
       "\n",
       "                 Tissue Source Site_NJ  Tissue Source Site_O1  \\\n",
       "Sample ID                                                       \n",
       "TCGA-05-4244-01                      0                      0   \n",
       "TCGA-05-4249-01                      0                      0   \n",
       "TCGA-05-4250-01                      0                      0   \n",
       "TCGA-05-4382-01                      0                      0   \n",
       "TCGA-05-4384-01                      0                      0   \n",
       "\n",
       "                 Tissue Source Site_S2  Person Neoplasm Status_TUMOR FREE  \\\n",
       "Sample ID                                                                   \n",
       "TCGA-05-4244-01                      0                                  1   \n",
       "TCGA-05-4249-01                      0                                  1   \n",
       "TCGA-05-4250-01                      0                                  1   \n",
       "TCGA-05-4382-01                      0                                  1   \n",
       "TCGA-05-4384-01                      0                                  1   \n",
       "\n",
       "                 Person Neoplasm Status_WITH TUMOR  Vial number_A  \\\n",
       "Sample ID                                                           \n",
       "TCGA-05-4244-01                                  0              1   \n",
       "TCGA-05-4249-01                                  0              1   \n",
       "TCGA-05-4250-01                                  0              1   \n",
       "TCGA-05-4382-01                                  0              1   \n",
       "TCGA-05-4384-01                                  0              1   \n",
       "\n",
       "                 Vial number_B  Patient's Vital Status_Alive  \\\n",
       "Sample ID                                                      \n",
       "TCGA-05-4244-01              0                             1   \n",
       "TCGA-05-4249-01              0                             1   \n",
       "TCGA-05-4250-01              0                             0   \n",
       "TCGA-05-4382-01              0                             1   \n",
       "TCGA-05-4384-01              0                             1   \n",
       "\n",
       "                 Patient's Vital Status_Dead  Overall Survival (Months)2  \n",
       "Sample ID                                                                 \n",
       "TCGA-05-4244-01                            0                        0.00  \n",
       "TCGA-05-4249-01                            0                       50.03  \n",
       "TCGA-05-4250-01                            1                        3.98  \n",
       "TCGA-05-4382-01                            0                       19.94  \n",
       "TCGA-05-4384-01                            0                       13.99  \n",
       "\n",
       "[5 rows x 347 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset1['Overall Survival (Months)2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset2['Overall Survival (Months)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genes_flux = dataset1.merge(dataset2,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genes_Flux_Clinical = Genes_flux.merge(dataset3,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=Genes_Flux_Clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis Age</th>\n",
       "      <th>Birth from Initial Pathologic Diagnosis Date</th>\n",
       "      <th>Last Alive Less Initial Pathologic Diagnosis Date Calculated Day Value</th>\n",
       "      <th>Fraction Genome Altered</th>\n",
       "      <th>Year Cancer Initial Diagnosis</th>\n",
       "      <th>Longest Dimension</th>\n",
       "      <th>Number of Samples Per Patient</th>\n",
       "      <th>Sample type id</th>\n",
       "      <th>Shortest Dimension</th>\n",
       "      <th>Specimen Second Longest Dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>SLTM</th>\n",
       "      <th>SLU7</th>\n",
       "      <th>SLURP1</th>\n",
       "      <th>SMAD2</th>\n",
       "      <th>SMAD3</th>\n",
       "      <th>SMAD4</th>\n",
       "      <th>SMAD5</th>\n",
       "      <th>SMAD6</th>\n",
       "      <th>SMAD7</th>\n",
       "      <th>Survival</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-05-4244-01</th>\n",
       "      <td>70.0</td>\n",
       "      <td>-25752.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456523</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1877</td>\n",
       "      <td>3.4584</td>\n",
       "      <td>-0.2752</td>\n",
       "      <td>-0.7736</td>\n",
       "      <td>-0.6896</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>-0.6433</td>\n",
       "      <td>0.7445</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-05-4249-01</th>\n",
       "      <td>67.0</td>\n",
       "      <td>-24532.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.222128</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5540</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>-0.2752</td>\n",
       "      <td>-0.6214</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>1.3829</td>\n",
       "      <td>2.3203</td>\n",
       "      <td>-0.4918</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>50.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-05-4250-01</th>\n",
       "      <td>79.0</td>\n",
       "      <td>-29068.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.3805</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>-0.2752</td>\n",
       "      <td>-1.3034</td>\n",
       "      <td>1.0473</td>\n",
       "      <td>-0.3628</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>-0.8961</td>\n",
       "      <td>-1.1245</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-05-4382-01</th>\n",
       "      <td>68.0</td>\n",
       "      <td>-24868.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085449</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3885</td>\n",
       "      <td>-1.5611</td>\n",
       "      <td>-0.2752</td>\n",
       "      <td>0.3948</td>\n",
       "      <td>-0.6485</td>\n",
       "      <td>0.5367</td>\n",
       "      <td>-0.9418</td>\n",
       "      <td>-0.1446</td>\n",
       "      <td>2.2863</td>\n",
       "      <td>19.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-05-4384-01</th>\n",
       "      <td>66.0</td>\n",
       "      <td>-24411.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066063</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>-0.2752</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>-0.4482</td>\n",
       "      <td>0.5020</td>\n",
       "      <td>0.5863</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>-0.3951</td>\n",
       "      <td>13.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 17114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Diagnosis Age  Birth from Initial Pathologic Diagnosis Date  \\\n",
       "Sample ID                                                                      \n",
       "TCGA-05-4244-01           70.0                                      -25752.0   \n",
       "TCGA-05-4249-01           67.0                                      -24532.0   \n",
       "TCGA-05-4250-01           79.0                                      -29068.0   \n",
       "TCGA-05-4382-01           68.0                                      -24868.0   \n",
       "TCGA-05-4384-01           66.0                                      -24411.0   \n",
       "\n",
       "                 Last Alive Less Initial Pathologic Diagnosis Date Calculated Day Value  \\\n",
       "Sample ID                                                                                 \n",
       "TCGA-05-4244-01                                                  0                        \n",
       "TCGA-05-4249-01                                                  0                        \n",
       "TCGA-05-4250-01                                                  0                        \n",
       "TCGA-05-4382-01                                                  0                        \n",
       "TCGA-05-4384-01                                                  0                        \n",
       "\n",
       "                 Fraction Genome Altered  Year Cancer Initial Diagnosis  \\\n",
       "Sample ID                                                                 \n",
       "TCGA-05-4244-01                 0.456523                         2009.0   \n",
       "TCGA-05-4249-01                 0.222128                         2007.0   \n",
       "TCGA-05-4250-01                 0.236200                         2007.0   \n",
       "TCGA-05-4382-01                 0.085449                         2009.0   \n",
       "TCGA-05-4384-01                 0.066063                         2009.0   \n",
       "\n",
       "                 Longest Dimension  Number of Samples Per Patient  \\\n",
       "Sample ID                                                           \n",
       "TCGA-05-4244-01                1.1                              1   \n",
       "TCGA-05-4249-01                1.4                              1   \n",
       "TCGA-05-4250-01                1.2                              1   \n",
       "TCGA-05-4382-01                0.9                              1   \n",
       "TCGA-05-4384-01                0.8                              1   \n",
       "\n",
       "                 Sample type id  Shortest Dimension  \\\n",
       "Sample ID                                             \n",
       "TCGA-05-4244-01               1                 0.3   \n",
       "TCGA-05-4249-01               1                 0.4   \n",
       "TCGA-05-4250-01               1                 0.3   \n",
       "TCGA-05-4382-01               1                 0.3   \n",
       "TCGA-05-4384-01               1                 0.4   \n",
       "\n",
       "                 Specimen Second Longest Dimension  ...    SLTM    SLU7  \\\n",
       "Sample ID                                           ...                   \n",
       "TCGA-05-4244-01                                0.9  ... -1.1877  3.4584   \n",
       "TCGA-05-4249-01                                0.8  ... -0.5540  0.7962   \n",
       "TCGA-05-4250-01                                0.7  ... -1.3805  0.0730   \n",
       "TCGA-05-4382-01                                0.8  ... -0.3885 -1.5611   \n",
       "TCGA-05-4384-01                                0.8  ...  0.4227  0.7651   \n",
       "\n",
       "                 SLURP1   SMAD2   SMAD3   SMAD4   SMAD5   SMAD6   SMAD7  \\\n",
       "Sample ID                                                                 \n",
       "TCGA-05-4244-01 -0.2752 -0.7736 -0.6896 -0.0017  0.1779 -0.6433  0.7445   \n",
       "TCGA-05-4249-01 -0.2752 -0.6214  0.0881  1.3829  2.3203 -0.4918  0.0368   \n",
       "TCGA-05-4250-01 -0.2752 -1.3034  1.0473 -0.3628  0.0526 -0.8961 -1.1245   \n",
       "TCGA-05-4382-01 -0.2752  0.3948 -0.6485  0.5367 -0.9418 -0.1446  2.2863   \n",
       "TCGA-05-4384-01 -0.2752  0.2285 -0.4482  0.5020  0.5863  0.3185 -0.3951   \n",
       "\n",
       "                 Survival   \n",
       "Sample ID                   \n",
       "TCGA-05-4244-01       0.00  \n",
       "TCGA-05-4249-01      50.03  \n",
       "TCGA-05-4250-01       3.98  \n",
       "TCGA-05-4382-01      19.94  \n",
       "TCGA-05-4384-01      13.99  \n",
       "\n",
       "[5 rows x 17114 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dt['Patient\\'s Vital Status_Dead']\n",
    "del dt['Patient\\'s Vital Status_Alive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 17112)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.iloc[:,0:17111].values\n",
    "y = dt.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "X_val = sc_X.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_y = StandardScaler()\n",
    "y_train = np.squeeze(sc_y.fit_transform(y_train.reshape(-1, 1)))\n",
    "y_val = np.squeeze(sc_y.transform(y_val.reshape(-1, 1)))\n",
    "y_test = np.squeeze(sc_y.transform(y_test.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    " #create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # The Input Layer:\n",
    "    model.add(Dense(128, kernel_initializer='normal', input_dim = X_train.shape[1], activation='relu'))\n",
    "    \n",
    "    # The Hidden Layers:\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "    \n",
    "    # The Output Layer:\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=baseline_model, batch_size=15, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 1.3824 - mean_absolute_error: 0.8162\n",
      "Epoch 2/10\n",
      "297/297 [==============================] - 0s 743us/sample - loss: 1.0325 - mean_absolute_error: 0.7199\n",
      "Epoch 3/10\n",
      "297/297 [==============================] - 0s 719us/sample - loss: 0.5135 - mean_absolute_error: 0.5192\n",
      "Epoch 4/10\n",
      "297/297 [==============================] - 0s 773us/sample - loss: 0.9223 - mean_absolute_error: 0.4441\n",
      "Epoch 5/10\n",
      "297/297 [==============================] - 0s 832us/sample - loss: 0.4057 - mean_absolute_error: 0.3681\n",
      "Epoch 6/10\n",
      "297/297 [==============================] - 0s 780us/sample - loss: 0.1487 - mean_absolute_error: 0.2569\n",
      "Epoch 7/10\n",
      "297/297 [==============================] - 0s 732us/sample - loss: 0.2767 - mean_absolute_error: 0.2771\n",
      "Epoch 8/10\n",
      "297/297 [==============================] - 0s 743us/sample - loss: 0.2367 - mean_absolute_error: 0.2863\n",
      "Epoch 9/10\n",
      "297/297 [==============================] - 0s 714us/sample - loss: 0.3181 - mean_absolute_error: 0.2733\n",
      "Epoch 10/10\n",
      "297/297 [==============================] - 0s 731us/sample - loss: 0.1140 - mean_absolute_error: 0.2034\n",
      "33/33 [==============================] - 0s 2ms/sample - loss: 0.5510 - mean_absolute_error: 0.5317\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 1.3156 - mean_absolute_error: 0.7822\n",
      "Epoch 2/10\n",
      "297/297 [==============================] - 0s 790us/sample - loss: 0.8291 - mean_absolute_error: 0.5966\n",
      "Epoch 3/10\n",
      "297/297 [==============================] - 0s 784us/sample - loss: 0.6284 - mean_absolute_error: 0.5450\n",
      "Epoch 4/10\n",
      "297/297 [==============================] - 0s 773us/sample - loss: 0.8014 - mean_absolute_error: 0.4739\n",
      "Epoch 5/10\n",
      "297/297 [==============================] - 0s 781us/sample - loss: 0.3396 - mean_absolute_error: 0.3145\n",
      "Epoch 6/10\n",
      "297/297 [==============================] - 0s 844us/sample - loss: 0.2515 - mean_absolute_error: 0.2713\n",
      "Epoch 7/10\n",
      "297/297 [==============================] - 0s 819us/sample - loss: 0.2652 - mean_absolute_error: 0.2699\n",
      "Epoch 8/10\n",
      "297/297 [==============================] - 0s 791us/sample - loss: 0.2599 - mean_absolute_error: 0.2199\n",
      "Epoch 9/10\n",
      "297/297 [==============================] - 0s 781us/sample - loss: 0.1908 - mean_absolute_error: 0.2434\n",
      "Epoch 10/10\n",
      "297/297 [==============================] - 0s 815us/sample - loss: 0.1777 - mean_absolute_error: 0.2473\n",
      "33/33 [==============================] - 0s 2ms/sample - loss: 1.1673 - mean_absolute_error: 0.7281\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 1.3253 - mean_absolute_error: 0.8392\n",
      "Epoch 2/10\n",
      "297/297 [==============================] - 0s 818us/sample - loss: 0.8676 - mean_absolute_error: 0.6581\n",
      "Epoch 3/10\n",
      "297/297 [==============================] - 0s 745us/sample - loss: 0.5447 - mean_absolute_error: 0.5058\n",
      "Epoch 4/10\n",
      "297/297 [==============================] - 0s 726us/sample - loss: 1.1624 - mean_absolute_error: 0.4879\n",
      "Epoch 5/10\n",
      "297/297 [==============================] - 0s 752us/sample - loss: 0.4590 - mean_absolute_error: 0.4028\n",
      "Epoch 6/10\n",
      "297/297 [==============================] - 0s 783us/sample - loss: 0.2708 - mean_absolute_error: 0.3514\n",
      "Epoch 7/10\n",
      "297/297 [==============================] - 0s 820us/sample - loss: 0.2569 - mean_absolute_error: 0.2998\n",
      "Epoch 8/10\n",
      "297/297 [==============================] - 0s 718us/sample - loss: 0.2327 - mean_absolute_error: 0.2026\n",
      "Epoch 9/10\n",
      "297/297 [==============================] - 0s 706us/sample - loss: 0.1938 - mean_absolute_error: 0.1751\n",
      "Epoch 10/10\n",
      "297/297 [==============================] - 0s 786us/sample - loss: 0.0878 - mean_absolute_error: 0.1859\n",
      "33/33 [==============================] - 0s 2ms/sample - loss: 1.3849 - mean_absolute_error: 0.7687\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 1.4488 - mean_absolute_error: 0.8166\n",
      "Epoch 2/10\n",
      "297/297 [==============================] - 0s 757us/sample - loss: 1.0111 - mean_absolute_error: 0.6864\n",
      "Epoch 3/10\n",
      "297/297 [==============================] - 0s 787us/sample - loss: 0.9610 - mean_absolute_error: 0.6157\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 0s 793us/sample - loss: 0.5874 - mean_absolute_error: 0.5487\n",
      "Epoch 5/10\n",
      "297/297 [==============================] - 0s 804us/sample - loss: 0.4453 - mean_absolute_error: 0.3987\n",
      "Epoch 6/10\n",
      "297/297 [==============================] - 0s 724us/sample - loss: 0.2926 - mean_absolute_error: 0.3561\n",
      "Epoch 7/10\n",
      "297/297 [==============================] - 0s 697us/sample - loss: 0.3697 - mean_absolute_error: 0.3442\n",
      "Epoch 8/10\n",
      "297/297 [==============================] - 0s 718us/sample - loss: 0.3090 - mean_absolute_error: 0.2736\n",
      "Epoch 9/10\n",
      "297/297 [==============================] - 0s 800us/sample - loss: 0.0801 - mean_absolute_error: 0.1885\n",
      "Epoch 10/10\n",
      "297/297 [==============================] - 0s 706us/sample - loss: 0.1310 - mean_absolute_error: 0.1634\n",
      "33/33 [==============================] - 0s 1ms/sample - loss: 1.0877 - mean_absolute_error: 0.7718\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 1.2314 - mean_absolute_error: 0.8117\n",
      "Epoch 2/10\n",
      "297/297 [==============================] - 0s 706us/sample - loss: 0.8054 - mean_absolute_error: 0.6353\n",
      "Epoch 3/10\n",
      "297/297 [==============================] - 0s 715us/sample - loss: 0.4230 - mean_absolute_error: 0.4616\n",
      "Epoch 4/10\n",
      "297/297 [==============================] - 0s 717us/sample - loss: 0.3779 - mean_absolute_error: 0.3660\n",
      "Epoch 5/10\n",
      "297/297 [==============================] - 0s 715us/sample - loss: 0.2627 - mean_absolute_error: 0.3271\n",
      "Epoch 6/10\n",
      "297/297 [==============================] - 0s 707us/sample - loss: 0.2047 - mean_absolute_error: 0.2994\n",
      "Epoch 7/10\n",
      "297/297 [==============================] - 0s 704us/sample - loss: 0.1912 - mean_absolute_error: 0.2643\n",
      "Epoch 8/10\n",
      "297/297 [==============================] - 0s 701us/sample - loss: 0.1292 - mean_absolute_error: 0.2297\n",
      "Epoch 9/10\n",
      "297/297 [==============================] - 0s 709us/sample - loss: 0.0713 - mean_absolute_error: 0.1643\n",
      "Epoch 10/10\n",
      "297/297 [==============================] - 0s 707us/sample - loss: 0.0666 - mean_absolute_error: 0.1269\n",
      "33/33 [==============================] - 0s 2ms/sample - loss: 2.3635 - mean_absolute_error: 0.7685\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 1.4694 - mean_absolute_error: 0.8641\n",
      "Epoch 2/10\n",
      "297/297 [==============================] - 0s 726us/sample - loss: 0.8722 - mean_absolute_error: 0.6808\n",
      "Epoch 3/10\n",
      "297/297 [==============================] - 0s 727us/sample - loss: 0.5714 - mean_absolute_error: 0.5336\n",
      "Epoch 4/10\n",
      "297/297 [==============================] - 0s 729us/sample - loss: 0.3520 - mean_absolute_error: 0.3921\n",
      "Epoch 5/10\n",
      "297/297 [==============================] - 0s 737us/sample - loss: 0.4251 - mean_absolute_error: 0.4276\n",
      "Epoch 6/10\n",
      "297/297 [==============================] - 0s 723us/sample - loss: 0.3742 - mean_absolute_error: 0.3276\n",
      "Epoch 7/10\n",
      "297/297 [==============================] - 0s 725us/sample - loss: 0.2064 - mean_absolute_error: 0.3106\n",
      "Epoch 8/10\n",
      "297/297 [==============================] - 0s 721us/sample - loss: 0.1325 - mean_absolute_error: 0.2408\n",
      "Epoch 9/10\n",
      "297/297 [==============================] - 0s 759us/sample - loss: 0.3283 - mean_absolute_error: 0.3015\n",
      "Epoch 10/10\n",
      "297/297 [==============================] - 0s 760us/sample - loss: 0.0751 - mean_absolute_error: 0.1895\n",
      "33/33 [==============================] - 0s 2ms/sample - loss: 0.8888 - mean_absolute_error: 0.7089\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 1.1430 - mean_absolute_error: 0.7631\n",
      "Epoch 2/10\n",
      "297/297 [==============================] - 0s 726us/sample - loss: 0.8098 - mean_absolute_error: 0.6122\n",
      "Epoch 3/10\n",
      "297/297 [==============================] - 0s 714us/sample - loss: 0.4618 - mean_absolute_error: 0.5069\n",
      "Epoch 4/10\n",
      "297/297 [==============================] - 0s 710us/sample - loss: 0.4561 - mean_absolute_error: 0.4284\n",
      "Epoch 5/10\n",
      "297/297 [==============================] - 0s 729us/sample - loss: 0.3609 - mean_absolute_error: 0.3247\n",
      "Epoch 6/10\n",
      "297/297 [==============================] - 0s 714us/sample - loss: 0.2944 - mean_absolute_error: 0.3142\n",
      "Epoch 7/10\n",
      "297/297 [==============================] - 0s 729us/sample - loss: 0.1493 - mean_absolute_error: 0.2652\n",
      "Epoch 8/10\n",
      "297/297 [==============================] - 0s 740us/sample - loss: 0.3880 - mean_absolute_error: 0.2796\n",
      "Epoch 9/10\n",
      "297/297 [==============================] - 0s 708us/sample - loss: 0.2353 - mean_absolute_error: 0.2679\n",
      "Epoch 10/10\n",
      "297/297 [==============================] - 0s 738us/sample - loss: 0.1999 - mean_absolute_error: 0.3010\n",
      "33/33 [==============================] - 0s 2ms/sample - loss: 1.7680 - mean_absolute_error: 0.7620\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 1.2976 - mean_absolute_error: 0.7826\n",
      "Epoch 2/10\n",
      "297/297 [==============================] - 0s 709us/sample - loss: 0.9793 - mean_absolute_error: 0.7001\n",
      "Epoch 3/10\n",
      "297/297 [==============================] - 0s 710us/sample - loss: 0.7532 - mean_absolute_error: 0.5802\n",
      "Epoch 4/10\n",
      "297/297 [==============================] - 0s 707us/sample - loss: 0.3572 - mean_absolute_error: 0.4368\n",
      "Epoch 5/10\n",
      "297/297 [==============================] - 0s 708us/sample - loss: 0.4956 - mean_absolute_error: 0.4547\n",
      "Epoch 6/10\n",
      "297/297 [==============================] - 0s 697us/sample - loss: 0.3165 - mean_absolute_error: 0.4208\n",
      "Epoch 7/10\n",
      "297/297 [==============================] - 0s 721us/sample - loss: 0.4907 - mean_absolute_error: 0.4107\n",
      "Epoch 8/10\n",
      "297/297 [==============================] - 0s 714us/sample - loss: 0.3028 - mean_absolute_error: 0.3318\n",
      "Epoch 9/10\n",
      "297/297 [==============================] - 0s 698us/sample - loss: 0.3130 - mean_absolute_error: 0.2279\n",
      "Epoch 10/10\n",
      "297/297 [==============================] - 0s 707us/sample - loss: 0.0997 - mean_absolute_error: 0.2037\n",
      "33/33 [==============================] - 0s 2ms/sample - loss: 0.7263 - mean_absolute_error: 0.6031\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 1.2921 - mean_absolute_error: 0.8040\n",
      "Epoch 2/10\n",
      "297/297 [==============================] - 0s 706us/sample - loss: 1.1445 - mean_absolute_error: 0.7966\n",
      "Epoch 3/10\n",
      "297/297 [==============================] - 0s 706us/sample - loss: 0.7279 - mean_absolute_error: 0.5845\n",
      "Epoch 4/10\n",
      "297/297 [==============================] - 0s 703us/sample - loss: 0.3949 - mean_absolute_error: 0.4320\n",
      "Epoch 5/10\n",
      "297/297 [==============================] - 0s 710us/sample - loss: 0.4567 - mean_absolute_error: 0.3822\n",
      "Epoch 6/10\n",
      "297/297 [==============================] - 0s 703us/sample - loss: 0.2153 - mean_absolute_error: 0.3022\n",
      "Epoch 7/10\n",
      "297/297 [==============================] - 0s 708us/sample - loss: 0.2799 - mean_absolute_error: 0.2740\n",
      "Epoch 8/10\n",
      "297/297 [==============================] - 0s 707us/sample - loss: 0.3443 - mean_absolute_error: 0.2565\n",
      "Epoch 9/10\n",
      "297/297 [==============================] - 0s 703us/sample - loss: 0.1547 - mean_absolute_error: 0.2073\n",
      "Epoch 10/10\n",
      "297/297 [==============================] - 0s 699us/sample - loss: 0.4119 - mean_absolute_error: 0.2540\n",
      "33/33 [==============================] - 0s 2ms/sample - loss: 0.8384 - mean_absolute_error: 0.7081\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "297/297 [==============================] - 0s 1ms/sample - loss: 1.4966 - mean_absolute_error: 0.8665\n",
      "Epoch 2/10\n",
      "297/297 [==============================] - 0s 687us/sample - loss: 1.1149 - mean_absolute_error: 0.7525\n",
      "Epoch 3/10\n",
      "297/297 [==============================] - 0s 718us/sample - loss: 0.7781 - mean_absolute_error: 0.6250\n",
      "Epoch 4/10\n",
      "297/297 [==============================] - 0s 709us/sample - loss: 0.6127 - mean_absolute_error: 0.4773\n",
      "Epoch 5/10\n",
      "297/297 [==============================] - 0s 709us/sample - loss: 0.4032 - mean_absolute_error: 0.3697\n",
      "Epoch 6/10\n",
      "297/297 [==============================] - 0s 707us/sample - loss: 0.2980 - mean_absolute_error: 0.2942\n",
      "Epoch 7/10\n",
      "297/297 [==============================] - 0s 716us/sample - loss: 0.1584 - mean_absolute_error: 0.2319\n",
      "Epoch 8/10\n",
      "297/297 [==============================] - 0s 712us/sample - loss: 0.3094 - mean_absolute_error: 0.2399\n",
      "Epoch 9/10\n",
      "297/297 [==============================] - 0s 704us/sample - loss: 0.2658 - mean_absolute_error: 0.2332\n",
      "Epoch 10/10\n",
      "297/297 [==============================] - 0s 716us/sample - loss: 0.1356 - mean_absolute_error: 0.2351\n",
      "33/33 [==============================] - 0s 2ms/sample - loss: 0.2731 - mean_absolute_error: 0.3582\n",
      "Results: -1.10 (0.58) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold =KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "330/330 [==============================] - 0s 1ms/sample - loss: 1.3770 - mean_absolute_error: 0.8013\n",
      "Epoch 2/10\n",
      "330/330 [==============================] - 0s 768us/sample - loss: 1.0430 - mean_absolute_error: 0.6993\n",
      "Epoch 3/10\n",
      "330/330 [==============================] - 0s 810us/sample - loss: 0.6007 - mean_absolute_error: 0.5587\n",
      "Epoch 4/10\n",
      "330/330 [==============================] - 0s 773us/sample - loss: 0.3973 - mean_absolute_error: 0.4400\n",
      "Epoch 5/10\n",
      "330/330 [==============================] - 0s 777us/sample - loss: 0.3542 - mean_absolute_error: 0.3248\n",
      "Epoch 6/10\n",
      "330/330 [==============================] - 0s 767us/sample - loss: 0.2866 - mean_absolute_error: 0.3108\n",
      "Epoch 7/10\n",
      "330/330 [==============================] - 0s 733us/sample - loss: 0.1568 - mean_absolute_error: 0.2290\n",
      "Epoch 8/10\n",
      "330/330 [==============================] - 0s 738us/sample - loss: 0.0937 - mean_absolute_error: 0.1980\n",
      "Epoch 9/10\n",
      "330/330 [==============================] - 0s 772us/sample - loss: 0.2106 - mean_absolute_error: 0.1937\n",
      "Epoch 10/10\n",
      "330/330 [==============================] - 0s 734us/sample - loss: 0.0536 - mean_absolute_error: 0.1555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4abed7f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 326us/sample\n"
     ]
    }
   ],
   "source": [
    "y_predval = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30804846209246.645\n",
      "2.259127687389036e+28\n",
      "150303948297742.2\n",
      "R2 Score\n",
      "-3.242777451906352e+28\n"
     ]
    }
   ],
   "source": [
    "# Print result of MAE\n",
    "from sklearn import metrics\n",
    "print(metrics.mean_absolute_error(y_val, y_predval))\n",
    "\n",
    "# Print result of MSE\n",
    "print(metrics.mean_squared_error(y_val, y_predval))\n",
    "\n",
    "# Print result of RMSE\n",
    "print(np.sqrt(metrics.mean_squared_error(y_val, y_predval)))\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "accuracy=r2_score(y_val,y_predval)\n",
    "\n",
    "print('R2 Score')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 = -32427774519063518305725710336.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the Decision Tree Regression Results\n",
    "# Loading Packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "from scipy.integrate import simps\n",
    "\n",
    "# Function for Regression Error Characteritic Curve\n",
    "\n",
    "def REC(y_val , y_predval):\n",
    "    \n",
    "    # initilizing the lists\n",
    "    Accuracy = []\n",
    "    \n",
    "    # initializing the values for Epsilon\n",
    "    Begin_Range = 0\n",
    "    End_Range = 1.5\n",
    "    Interval_Size = 0.01\n",
    "    \n",
    "    # List of epsilons\n",
    "    Epsilon = np.arange(Begin_Range , End_Range , Interval_Size)\n",
    "    \n",
    "    # Main Loops\n",
    "    for i in range(len(Epsilon)):\n",
    "        count = 0.0\n",
    "        for j in range(len(y_val)):\n",
    "            if np.linalg.norm(y_val[j] - y_predval[j]) / np.sqrt( np.linalg.norm(y_val[j]) **2 + np.linalg.norm(y_predval[j])**2 ) < Epsilon[i]:\n",
    "                count = count + 1\n",
    "        \n",
    "        Accuracy.append(count/len(y_val))\n",
    "    \n",
    "    # Calculating Area Under Curve using Simpson's rule\n",
    "    AUC = simps(Accuracy , Epsilon ) / End_Range\n",
    "        \n",
    "    # returning epsilon , accuracy , area under curve    \n",
    "    return Epsilon , Accuracy , AUC\n",
    "\n",
    "# finding the deviation and accuracy, and area under curve for plotting\n",
    "Deviation, Accuracy, AUC = REC(y_val, y_predval)\n",
    "\n",
    "# Calculating R^2 of the true and predicted values\n",
    "RR = r2_score(y_val, y_predval)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(20 , 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_val, y_predval,color = \"darkorange\")\n",
    "plt.xlabel(\"Real Data\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.figure(figsize=(20 , 10))\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'k--', lw=4)\n",
    "print(\"R^2 = %0.4f\" %RR)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Regression Error Characteristic (REC)\")\n",
    "plt.plot(Deviation, Accuracy, \"--b\",lw =3)\n",
    "plt.xlabel(\"Deviation\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.text(1.1, 0.07, \"AUC = %0.4f\" %AUC , fontsize=15)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search paramerters\n",
    "batch_size = [5, 10, 15, 20,25,30,50]\n",
    "epochs = [10, 30,50,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zayeem/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 1s 3ms/sample - loss: 1.4293 - mean_absolute_error: 0.7967\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.1261 - mean_absolute_error: 0.6796\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.6990 - mean_absolute_error: 0.5707\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4131 - mean_absolute_error: 0.4536\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5430 - mean_absolute_error: 0.4233\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3021 - mean_absolute_error: 0.3151\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3714 - mean_absolute_error: 0.2989\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 1.1402 - mean_absolute_error: 0.3928\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.6833 - mean_absolute_error: 0.3855\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.3543 - mean_absolute_error: 0.3150\n",
      "110/110 [==============================] - 0s 755us/sample - loss: 1.2824 - mean_absolute_error: 0.8073\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 1.1535 - mean_absolute_error: 0.4303\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 1s 3ms/sample - loss: 1.4437 - mean_absolute_error: 0.9250\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.7244 - mean_absolute_error: 0.5965\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.6205 - mean_absolute_error: 0.5477\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3837 - mean_absolute_error: 0.4181\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2946 - mean_absolute_error: 0.3863\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3265 - mean_absolute_error: 0.3521\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1615 - mean_absolute_error: 0.2687\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1906 - mean_absolute_error: 0.2645\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1693 - mean_absolute_error: 0.2128\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1201 - mean_absolute_error: 0.1955\n",
      "110/110 [==============================] - 0s 800us/sample - loss: 1.6220 - mean_absolute_error: 0.7749\n",
      "220/220 [==============================] - 0s 450us/sample - loss: 0.0631 - mean_absolute_error: 0.1474\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 1s 3ms/sample - loss: 1.7249 - mean_absolute_error: 0.9653\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.3169 - mean_absolute_error: 0.7652\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.8900 - mean_absolute_error: 0.6347\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.8438 - mean_absolute_error: 0.5585\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.6856 - mean_absolute_error: 0.5176\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5079 - mean_absolute_error: 0.3864\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1461 - mean_absolute_error: 0.2614\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.1392 - mean_absolute_error: 0.3958\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5000 - mean_absolute_error: 0.3503\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3071 - mean_absolute_error: 0.2870\n",
      "110/110 [==============================] - 0s 798us/sample - loss: 0.8206 - mean_absolute_error: 0.6050\n",
      "220/220 [==============================] - 0s 381us/sample - loss: 0.2604 - mean_absolute_error: 0.2422\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 1s 3ms/sample - loss: 1.6646 - mean_absolute_error: 0.9026\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.2267 - mean_absolute_error: 0.6955\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.6705 - mean_absolute_error: 0.5584\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.7270 - mean_absolute_error: 0.5538\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5031 - mean_absolute_error: 0.4334\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.7129 - mean_absolute_error: 0.5092\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2711 - mean_absolute_error: 0.3377\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2951 - mean_absolute_error: 0.3147\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5530 - mean_absolute_error: 0.3619\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4353 - mean_absolute_error: 0.3005\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2843 - mean_absolute_error: 0.3076\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3255 - mean_absolute_error: 0.2684\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4206 - mean_absolute_error: 0.3083\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2165 - mean_absolute_error: 0.2502\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.7839 - mean_absolute_error: 0.3125\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2865 - mean_absolute_error: 0.2312\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0619 - mean_absolute_error: 0.1536\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0821 - mean_absolute_error: 0.1216\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2322 - mean_absolute_error: 0.1428\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1483 - mean_absolute_error: 0.1684\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1363 - mean_absolute_error: 0.1859\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3510 - mean_absolute_error: 0.1833\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1319 - mean_absolute_error: 0.1754\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1912 - mean_absolute_error: 0.2019\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3685 - mean_absolute_error: 0.2067\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2245 - mean_absolute_error: 0.1847\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0761 - mean_absolute_error: 0.1483\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1573 - mean_absolute_error: 0.1711\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3365 - mean_absolute_error: 0.1876\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1890 - mean_absolute_error: 0.1322\n",
      "110/110 [==============================] - 0s 728us/sample - loss: 1.0772 - mean_absolute_error: 0.7312\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 0.0308 - mean_absolute_error: 0.0750\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 1s 3ms/sample - loss: 1.1630 - mean_absolute_error: 0.7835\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.9969 - mean_absolute_error: 0.6940\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.6808 - mean_absolute_error: 0.5830\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5275 - mean_absolute_error: 0.5349\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2263 - mean_absolute_error: 0.3502\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2986 - mean_absolute_error: 0.3381\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2856 - mean_absolute_error: 0.3139\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2139 - mean_absolute_error: 0.2717\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1328 - mean_absolute_error: 0.2325\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1192 - mean_absolute_error: 0.1743\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0821 - mean_absolute_error: 0.1984\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1174 - mean_absolute_error: 0.1978\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0756 - mean_absolute_error: 0.1482\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0745 - mean_absolute_error: 0.1496\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1132 - mean_absolute_error: 0.1562\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0670 - mean_absolute_error: 0.1435\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0539 - mean_absolute_error: 0.1421\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0745 - mean_absolute_error: 0.1339\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0685 - mean_absolute_error: 0.1362\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0611 - mean_absolute_error: 0.1141\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0302 - mean_absolute_error: 0.1026\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0321 - mean_absolute_error: 0.1057\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0529 - mean_absolute_error: 0.1144\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0812 - mean_absolute_error: 0.1164\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0407 - mean_absolute_error: 0.1088\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0371 - mean_absolute_error: 0.1007\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0691 - mean_absolute_error: 0.1275\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0506 - mean_absolute_error: 0.1295\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0275 - mean_absolute_error: 0.0921\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0154 - mean_absolute_error: 0.0747\n",
      "110/110 [==============================] - 0s 755us/sample - loss: 1.4905 - mean_absolute_error: 0.7076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 396us/sample - loss: 0.0108 - mean_absolute_error: 0.0684\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 1s 3ms/sample - loss: 1.7213 - mean_absolute_error: 0.9338\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.6805 - mean_absolute_error: 0.8869\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.8165 - mean_absolute_error: 0.5993\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.9850 - mean_absolute_error: 0.5931\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 2.5820 - mean_absolute_error: 0.7214\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.9310 - mean_absolute_error: 0.4964\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5059 - mean_absolute_error: 0.4330\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5058 - mean_absolute_error: 0.3558\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4300 - mean_absolute_error: 0.2822\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2391 - mean_absolute_error: 0.2839\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3170 - mean_absolute_error: 0.2583\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2989 - mean_absolute_error: 0.2645\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2609 - mean_absolute_error: 0.2551\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3119 - mean_absolute_error: 0.2169\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1036 - mean_absolute_error: 0.1660\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0808 - mean_absolute_error: 0.1354\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4018 - mean_absolute_error: 0.2372\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2523 - mean_absolute_error: 0.1821\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1353 - mean_absolute_error: 0.2079\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3043 - mean_absolute_error: 0.2194\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3122 - mean_absolute_error: 0.2256\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1738 - mean_absolute_error: 0.2762\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3555 - mean_absolute_error: 0.2756\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2237 - mean_absolute_error: 0.2331\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2579 - mean_absolute_error: 0.2441\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4151 - mean_absolute_error: 0.3038\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1970 - mean_absolute_error: 0.3005\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2442 - mean_absolute_error: 0.2837\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0936 - mean_absolute_error: 0.1901\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3628 - mean_absolute_error: 0.1872\n",
      "110/110 [==============================] - 0s 770us/sample - loss: 0.7651 - mean_absolute_error: 0.6405\n",
      "220/220 [==============================] - 0s 389us/sample - loss: 0.2243 - mean_absolute_error: 0.1890\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 1s 3ms/sample - loss: 1.5359 - mean_absolute_error: 0.8571\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.4301 - mean_absolute_error: 0.7768\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.8920 - mean_absolute_error: 0.5938\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.6157 - mean_absolute_error: 0.5400\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.7453 - mean_absolute_error: 0.4760\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5292 - mean_absolute_error: 0.4167\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4826 - mean_absolute_error: 0.4391\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 2.7833 - mean_absolute_error: 0.5799\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.6190 - mean_absolute_error: 0.4171\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.4282 - mean_absolute_error: 0.3820\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.2631 - mean_absolute_error: 0.2936\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.3568 - mean_absolute_error: 0.2895\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.4643 - mean_absolute_error: 0.2508 0s - loss: 0.0558 - mean_absolute_error\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.4781 - mean_absolute_error: 0.2671\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2216 - mean_absolute_error: 0.1944\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1304 - mean_absolute_error: 0.1777\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.1941 - mean_absolute_error: 0.2212\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2711 - mean_absolute_error: 0.1558\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2288 - mean_absolute_error: 0.1473\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1807 - mean_absolute_error: 0.1367\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0713 - mean_absolute_error: 0.1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0519 - mean_absolute_error: 0.0891\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0853 - mean_absolute_error: 0.0932\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0524 - mean_absolute_error: 0.0802\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0634 - mean_absolute_error: 0.0960\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1755 - mean_absolute_error: 0.1004\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0322 - mean_absolute_error: 0.0741\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0322 - mean_absolute_error: 0.0744\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0318 - mean_absolute_error: 0.0779\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0312 - mean_absolute_error: 0.0842\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0376 - mean_absolute_error: 0.0643\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0299 - mean_absolute_error: 0.0638\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0283 - mean_absolute_error: 0.0760\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0321 - mean_absolute_error: 0.0682\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0288 - mean_absolute_error: 0.0600\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 1s 3ms/sample - loss: 0.0158 - mean_absolute_error: 0.0488\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0242 - mean_absolute_error: 0.0563\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0274 - mean_absolute_error: 0.0665\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0413 - mean_absolute_error: 0.0726\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0492 - mean_absolute_error: 0.0892\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0922 - mean_absolute_error: 0.1129\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0674 - mean_absolute_error: 0.1135\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1122 - mean_absolute_error: 0.1168\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0537 - mean_absolute_error: 0.1186\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1117 - mean_absolute_error: 0.1586\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1423 - mean_absolute_error: 0.1875\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2435 - mean_absolute_error: 0.2335\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2931 - mean_absolute_error: 0.2474\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1846 - mean_absolute_error: 0.2039\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1600 - mean_absolute_error: 0.2052\n",
      "110/110 [==============================] - 0s 686us/sample - loss: 1.1154 - mean_absolute_error: 0.7027\n",
      "220/220 [==============================] - 0s 311us/sample - loss: 0.1391 - mean_absolute_error: 0.2145\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 1.4463 - mean_absolute_error: 0.9186\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.9039 - mean_absolute_error: 0.6776\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.5903 - mean_absolute_error: 0.5036\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4724 - mean_absolute_error: 0.4594\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1967 - mean_absolute_error: 0.3287\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.4802 - mean_absolute_error: 0.3950\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2691 - mean_absolute_error: 0.3327\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2580 - mean_absolute_error: 0.3328\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1953 - mean_absolute_error: 0.2443\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1717 - mean_absolute_error: 0.2343\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0847 - mean_absolute_error: 0.1900\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0775 - mean_absolute_error: 0.1690\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2146 - mean_absolute_error: 0.2317\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.1816 - mean_absolute_error: 0.1886\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1211 - mean_absolute_error: 0.1351\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0809 - mean_absolute_error: 0.1187\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0426 - mean_absolute_error: 0.1129\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0345 - mean_absolute_error: 0.1026\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0443 - mean_absolute_error: 0.1047\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0457 - mean_absolute_error: 0.1179\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0578 - mean_absolute_error: 0.1141\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0252 - mean_absolute_error: 0.0967\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0439 - mean_absolute_error: 0.0999\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0434 - mean_absolute_error: 0.1034\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0760 - mean_absolute_error: 0.1027\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0395 - mean_absolute_error: 0.1017\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0229 - mean_absolute_error: 0.0849\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0165 - mean_absolute_error: 0.0745\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0340 - mean_absolute_error: 0.0995\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0448 - mean_absolute_error: 0.0878\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0313 - mean_absolute_error: 0.0978\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0942 - mean_absolute_error: 0.1360\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1126 - mean_absolute_error: 0.1197\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0872 - mean_absolute_error: 0.0984\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0840 - mean_absolute_error: 0.1361\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0505 - mean_absolute_error: 0.1397\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0426 - mean_absolute_error: 0.1174\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0946 - mean_absolute_error: 0.1402\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0483 - mean_absolute_error: 0.1323\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0416 - mean_absolute_error: 0.1162\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0676 - mean_absolute_error: 0.1272\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0337 - mean_absolute_error: 0.1109\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0284 - mean_absolute_error: 0.1081\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0285 - mean_absolute_error: 0.0875\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0836 - mean_absolute_error: 0.1408\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0773 - mean_absolute_error: 0.1878\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0802 - mean_absolute_error: 0.1832\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2307 - mean_absolute_error: 0.2025\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0994 - mean_absolute_error: 0.2138\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1168 - mean_absolute_error: 0.2134\n",
      "110/110 [==============================] - 0s 785us/sample - loss: 1.9907 - mean_absolute_error: 0.7733\n",
      "220/220 [==============================] - 0s 371us/sample - loss: 0.4900 - mean_absolute_error: 0.3577\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 2.0196 - mean_absolute_error: 1.0329\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.5532 - mean_absolute_error: 0.7899\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.1621 - mean_absolute_error: 0.7159\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5671 - mean_absolute_error: 0.4889\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5202 - mean_absolute_error: 0.4556\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.9442 - mean_absolute_error: 0.5271\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5189 - mean_absolute_error: 0.4678\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4951 - mean_absolute_error: 0.4585\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.8511 - mean_absolute_error: 0.5029\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.6515 - mean_absolute_error: 0.4219\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.6237 - mean_absolute_error: 0.4438\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2707 - mean_absolute_error: 0.3187\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2504 - mean_absolute_error: 0.2491\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1747 - mean_absolute_error: 0.1861\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2339 - mean_absolute_error: 0.1848\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2702 - mean_absolute_error: 0.3099\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3177 - mean_absolute_error: 0.2446\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0955 - mean_absolute_error: 0.1808\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0614 - mean_absolute_error: 0.1384\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1178 - mean_absolute_error: 0.1492\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1019 - mean_absolute_error: 0.1566\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1705 - mean_absolute_error: 0.1366\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0949 - mean_absolute_error: 0.1409\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2365 - mean_absolute_error: 0.1673\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3183 - mean_absolute_error: 0.1995\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2457 - mean_absolute_error: 0.2139\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0948 - mean_absolute_error: 0.1787\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1075 - mean_absolute_error: 0.1612\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0834 - mean_absolute_error: 0.1344\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1863 - mean_absolute_error: 0.1555\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2403 - mean_absolute_error: 0.1420\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2391 - mean_absolute_error: 0.1370\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0614 - mean_absolute_error: 0.0993\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1701 - mean_absolute_error: 0.1013\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0433 - mean_absolute_error: 0.0913\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0672 - mean_absolute_error: 0.1033\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0315 - mean_absolute_error: 0.0995\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0538 - mean_absolute_error: 0.0842\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2054 - mean_absolute_error: 0.1179\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1437 - mean_absolute_error: 0.1033\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1112 - mean_absolute_error: 0.1218\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1130 - mean_absolute_error: 0.1453\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1101 - mean_absolute_error: 0.1587\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1320 - mean_absolute_error: 0.1351\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0492 - mean_absolute_error: 0.1205\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0618 - mean_absolute_error: 0.1072\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0363 - mean_absolute_error: 0.0907\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0539 - mean_absolute_error: 0.0887\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0364 - mean_absolute_error: 0.0834\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0308 - mean_absolute_error: 0.0722\n",
      "110/110 [==============================] - 0s 830us/sample - loss: 0.8586 - mean_absolute_error: 0.6259\n",
      "220/220 [==============================] - 0s 436us/sample - loss: 0.0196 - mean_absolute_error: 0.0580\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_100 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 1s 3ms/sample - loss: 1.4355 - mean_absolute_error: 0.8435\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.2831 - mean_absolute_error: 0.7953\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.1025 - mean_absolute_error: 0.6771\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.5871 - mean_absolute_error: 0.4547\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 2.0628 - mean_absolute_error: 0.5513\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.7429 - mean_absolute_error: 0.4546\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3124 - mean_absolute_error: 0.3274\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2917 - mean_absolute_error: 0.2809\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.2578 - mean_absolute_error: 0.3459\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5923 - mean_absolute_error: 0.3497\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3829 - mean_absolute_error: 0.3139\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1817 - mean_absolute_error: 0.2649\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3424 - mean_absolute_error: 0.2503\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1598 - mean_absolute_error: 0.1712\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1197 - mean_absolute_error: 0.1485\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1485 - mean_absolute_error: 0.1367\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0369 - mean_absolute_error: 0.1080\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0411 - mean_absolute_error: 0.1018\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0906 - mean_absolute_error: 0.1254\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2063 - mean_absolute_error: 0.1443\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1802 - mean_absolute_error: 0.1177\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1089 - mean_absolute_error: 0.1175\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1063 - mean_absolute_error: 0.1257\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0680 - mean_absolute_error: 0.1420\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.1227 - mean_absolute_error: 0.1533\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0701 - mean_absolute_error: 0.1422\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1928 - mean_absolute_error: 0.1795\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1833 - mean_absolute_error: 0.1645\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1558 - mean_absolute_error: 0.1471\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1312 - mean_absolute_error: 0.1502\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1486 - mean_absolute_error: 0.1473\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0425 - mean_absolute_error: 0.1171\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0710 - mean_absolute_error: 0.1340\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1330 - mean_absolute_error: 0.1263\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0741 - mean_absolute_error: 0.1261\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0746 - mean_absolute_error: 0.1192\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0411 - mean_absolute_error: 0.1075\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0298 - mean_absolute_error: 0.0919\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0629 - mean_absolute_error: 0.0874\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0188 - mean_absolute_error: 0.0712\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0224 - mean_absolute_error: 0.0714\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0198 - mean_absolute_error: 0.0646\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0600 - mean_absolute_error: 0.0847\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0689 - mean_absolute_error: 0.0928\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0475 - mean_absolute_error: 0.0869\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0165 - mean_absolute_error: 0.0705\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0337 - mean_absolute_error: 0.0805\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0435 - mean_absolute_error: 0.0912\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1294 - mean_absolute_error: 0.1007\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0430 - mean_absolute_error: 0.0896\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1412 - mean_absolute_error: 0.1225\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2008 - mean_absolute_error: 0.1292\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1392 - mean_absolute_error: 0.1395\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1602 - mean_absolute_error: 0.1617\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0741 - mean_absolute_error: 0.1348\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0691 - mean_absolute_error: 0.1365\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1222 - mean_absolute_error: 0.1474\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1412 - mean_absolute_error: 0.1387\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0236 - mean_absolute_error: 0.0843\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0263 - mean_absolute_error: 0.0877\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0678 - mean_absolute_error: 0.1088\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0726 - mean_absolute_error: 0.1285\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1222 - mean_absolute_error: 0.1175\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0429 - mean_absolute_error: 0.0958\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0475 - mean_absolute_error: 0.0955\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0726 - mean_absolute_error: 0.0988\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0216 - mean_absolute_error: 0.0704\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0224 - mean_absolute_error: 0.0602\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0192 - mean_absolute_error: 0.0551\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0184 - mean_absolute_error: 0.0577\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0413 - mean_absolute_error: 0.0786\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0311 - mean_absolute_error: 0.0700\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0246 - mean_absolute_error: 0.0672\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0631 - mean_absolute_error: 0.0783\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0688 - mean_absolute_error: 0.1330\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1842 - mean_absolute_error: 0.1860\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3554 - mean_absolute_error: 0.2770\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2532 - mean_absolute_error: 0.2870\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4127 - mean_absolute_error: 0.3525\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3040 - mean_absolute_error: 0.3185\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3665 - mean_absolute_error: 0.3723\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4123 - mean_absolute_error: 0.3406\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2437 - mean_absolute_error: 0.2560\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2448 - mean_absolute_error: 0.2035\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1046 - mean_absolute_error: 0.1641\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0909 - mean_absolute_error: 0.1385\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0914 - mean_absolute_error: 0.1312\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0472 - mean_absolute_error: 0.0988\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0288 - mean_absolute_error: 0.0774\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0284 - mean_absolute_error: 0.0641\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0134 - mean_absolute_error: 0.0607\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0181 - mean_absolute_error: 0.0643\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0150 - mean_absolute_error: 0.0604\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0172 - mean_absolute_error: 0.0652\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0190 - mean_absolute_error: 0.0562\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0093 - mean_absolute_error: 0.0432\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0090 - mean_absolute_error: 0.0403\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0164 - mean_absolute_error: 0.0408\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0246 - mean_absolute_error: 0.0476\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0438 - mean_absolute_error: 0.0552\n",
      "110/110 [==============================] - 0s 788us/sample - loss: 1.0873 - mean_absolute_error: 0.7365\n",
      "220/220 [==============================] - 0s 400us/sample - loss: 0.0028 - mean_absolute_error: 0.0327\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 1s 3ms/sample - loss: 1.1308 - mean_absolute_error: 0.7844\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.8592 - mean_absolute_error: 0.6456\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5224 - mean_absolute_error: 0.5203\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.7088 - mean_absolute_error: 0.4635\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3026 - mean_absolute_error: 0.3796\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1852 - mean_absolute_error: 0.3024\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1700 - mean_absolute_error: 0.2277\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1058 - mean_absolute_error: 0.2005\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1324 - mean_absolute_error: 0.2087\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0745 - mean_absolute_error: 0.1715\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0779 - mean_absolute_error: 0.1539\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0632 - mean_absolute_error: 0.1469\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0961 - mean_absolute_error: 0.1425\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0441 - mean_absolute_error: 0.1219\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0389 - mean_absolute_error: 0.1087\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0269 - mean_absolute_error: 0.0936\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0317 - mean_absolute_error: 0.0900\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0307 - mean_absolute_error: 0.1023\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0431 - mean_absolute_error: 0.1004\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0419 - mean_absolute_error: 0.1042\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0214 - mean_absolute_error: 0.0878\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0357 - mean_absolute_error: 0.0879\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0406 - mean_absolute_error: 0.1004\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0382 - mean_absolute_error: 0.0974\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0278 - mean_absolute_error: 0.0996\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0550 - mean_absolute_error: 0.1149\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0556 - mean_absolute_error: 0.1391\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0582 - mean_absolute_error: 0.1253\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0157 - mean_absolute_error: 0.0811\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0160 - mean_absolute_error: 0.0753\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0371 - mean_absolute_error: 0.0977\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0847 - mean_absolute_error: 0.1263\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0980 - mean_absolute_error: 0.1332\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0891 - mean_absolute_error: 0.1470\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0603 - mean_absolute_error: 0.1285\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0481 - mean_absolute_error: 0.1365\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0411 - mean_absolute_error: 0.1275\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0391 - mean_absolute_error: 0.1188\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0409 - mean_absolute_error: 0.1224\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0787 - mean_absolute_error: 0.1342\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0551 - mean_absolute_error: 0.1400\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0524 - mean_absolute_error: 0.1392\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0539 - mean_absolute_error: 0.1499\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0410 - mean_absolute_error: 0.1211\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0200 - mean_absolute_error: 0.0901\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0120 - mean_absolute_error: 0.0728\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0246 - mean_absolute_error: 0.0730\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0143 - mean_absolute_error: 0.0699\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0203 - mean_absolute_error: 0.0824\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0227 - mean_absolute_error: 0.0758\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0155 - mean_absolute_error: 0.0626\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0248 - mean_absolute_error: 0.0676\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0244 - mean_absolute_error: 0.0684\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0193 - mean_absolute_error: 0.0659\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0419 - mean_absolute_error: 0.0856\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0535 - mean_absolute_error: 0.1017\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0229 - mean_absolute_error: 0.0822\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0134 - mean_absolute_error: 0.0709\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0114 - mean_absolute_error: 0.0651\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0076 - mean_absolute_error: 0.0552\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0088 - mean_absolute_error: 0.0532\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0134 - mean_absolute_error: 0.0663\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0158 - mean_absolute_error: 0.0701\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0116 - mean_absolute_error: 0.0653\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0056 - mean_absolute_error: 0.0478\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0038 - mean_absolute_error: 0.0406\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0060 - mean_absolute_error: 0.0477\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0073 - mean_absolute_error: 0.0540\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0120 - mean_absolute_error: 0.0614\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0159 - mean_absolute_error: 0.0770\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0230 - mean_absolute_error: 0.0921\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0196 - mean_absolute_error: 0.0955\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0182 - mean_absolute_error: 0.0872\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0106 - mean_absolute_error: 0.0712\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0121 - mean_absolute_error: 0.0731\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0095 - mean_absolute_error: 0.0646\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0139 - mean_absolute_error: 0.0722\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0182 - mean_absolute_error: 0.0770\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0345 - mean_absolute_error: 0.0935\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0619 - mean_absolute_error: 0.1304\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0698 - mean_absolute_error: 0.1730\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0636 - mean_absolute_error: 0.1805\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0770 - mean_absolute_error: 0.1891\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1091 - mean_absolute_error: 0.1975\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0868 - mean_absolute_error: 0.2044\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0953 - mean_absolute_error: 0.2043\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0784 - mean_absolute_error: 0.1665\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0456 - mean_absolute_error: 0.1307\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0928 - mean_absolute_error: 0.1444\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0563 - mean_absolute_error: 0.1418\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0776 - mean_absolute_error: 0.1580\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1222 - mean_absolute_error: 0.1745\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0991 - mean_absolute_error: 0.1992\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0812 - mean_absolute_error: 0.1734\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0627 - mean_absolute_error: 0.1632\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0663 - mean_absolute_error: 0.1566\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0181 - mean_absolute_error: 0.0956\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0205 - mean_absolute_error: 0.0811\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0136 - mean_absolute_error: 0.0602\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0167 - mean_absolute_error: 0.0597\n",
      "110/110 [==============================] - 0s 747us/sample - loss: 1.5276 - mean_absolute_error: 0.7492\n",
      "220/220 [==============================] - 0s 376us/sample - loss: 0.0089 - mean_absolute_error: 0.0458\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 1s 3ms/sample - loss: 1.7732 - mean_absolute_error: 0.9539\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.5468 - mean_absolute_error: 0.8561\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.9241 - mean_absolute_error: 0.6362\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.3083 - mean_absolute_error: 0.7034\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5624 - mean_absolute_error: 0.5006\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.3079 - mean_absolute_error: 0.4617\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5832 - mean_absolute_error: 0.4424\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3911 - mean_absolute_error: 0.3605\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.8541 - mean_absolute_error: 0.3685\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3834 - mean_absolute_error: 0.3438\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2021 - mean_absolute_error: 0.3008\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4123 - mean_absolute_error: 0.3026\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3132 - mean_absolute_error: 0.2682\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4033 - mean_absolute_error: 0.2833\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.5481 - mean_absolute_error: 0.3400\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.6149 - mean_absolute_error: 0.3512\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3550 - mean_absolute_error: 0.3034\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1342 - mean_absolute_error: 0.2146\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.4061 - mean_absolute_error: 0.2519\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0936 - mean_absolute_error: 0.1356\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0240 - mean_absolute_error: 0.0890\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0883 - mean_absolute_error: 0.1165\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2555 - mean_absolute_error: 0.2097\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.3225 - mean_absolute_error: 0.1755\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1973 - mean_absolute_error: 0.1389\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0346 - mean_absolute_error: 0.1108\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0532 - mean_absolute_error: 0.1174\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2212 - mean_absolute_error: 0.1437\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1262 - mean_absolute_error: 0.1415\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1280 - mean_absolute_error: 0.1531\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2202 - mean_absolute_error: 0.1160\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1573 - mean_absolute_error: 0.1291\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0799 - mean_absolute_error: 0.1290\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0784 - mean_absolute_error: 0.1028\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.1548 - mean_absolute_error: 0.1301\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2987 - mean_absolute_error: 0.1997\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.1621 - mean_absolute_error: 0.1362\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1082 - mean_absolute_error: 0.1268\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2162 - mean_absolute_error: 0.1119\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1467 - mean_absolute_error: 0.0939\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0249 - mean_absolute_error: 0.0655\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0422 - mean_absolute_error: 0.0831\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2260 - mean_absolute_error: 0.1392\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2417 - mean_absolute_error: 0.1454\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.2052 - mean_absolute_error: 0.1275\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0885 - mean_absolute_error: 0.1085\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0762 - mean_absolute_error: 0.1037\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0534 - mean_absolute_error: 0.0944\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.3455 - mean_absolute_error: 0.1476\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.2897 - mean_absolute_error: 0.1884\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.1137 - mean_absolute_error: 0.1467\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.2601 - mean_absolute_error: 0.1920\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.3521 - mean_absolute_error: 0.2055\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1904 - mean_absolute_error: 0.1620\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0717 - mean_absolute_error: 0.1314\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0760 - mean_absolute_error: 0.1300\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.1775 - mean_absolute_error: 0.1591\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0629 - mean_absolute_error: 0.1152\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0276 - mean_absolute_error: 0.0973\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0167 - mean_absolute_error: 0.0660\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0100 - mean_absolute_error: 0.0498\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0063 - mean_absolute_error: 0.0360\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0107 - mean_absolute_error: 0.0429\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0087 - mean_absolute_error: 0.0357\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0126 - mean_absolute_error: 0.0379\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0175 - mean_absolute_error: 0.0461\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0150 - mean_absolute_error: 0.0434\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0128 - mean_absolute_error: 0.0379\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0055 - mean_absolute_error: 0.0329\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0066 - mean_absolute_error: 0.0347\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0057 - mean_absolute_error: 0.0306\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0052 - mean_absolute_error: 0.0324\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0077 - mean_absolute_error: 0.0431\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0068 - mean_absolute_error: 0.0429\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0072 - mean_absolute_error: 0.0447\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0146 - mean_absolute_error: 0.0551\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0205 - mean_absolute_error: 0.0757\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0333 - mean_absolute_error: 0.0934\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0315 - mean_absolute_error: 0.1033\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0498 - mean_absolute_error: 0.1144\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0856 - mean_absolute_error: 0.1354\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0564 - mean_absolute_error: 0.1265\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0270 - mean_absolute_error: 0.1010\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0257 - mean_absolute_error: 0.1009\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0381 - mean_absolute_error: 0.1057\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0391 - mean_absolute_error: 0.1010\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0376 - mean_absolute_error: 0.0960\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0554 - mean_absolute_error: 0.1106\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0606 - mean_absolute_error: 0.0977\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0216 - mean_absolute_error: 0.0858\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0173 - mean_absolute_error: 0.0697\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0111 - mean_absolute_error: 0.0595\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0200 - mean_absolute_error: 0.0729\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0182 - mean_absolute_error: 0.0754\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0143 - mean_absolute_error: 0.0692\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 1s 2ms/sample - loss: 0.0112 - mean_absolute_error: 0.0682\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0083 - mean_absolute_error: 0.0602\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0089 - mean_absolute_error: 0.0517\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0150 - mean_absolute_error: 0.0686\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.0262 - mean_absolute_error: 0.0783\n",
      "110/110 [==============================] - 0s 776us/sample - loss: 0.7760 - mean_absolute_error: 0.6272\n",
      "220/220 [==============================] - 0s 387us/sample - loss: 0.0203 - mean_absolute_error: 0.0727\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.3882 - mean_absolute_error: 0.8200\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.2043 - mean_absolute_error: 0.6699\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6146 - mean_absolute_error: 0.4734\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4767 - mean_absolute_error: 0.4532\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.5931 - mean_absolute_error: 0.4017\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2564 - mean_absolute_error: 0.3380\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.7770 - mean_absolute_error: 0.4112\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4038 - mean_absolute_error: 0.2794\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2919 - mean_absolute_error: 0.2759\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3332 - mean_absolute_error: 0.2917\n",
      "110/110 [==============================] - 0s 614us/sample - loss: 1.0357 - mean_absolute_error: 0.6921\n",
      "220/220 [==============================] - 0s 233us/sample - loss: 0.3102 - mean_absolute_error: 0.2085\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_120 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.9374 - mean_absolute_error: 0.7168\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6716 - mean_absolute_error: 0.5862\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3588 - mean_absolute_error: 0.4399\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3346 - mean_absolute_error: 0.4299\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2571 - mean_absolute_error: 0.3382\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1400 - mean_absolute_error: 0.2438\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1639 - mean_absolute_error: 0.2565\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0852 - mean_absolute_error: 0.1890\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0999 - mean_absolute_error: 0.1816\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0677 - mean_absolute_error: 0.1521\n",
      "110/110 [==============================] - 0s 614us/sample - loss: 1.5937 - mean_absolute_error: 0.7413\n",
      "220/220 [==============================] - 0s 236us/sample - loss: 0.0703 - mean_absolute_error: 0.1303\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.5983 - mean_absolute_error: 0.9028\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4744 - mean_absolute_error: 0.7907\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.7502 - mean_absolute_error: 0.5945\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6225 - mean_absolute_error: 0.5300\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6396 - mean_absolute_error: 0.4155\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2977 - mean_absolute_error: 0.3832\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2569 - mean_absolute_error: 0.3033\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3863 - mean_absolute_error: 0.2607\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2034 - mean_absolute_error: 0.2885\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2900 - mean_absolute_error: 0.3040\n",
      "110/110 [==============================] - 0s 655us/sample - loss: 0.5956 - mean_absolute_error: 0.5812\n",
      "220/220 [==============================] - 0s 240us/sample - loss: 0.3477 - mean_absolute_error: 0.2911\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_130 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.3318 - mean_absolute_error: 0.8211\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.2781 - mean_absolute_error: 0.7674\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.7896 - mean_absolute_error: 0.6318\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3507 - mean_absolute_error: 0.3819\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6443 - mean_absolute_error: 0.4110\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4685 - mean_absolute_error: 0.3516\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2264 - mean_absolute_error: 0.2902\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4047 - mean_absolute_error: 0.3025\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3230 - mean_absolute_error: 0.2468\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3594 - mean_absolute_error: 0.2702\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2828 - mean_absolute_error: 0.2806\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0588 - mean_absolute_error: 0.1690\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0873 - mean_absolute_error: 0.1694\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0884 - mean_absolute_error: 0.1851\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0702 - mean_absolute_error: 0.1748\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1472 - mean_absolute_error: 0.1468\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0805 - mean_absolute_error: 0.1300\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1456 - mean_absolute_error: 0.1722\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3590 - mean_absolute_error: 0.2108\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2540 - mean_absolute_error: 0.1895\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0649 - mean_absolute_error: 0.1429\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6901 - mean_absolute_error: 0.2115\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3450 - mean_absolute_error: 0.2269\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1786 - mean_absolute_error: 0.1861\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0781 - mean_absolute_error: 0.1418\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2584 - mean_absolute_error: 0.1557\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1183 - mean_absolute_error: 0.1394\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1189 - mean_absolute_error: 0.1619\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2225 - mean_absolute_error: 0.1425\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0841 - mean_absolute_error: 0.1250\n",
      "110/110 [==============================] - 0s 627us/sample - loss: 1.0155 - mean_absolute_error: 0.7017\n",
      "220/220 [==============================] - 0s 235us/sample - loss: 0.0902 - mean_absolute_error: 0.1046\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 0.9970 - mean_absolute_error: 0.7520\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.7871 - mean_absolute_error: 0.6565\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4343 - mean_absolute_error: 0.4673\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3704 - mean_absolute_error: 0.4382\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1768 - mean_absolute_error: 0.3066\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1962 - mean_absolute_error: 0.2756\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2093 - mean_absolute_error: 0.2544\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0782 - mean_absolute_error: 0.1760\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0880 - mean_absolute_error: 0.1645\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0414 - mean_absolute_error: 0.1307\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0593 - mean_absolute_error: 0.1292\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0428 - mean_absolute_error: 0.1237\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0379 - mean_absolute_error: 0.1124\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0248 - mean_absolute_error: 0.1040\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0263 - mean_absolute_error: 0.0943\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0489 - mean_absolute_error: 0.1058\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0305 - mean_absolute_error: 0.0870\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0494 - mean_absolute_error: 0.0891\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0181 - mean_absolute_error: 0.0732\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0161 - mean_absolute_error: 0.0681\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0226 - mean_absolute_error: 0.0803\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0279 - mean_absolute_error: 0.0959\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0427 - mean_absolute_error: 0.1014\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0368 - mean_absolute_error: 0.0991\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0469 - mean_absolute_error: 0.0957\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0282 - mean_absolute_error: 0.1000\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0441 - mean_absolute_error: 0.1013\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0285 - mean_absolute_error: 0.1083\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0406 - mean_absolute_error: 0.1188\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0249 - mean_absolute_error: 0.0886\n",
      "110/110 [==============================] - 0s 672us/sample - loss: 1.5827 - mean_absolute_error: 0.7323\n",
      "220/220 [==============================] - 0s 236us/sample - loss: 0.0274 - mean_absolute_error: 0.0720\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_140 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.6763 - mean_absolute_error: 0.8932\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.3318 - mean_absolute_error: 0.7831\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.7873 - mean_absolute_error: 0.6284\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3893 - mean_absolute_error: 0.4609\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6642 - mean_absolute_error: 0.4712\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.5346 - mean_absolute_error: 0.3768\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2630 - mean_absolute_error: 0.3320\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1803 - mean_absolute_error: 0.2754\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1892 - mean_absolute_error: 0.2692\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4150 - mean_absolute_error: 0.2687\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1450 - mean_absolute_error: 0.2296\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1395 - mean_absolute_error: 0.2228\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2808 - mean_absolute_error: 0.1996\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0773 - mean_absolute_error: 0.1904\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0506 - mean_absolute_error: 0.1417\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0537 - mean_absolute_error: 0.1350\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1883 - mean_absolute_error: 0.1539\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0596 - mean_absolute_error: 0.1442\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0689 - mean_absolute_error: 0.1417\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0760 - mean_absolute_error: 0.1331\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0934 - mean_absolute_error: 0.1351\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0363 - mean_absolute_error: 0.1150\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0320 - mean_absolute_error: 0.0921\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0545 - mean_absolute_error: 0.0894\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1810 - mean_absolute_error: 0.1189\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0962 - mean_absolute_error: 0.1185\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0488 - mean_absolute_error: 0.1039\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1182 - mean_absolute_error: 0.1221\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0564 - mean_absolute_error: 0.0996\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0644 - mean_absolute_error: 0.1020\n",
      "110/110 [==============================] - 0s 612us/sample - loss: 0.6254 - mean_absolute_error: 0.5968\n",
      "220/220 [==============================] - 0s 233us/sample - loss: 0.0293 - mean_absolute_error: 0.0794\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_145 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.3433 - mean_absolute_error: 0.8422\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.1017 - mean_absolute_error: 0.6792\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6612 - mean_absolute_error: 0.5369\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6887 - mean_absolute_error: 0.4839\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.8005 - mean_absolute_error: 0.4231\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4313 - mean_absolute_error: 0.3216\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3341 - mean_absolute_error: 0.3442\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4953 - mean_absolute_error: 0.3420\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1604 - mean_absolute_error: 0.2553\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1467 - mean_absolute_error: 0.1939\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1487 - mean_absolute_error: 0.1817\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3111 - mean_absolute_error: 0.2296\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1854 - mean_absolute_error: 0.1867\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1012 - mean_absolute_error: 0.1866\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1022 - mean_absolute_error: 0.1598\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1704 - mean_absolute_error: 0.1292\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0804 - mean_absolute_error: 0.1128\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0311 - mean_absolute_error: 0.0892\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0381 - mean_absolute_error: 0.0819\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0110 - mean_absolute_error: 0.0668\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0066 - mean_absolute_error: 0.0478\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0046 - mean_absolute_error: 0.0353\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0052 - mean_absolute_error: 0.0337\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0070 - mean_absolute_error: 0.0345\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0064 - mean_absolute_error: 0.0344\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0127 - mean_absolute_error: 0.0385\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0481 - mean_absolute_error: 0.0777\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0378 - mean_absolute_error: 0.1104\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0597 - mean_absolute_error: 0.1190\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0611 - mean_absolute_error: 0.1240\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1438 - mean_absolute_error: 0.1252\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0429 - mean_absolute_error: 0.0993\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0304 - mean_absolute_error: 0.0903\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0296 - mean_absolute_error: 0.0811\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0642 - mean_absolute_error: 0.0900\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1808 - mean_absolute_error: 0.1397\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1359 - mean_absolute_error: 0.1386\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0799 - mean_absolute_error: 0.1263\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0184 - mean_absolute_error: 0.0721\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0506 - mean_absolute_error: 0.0884\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0345 - mean_absolute_error: 0.0760\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0526 - mean_absolute_error: 0.1034\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0239 - mean_absolute_error: 0.0956\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0309 - mean_absolute_error: 0.0895\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0251 - mean_absolute_error: 0.0730\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0375 - mean_absolute_error: 0.0651\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0276 - mean_absolute_error: 0.0636\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0800 - mean_absolute_error: 0.1044\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0289 - mean_absolute_error: 0.0888\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0675 - mean_absolute_error: 0.1137\n",
      "110/110 [==============================] - 0s 700us/sample - loss: 1.0068 - mean_absolute_error: 0.6860\n",
      "220/220 [==============================] - 0s 239us/sample - loss: 0.0339 - mean_absolute_error: 0.0800\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_150 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.2367 - mean_absolute_error: 0.8517\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6713 - mean_absolute_error: 0.5611\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4028 - mean_absolute_error: 0.4453\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2329 - mean_absolute_error: 0.3289\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1761 - mean_absolute_error: 0.2993\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2853 - mean_absolute_error: 0.3414\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2087 - mean_absolute_error: 0.2980\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1086 - mean_absolute_error: 0.2369\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2105 - mean_absolute_error: 0.2255\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1183 - mean_absolute_error: 0.1993\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1714 - mean_absolute_error: 0.2344\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1735 - mean_absolute_error: 0.1970\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1020 - mean_absolute_error: 0.1600\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0509 - mean_absolute_error: 0.1405\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1435 - mean_absolute_error: 0.2126\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1683 - mean_absolute_error: 0.1801\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1607 - mean_absolute_error: 0.1926\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0689 - mean_absolute_error: 0.1614\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0922 - mean_absolute_error: 0.1623\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1650 - mean_absolute_error: 0.1675\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1093 - mean_absolute_error: 0.1458\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0348 - mean_absolute_error: 0.1104\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0748 - mean_absolute_error: 0.1117\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1165 - mean_absolute_error: 0.1027\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0780 - mean_absolute_error: 0.0941\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0242 - mean_absolute_error: 0.0852\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0309 - mean_absolute_error: 0.1066\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0559 - mean_absolute_error: 0.1156\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0394 - mean_absolute_error: 0.1209\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0371 - mean_absolute_error: 0.1127\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0572 - mean_absolute_error: 0.1355\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0235 - mean_absolute_error: 0.0918\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0114 - mean_absolute_error: 0.0622\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0139 - mean_absolute_error: 0.0621\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0107 - mean_absolute_error: 0.0531\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0044 - mean_absolute_error: 0.0405\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0062 - mean_absolute_error: 0.0423\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0078 - mean_absolute_error: 0.0429\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0120 - mean_absolute_error: 0.0400\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0259 - mean_absolute_error: 0.0565\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0220 - mean_absolute_error: 0.0644\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0142 - mean_absolute_error: 0.0554\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0424 - mean_absolute_error: 0.0691\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0175 - mean_absolute_error: 0.0593\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0407 - mean_absolute_error: 0.0629\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0196 - mean_absolute_error: 0.0589\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0126 - mean_absolute_error: 0.0604\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0177 - mean_absolute_error: 0.0674\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0155 - mean_absolute_error: 0.0610\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0341 - mean_absolute_error: 0.0739\n",
      "110/110 [==============================] - 0s 629us/sample - loss: 1.5044 - mean_absolute_error: 0.7787\n",
      "220/220 [==============================] - 0s 236us/sample - loss: 0.0275 - mean_absolute_error: 0.0747\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_155 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.7801 - mean_absolute_error: 0.9413\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4909 - mean_absolute_error: 0.8971\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.7527 - mean_absolute_error: 0.5794\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.0009 - mean_absolute_error: 0.5949\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.7731 - mean_absolute_error: 0.5244\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2465 - mean_absolute_error: 0.3463\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1700 - mean_absolute_error: 0.2958\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3234 - mean_absolute_error: 0.3200\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.6446 - mean_absolute_error: 0.4214\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4353 - mean_absolute_error: 0.3445\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3865 - mean_absolute_error: 0.3122\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1034 - mean_absolute_error: 0.2090\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2047 - mean_absolute_error: 0.2190\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0688 - mean_absolute_error: 0.1540\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0187 - mean_absolute_error: 0.0922\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0135 - mean_absolute_error: 0.0645\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0091 - mean_absolute_error: 0.0475\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0190 - mean_absolute_error: 0.0509\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0354 - mean_absolute_error: 0.0678\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1052 - mean_absolute_error: 0.0785\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0639 - mean_absolute_error: 0.1373\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1403 - mean_absolute_error: 0.1747\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2370 - mean_absolute_error: 0.1823\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1385 - mean_absolute_error: 0.1717\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2678 - mean_absolute_error: 0.2093\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3929 - mean_absolute_error: 0.2076\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1078 - mean_absolute_error: 0.1763\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1921 - mean_absolute_error: 0.1976\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3219 - mean_absolute_error: 0.1736\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2260 - mean_absolute_error: 0.1387\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0495 - mean_absolute_error: 0.0971\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1041 - mean_absolute_error: 0.0952\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2101 - mean_absolute_error: 0.1202\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1775 - mean_absolute_error: 0.1058\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0687 - mean_absolute_error: 0.1046\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0724 - mean_absolute_error: 0.1014\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1456 - mean_absolute_error: 0.0983\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0601 - mean_absolute_error: 0.0913\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0552 - mean_absolute_error: 0.0948\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1381 - mean_absolute_error: 0.1068\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1702 - mean_absolute_error: 0.0995\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1436 - mean_absolute_error: 0.0974\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0569 - mean_absolute_error: 0.0678\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0119 - mean_absolute_error: 0.0515\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0847 - mean_absolute_error: 0.0729\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1688 - mean_absolute_error: 0.1011\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0931 - mean_absolute_error: 0.0840\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0151 - mean_absolute_error: 0.0583\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0144 - mean_absolute_error: 0.0490\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0084 - mean_absolute_error: 0.0444\n",
      "110/110 [==============================] - 0s 621us/sample - loss: 0.6783 - mean_absolute_error: 0.5823\n",
      "220/220 [==============================] - 0s 227us/sample - loss: 0.0148 - mean_absolute_error: 0.0571\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_160 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.7473 - mean_absolute_error: 0.9015\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4062 - mean_absolute_error: 0.7392\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.8552 - mean_absolute_error: 0.6255\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4338 - mean_absolute_error: 0.4569\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4143 - mean_absolute_error: 0.3445\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2688 - mean_absolute_error: 0.2473\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2025 - mean_absolute_error: 0.2312\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1315 - mean_absolute_error: 0.2095\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2043 - mean_absolute_error: 0.2289\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4178 - mean_absolute_error: 0.3105\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1625 - mean_absolute_error: 0.2118\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0751 - mean_absolute_error: 0.1740\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1214 - mean_absolute_error: 0.1629\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1271 - mean_absolute_error: 0.1468\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2406 - mean_absolute_error: 0.1477\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1799 - mean_absolute_error: 0.1616\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0617 - mean_absolute_error: 0.1331\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0394 - mean_absolute_error: 0.1165\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1123 - mean_absolute_error: 0.1292\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2710 - mean_absolute_error: 0.1724\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2392 - mean_absolute_error: 0.1528\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1461 - mean_absolute_error: 0.1354\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0389 - mean_absolute_error: 0.1212\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0294 - mean_absolute_error: 0.1073\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0362 - mean_absolute_error: 0.0932\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0760 - mean_absolute_error: 0.0983\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0746 - mean_absolute_error: 0.0967\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1185 - mean_absolute_error: 0.1302\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1127 - mean_absolute_error: 0.1237\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0479 - mean_absolute_error: 0.1145\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0271 - mean_absolute_error: 0.0954\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0184 - mean_absolute_error: 0.0727\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0067 - mean_absolute_error: 0.0518\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0058 - mean_absolute_error: 0.0410\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0071 - mean_absolute_error: 0.0376\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0150 - mean_absolute_error: 0.0448\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0327 - mean_absolute_error: 0.0670\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0357 - mean_absolute_error: 0.0822\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0466 - mean_absolute_error: 0.0887\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0537 - mean_absolute_error: 0.1030\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0205 - mean_absolute_error: 0.0693\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0081 - mean_absolute_error: 0.0593\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0077 - mean_absolute_error: 0.0568\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0119 - mean_absolute_error: 0.0560\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0210 - mean_absolute_error: 0.0634\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0482 - mean_absolute_error: 0.0837\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0266 - mean_absolute_error: 0.0707\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0512 - mean_absolute_error: 0.0710\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0172 - mean_absolute_error: 0.0670\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0359 - mean_absolute_error: 0.0831\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0192 - mean_absolute_error: 0.0599\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0280 - mean_absolute_error: 0.0579\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0420 - mean_absolute_error: 0.0775\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0518 - mean_absolute_error: 0.0868\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0118 - mean_absolute_error: 0.0614\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0188 - mean_absolute_error: 0.0681\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0406 - mean_absolute_error: 0.0882\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0248 - mean_absolute_error: 0.0851\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0798 - mean_absolute_error: 0.1092\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0512 - mean_absolute_error: 0.1228\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0704 - mean_absolute_error: 0.1295\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0441 - mean_absolute_error: 0.1079\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0996 - mean_absolute_error: 0.1210\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0978 - mean_absolute_error: 0.1308\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0556 - mean_absolute_error: 0.1356\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0965 - mean_absolute_error: 0.1695\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1408 - mean_absolute_error: 0.1789\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1137 - mean_absolute_error: 0.1993\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2450 - mean_absolute_error: 0.2072\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2460 - mean_absolute_error: 0.2223\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2074 - mean_absolute_error: 0.2230\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2554 - mean_absolute_error: 0.2377\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2226 - mean_absolute_error: 0.2440\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1503 - mean_absolute_error: 0.1722\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1119 - mean_absolute_error: 0.1431\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1341 - mean_absolute_error: 0.1317\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0457 - mean_absolute_error: 0.1152\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0684 - mean_absolute_error: 0.1084\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0885 - mean_absolute_error: 0.1037\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0820 - mean_absolute_error: 0.1059\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0329 - mean_absolute_error: 0.0960\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0462 - mean_absolute_error: 0.1029\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0486 - mean_absolute_error: 0.0823\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0795 - mean_absolute_error: 0.1090\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0627 - mean_absolute_error: 0.1105\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0712 - mean_absolute_error: 0.1220\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0294 - mean_absolute_error: 0.0853\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0252 - mean_absolute_error: 0.0737\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0163 - mean_absolute_error: 0.0505\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0053 - mean_absolute_error: 0.0368\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0048 - mean_absolute_error: 0.0288\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0068 - mean_absolute_error: 0.0323\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0030 - mean_absolute_error: 0.0269\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0019 - mean_absolute_error: 0.0227\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0010 - mean_absolute_error: 0.0171\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 6.3052e-04 - mean_absolute_error: 0.0124\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 5.2712e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.6292e-04 - mean_absolute_error: 0.0063\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.0571e-04 - mean_absolute_error: 0.0048\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 7.6993e-05 - mean_absolute_error: 0.0040\n",
      "110/110 [==============================] - 0s 616us/sample - loss: 1.0629 - mean_absolute_error: 0.7406\n",
      "220/220 [==============================] - 0s 237us/sample - loss: 4.2357e-05 - mean_absolute_error: 0.0032\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_165 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.2209 - mean_absolute_error: 0.8098\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.7099 - mean_absolute_error: 0.6074\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3349 - mean_absolute_error: 0.4229\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3627 - mean_absolute_error: 0.4296\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2701 - mean_absolute_error: 0.3727\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2099 - mean_absolute_error: 0.3091\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1607 - mean_absolute_error: 0.2670\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1050 - mean_absolute_error: 0.2010\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0745 - mean_absolute_error: 0.1591\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1285 - mean_absolute_error: 0.1625\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0759 - mean_absolute_error: 0.1506\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0802 - mean_absolute_error: 0.1605\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1095 - mean_absolute_error: 0.1474\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0557 - mean_absolute_error: 0.1240\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0264 - mean_absolute_error: 0.1054\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0192 - mean_absolute_error: 0.0881\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0262 - mean_absolute_error: 0.0673\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0136 - mean_absolute_error: 0.0696\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0400 - mean_absolute_error: 0.0871\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0385 - mean_absolute_error: 0.0817\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0252 - mean_absolute_error: 0.0913\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0157 - mean_absolute_error: 0.0768\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0152 - mean_absolute_error: 0.0649\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0062 - mean_absolute_error: 0.0569\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0053 - mean_absolute_error: 0.0506\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0056 - mean_absolute_error: 0.0493\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0095 - mean_absolute_error: 0.0484\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0097 - mean_absolute_error: 0.0511\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0080 - mean_absolute_error: 0.0560\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0071 - mean_absolute_error: 0.0526\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0042 - mean_absolute_error: 0.0394\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0029 - mean_absolute_error: 0.0345\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0034 - mean_absolute_error: 0.0348\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0076 - mean_absolute_error: 0.0411\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0337 - mean_absolute_error: 0.0721\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0425 - mean_absolute_error: 0.1108\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0488 - mean_absolute_error: 0.1007\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0180 - mean_absolute_error: 0.0884\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0343 - mean_absolute_error: 0.0962\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0305 - mean_absolute_error: 0.0928\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0624 - mean_absolute_error: 0.1284\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0989 - mean_absolute_error: 0.1414\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0741 - mean_absolute_error: 0.1467\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0471 - mean_absolute_error: 0.1187\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0272 - mean_absolute_error: 0.1083\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0617 - mean_absolute_error: 0.1378\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0895 - mean_absolute_error: 0.1440\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1878 - mean_absolute_error: 0.1967\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1044 - mean_absolute_error: 0.1659\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0824 - mean_absolute_error: 0.1666\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1565 - mean_absolute_error: 0.1849\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1145 - mean_absolute_error: 0.2254\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1254 - mean_absolute_error: 0.2440\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1027 - mean_absolute_error: 0.2203\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0398 - mean_absolute_error: 0.1297\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0313 - mean_absolute_error: 0.1121\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0236 - mean_absolute_error: 0.0838\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0214 - mean_absolute_error: 0.0656\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0130 - mean_absolute_error: 0.0621\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0085 - mean_absolute_error: 0.0548\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0091 - mean_absolute_error: 0.0491\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0037 - mean_absolute_error: 0.0360\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0051 - mean_absolute_error: 0.0366\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0080 - mean_absolute_error: 0.0372\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0105 - mean_absolute_error: 0.0402\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0072 - mean_absolute_error: 0.0395\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0116 - mean_absolute_error: 0.0511\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0153 - mean_absolute_error: 0.0628\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0239 - mean_absolute_error: 0.0674\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0098 - mean_absolute_error: 0.0564\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0067 - mean_absolute_error: 0.0448\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0029 - mean_absolute_error: 0.0309\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0062 - mean_absolute_error: 0.0364\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0046 - mean_absolute_error: 0.0346\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0048 - mean_absolute_error: 0.0345\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0030 - mean_absolute_error: 0.0279\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0020 - mean_absolute_error: 0.0257\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0031 - mean_absolute_error: 0.0237\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0051 - mean_absolute_error: 0.0265\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0044 - mean_absolute_error: 0.0280\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0036 - mean_absolute_error: 0.0296\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0064 - mean_absolute_error: 0.0312\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0065 - mean_absolute_error: 0.0351\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0104 - mean_absolute_error: 0.0464\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0207 - mean_absolute_error: 0.0650\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0123 - mean_absolute_error: 0.0579\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0284 - mean_absolute_error: 0.0806\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0420 - mean_absolute_error: 0.0867\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0164 - mean_absolute_error: 0.0775\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0223 - mean_absolute_error: 0.0780\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0362 - mean_absolute_error: 0.0839\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0170 - mean_absolute_error: 0.0711\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0096 - mean_absolute_error: 0.0547\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0147 - mean_absolute_error: 0.0493\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0143 - mean_absolute_error: 0.0633\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0216 - mean_absolute_error: 0.0667\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0172 - mean_absolute_error: 0.0628\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0077 - mean_absolute_error: 0.0526\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0109 - mean_absolute_error: 0.0542\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0060 - mean_absolute_error: 0.0463\n",
      "110/110 [==============================] - 0s 624us/sample - loss: 1.5482 - mean_absolute_error: 0.7352\n",
      "220/220 [==============================] - 0s 240us/sample - loss: 0.0121 - mean_absolute_error: 0.0590\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_170 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.6992 - mean_absolute_error: 0.9287\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.2692 - mean_absolute_error: 0.7618\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.7797 - mean_absolute_error: 0.6232\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.5728 - mean_absolute_error: 0.4602\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3725 - mean_absolute_error: 0.3902\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3687 - mean_absolute_error: 0.3931\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.5668 - mean_absolute_error: 0.4024\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2854 - mean_absolute_error: 0.3296\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4173 - mean_absolute_error: 0.4043\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3262 - mean_absolute_error: 0.2664\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1472 - mean_absolute_error: 0.2594\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.3563 - mean_absolute_error: 0.2441\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1435 - mean_absolute_error: 0.2355\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4764 - mean_absolute_error: 0.3219\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4561 - mean_absolute_error: 0.3257\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2085 - mean_absolute_error: 0.2148\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0579 - mean_absolute_error: 0.1605\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1739 - mean_absolute_error: 0.1714\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.4138 - mean_absolute_error: 0.2068\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2480 - mean_absolute_error: 0.1908\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1101 - mean_absolute_error: 0.1838\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1046 - mean_absolute_error: 0.1843\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.2196 - mean_absolute_error: 0.1794\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0951 - mean_absolute_error: 0.1617\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1128 - mean_absolute_error: 0.1945\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1719 - mean_absolute_error: 0.1760\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0447 - mean_absolute_error: 0.1138\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0241 - mean_absolute_error: 0.0979\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0225 - mean_absolute_error: 0.0808\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0163 - mean_absolute_error: 0.0711\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0149 - mean_absolute_error: 0.0592\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0063 - mean_absolute_error: 0.0369\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0053 - mean_absolute_error: 0.0317\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0023 - mean_absolute_error: 0.0251\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0033 - mean_absolute_error: 0.0252\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0038 - mean_absolute_error: 0.0258\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0045 - mean_absolute_error: 0.0247\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0060 - mean_absolute_error: 0.0267\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0086 - mean_absolute_error: 0.0330\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0129 - mean_absolute_error: 0.0378\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0230 - mean_absolute_error: 0.0476\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0115 - mean_absolute_error: 0.0413\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0120 - mean_absolute_error: 0.0351\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0232 - mean_absolute_error: 0.0490\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0171 - mean_absolute_error: 0.0555\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0489 - mean_absolute_error: 0.0781\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0152 - mean_absolute_error: 0.0681\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0232 - mean_absolute_error: 0.0672\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0157 - mean_absolute_error: 0.0539\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0419 - mean_absolute_error: 0.0830\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0375 - mean_absolute_error: 0.0909\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0388 - mean_absolute_error: 0.0891\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0454 - mean_absolute_error: 0.0893\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0564 - mean_absolute_error: 0.0762\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0164 - mean_absolute_error: 0.0569\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0265 - mean_absolute_error: 0.0710\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0308 - mean_absolute_error: 0.0677\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0585 - mean_absolute_error: 0.0832\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0410 - mean_absolute_error: 0.0912\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1238 - mean_absolute_error: 0.1507\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0975 - mean_absolute_error: 0.1192\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0480 - mean_absolute_error: 0.1201\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0187 - mean_absolute_error: 0.0880\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0340 - mean_absolute_error: 0.0949\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0967 - mean_absolute_error: 0.1204\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0432 - mean_absolute_error: 0.1054\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0294 - mean_absolute_error: 0.0874\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0286 - mean_absolute_error: 0.0788\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0140 - mean_absolute_error: 0.0546\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0133 - mean_absolute_error: 0.0466\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0278 - mean_absolute_error: 0.0629\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0404 - mean_absolute_error: 0.0700\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0397 - mean_absolute_error: 0.0812\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0310 - mean_absolute_error: 0.0800\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0212 - mean_absolute_error: 0.0676\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0127 - mean_absolute_error: 0.0510\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0098 - mean_absolute_error: 0.0452\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0046 - mean_absolute_error: 0.0305\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0033 - mean_absolute_error: 0.0272\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0030 - mean_absolute_error: 0.0312\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0062 - mean_absolute_error: 0.0400\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0151 - mean_absolute_error: 0.0558\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0136 - mean_absolute_error: 0.0487\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0137 - mean_absolute_error: 0.0464\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0250 - mean_absolute_error: 0.0548\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0208 - mean_absolute_error: 0.0636\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0239 - mean_absolute_error: 0.0748\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0187 - mean_absolute_error: 0.0617\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0096 - mean_absolute_error: 0.0466\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0059 - mean_absolute_error: 0.0453\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0080 - mean_absolute_error: 0.0433\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0087 - mean_absolute_error: 0.0434\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0128 - mean_absolute_error: 0.0544\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0166 - mean_absolute_error: 0.0553\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0147 - mean_absolute_error: 0.0556\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0143 - mean_absolute_error: 0.0569\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0213 - mean_absolute_error: 0.0729\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0559 - mean_absolute_error: 0.1018\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0738 - mean_absolute_error: 0.1268\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.1079 - mean_absolute_error: 0.1583\n",
      "110/110 [==============================] - 0s 621us/sample - loss: 0.6806 - mean_absolute_error: 0.6437\n",
      "220/220 [==============================] - 0s 236us/sample - loss: 0.1039 - mean_absolute_error: 0.1588\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4014 - mean_absolute_error: 0.8039\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 726us/sample - loss: 0.7980 - mean_absolute_error: 0.6251\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 850us/sample - loss: 0.5542 - mean_absolute_error: 0.5235\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 842us/sample - loss: 0.3811 - mean_absolute_error: 0.3781\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 789us/sample - loss: 0.3968 - mean_absolute_error: 0.3014\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 810us/sample - loss: 0.2117 - mean_absolute_error: 0.3531\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 764us/sample - loss: 0.3084 - mean_absolute_error: 0.3477\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 730us/sample - loss: 0.5115 - mean_absolute_error: 0.2992\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 714us/sample - loss: 0.3696 - mean_absolute_error: 0.2651\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 786us/sample - loss: 0.2604 - mean_absolute_error: 0.2137\n",
      "110/110 [==============================] - 0s 670us/sample - loss: 1.0103 - mean_absolute_error: 0.6768\n",
      "220/220 [==============================] - 0s 222us/sample - loss: 0.1314 - mean_absolute_error: 0.1459\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.1710 - mean_absolute_error: 0.7768\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.6964 - mean_absolute_error: 0.5703\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 737us/sample - loss: 0.3284 - mean_absolute_error: 0.4323\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 766us/sample - loss: 0.2238 - mean_absolute_error: 0.3498\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 820us/sample - loss: 0.2370 - mean_absolute_error: 0.3276\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.1725 - mean_absolute_error: 0.2679\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.2722 - mean_absolute_error: 0.3311\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 786us/sample - loss: 0.1678 - mean_absolute_error: 0.2598\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 792us/sample - loss: 0.0822 - mean_absolute_error: 0.1838\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 758us/sample - loss: 0.0988 - mean_absolute_error: 0.1739\n",
      "110/110 [==============================] - 0s 653us/sample - loss: 1.5915 - mean_absolute_error: 0.7419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 205us/sample - loss: 0.1036 - mean_absolute_error: 0.1841\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_185 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.8576 - mean_absolute_error: 0.9601\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 762us/sample - loss: 1.0289 - mean_absolute_error: 0.7641\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 850us/sample - loss: 0.6007 - mean_absolute_error: 0.5340\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 829us/sample - loss: 0.3961 - mean_absolute_error: 0.3869\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 865us/sample - loss: 0.5905 - mean_absolute_error: 0.4228\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 818us/sample - loss: 0.2196 - mean_absolute_error: 0.3255\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 847us/sample - loss: 0.4381 - mean_absolute_error: 0.3463\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 825us/sample - loss: 0.3285 - mean_absolute_error: 0.2813\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 793us/sample - loss: 0.1855 - mean_absolute_error: 0.2313\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 867us/sample - loss: 0.1189 - mean_absolute_error: 0.2074\n",
      "110/110 [==============================] - 0s 620us/sample - loss: 0.6043 - mean_absolute_error: 0.5368\n",
      "220/220 [==============================] - 0s 218us/sample - loss: 0.2553 - mean_absolute_error: 0.2446\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_190 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4550 - mean_absolute_error: 0.8701\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 801us/sample - loss: 1.1868 - mean_absolute_error: 0.6679\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 806us/sample - loss: 0.6483 - mean_absolute_error: 0.5715\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 799us/sample - loss: 0.5411 - mean_absolute_error: 0.4104\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 812us/sample - loss: 0.8715 - mean_absolute_error: 0.5241\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 842us/sample - loss: 0.4746 - mean_absolute_error: 0.4160\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 820us/sample - loss: 0.2363 - mean_absolute_error: 0.3208\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 777us/sample - loss: 0.2148 - mean_absolute_error: 0.2959\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 824us/sample - loss: 0.1404 - mean_absolute_error: 0.2364\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 833us/sample - loss: 0.1406 - mean_absolute_error: 0.2360\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 810us/sample - loss: 0.0492 - mean_absolute_error: 0.1593\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 833us/sample - loss: 0.0352 - mean_absolute_error: 0.1261\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 786us/sample - loss: 0.0664 - mean_absolute_error: 0.1379\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0502 - mean_absolute_error: 0.1170\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 889us/sample - loss: 0.0492 - mean_absolute_error: 0.1070\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 811us/sample - loss: 0.0579 - mean_absolute_error: 0.1017\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 786us/sample - loss: 0.1341 - mean_absolute_error: 0.1491\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 843us/sample - loss: 0.0571 - mean_absolute_error: 0.1361\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 808us/sample - loss: 0.0351 - mean_absolute_error: 0.1062\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0252 - mean_absolute_error: 0.0796\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 893us/sample - loss: 0.1057 - mean_absolute_error: 0.1048\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 801us/sample - loss: 0.0353 - mean_absolute_error: 0.0898\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 873us/sample - loss: 0.0572 - mean_absolute_error: 0.1177\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 813us/sample - loss: 0.0430 - mean_absolute_error: 0.1210\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 805us/sample - loss: 0.0533 - mean_absolute_error: 0.1294\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 843us/sample - loss: 0.0251 - mean_absolute_error: 0.0809\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 825us/sample - loss: 0.0340 - mean_absolute_error: 0.0721\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 807us/sample - loss: 0.0393 - mean_absolute_error: 0.0802\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 758us/sample - loss: 0.0516 - mean_absolute_error: 0.0891\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0222 - mean_absolute_error: 0.0739\n",
      "110/110 [==============================] - 0s 577us/sample - loss: 0.9655 - mean_absolute_error: 0.6777\n",
      "220/220 [==============================] - 0s 207us/sample - loss: 0.0279 - mean_absolute_error: 0.0773\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_195 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.0310 - mean_absolute_error: 0.7698\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 763us/sample - loss: 0.7566 - mean_absolute_error: 0.6349\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 862us/sample - loss: 0.4207 - mean_absolute_error: 0.4648\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 830us/sample - loss: 0.1738 - mean_absolute_error: 0.2966\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 836us/sample - loss: 0.2480 - mean_absolute_error: 0.3390\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 864us/sample - loss: 0.1086 - mean_absolute_error: 0.2219\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 825us/sample - loss: 0.0841 - mean_absolute_error: 0.1789\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0986 - mean_absolute_error: 0.1947\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0930 - mean_absolute_error: 0.1713\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 772us/sample - loss: 0.0933 - mean_absolute_error: 0.1691\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 828us/sample - loss: 0.1468 - mean_absolute_error: 0.1777\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 829us/sample - loss: 0.0647 - mean_absolute_error: 0.1547\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 829us/sample - loss: 0.0548 - mean_absolute_error: 0.1441\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 824us/sample - loss: 0.0620 - mean_absolute_error: 0.1263\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 824us/sample - loss: 0.0218 - mean_absolute_error: 0.0908\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 838us/sample - loss: 0.0353 - mean_absolute_error: 0.1068\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 851us/sample - loss: 0.0331 - mean_absolute_error: 0.0932\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 824us/sample - loss: 0.0168 - mean_absolute_error: 0.0858\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 805us/sample - loss: 0.0130 - mean_absolute_error: 0.0676\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 798us/sample - loss: 0.0137 - mean_absolute_error: 0.0542\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 823us/sample - loss: 0.0129 - mean_absolute_error: 0.0496\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 860us/sample - loss: 0.0136 - mean_absolute_error: 0.0590\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 827us/sample - loss: 0.0451 - mean_absolute_error: 0.0904\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 817us/sample - loss: 0.0216 - mean_absolute_error: 0.0932\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 917us/sample - loss: 0.0282 - mean_absolute_error: 0.1025\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 850us/sample - loss: 0.0132 - mean_absolute_error: 0.0765\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 849us/sample - loss: 0.0171 - mean_absolute_error: 0.0867\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 832us/sample - loss: 0.0152 - mean_absolute_error: 0.0827\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 939us/sample - loss: 0.0331 - mean_absolute_error: 0.0965\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 819us/sample - loss: 0.0261 - mean_absolute_error: 0.0919\n",
      "110/110 [==============================] - 0s 648us/sample - loss: 1.6136 - mean_absolute_error: 0.7548\n",
      "220/220 [==============================] - 0s 218us/sample - loss: 0.0303 - mean_absolute_error: 0.1071\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_200 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 2ms/sample - loss: 1.9024 - mean_absolute_error: 0.9187\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 836us/sample - loss: 1.2156 - mean_absolute_error: 0.7434\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 827us/sample - loss: 0.4919 - mean_absolute_error: 0.5113\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 840us/sample - loss: 0.5340 - mean_absolute_error: 0.3883\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 917us/sample - loss: 0.2668 - mean_absolute_error: 0.3591\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 838us/sample - loss: 0.2888 - mean_absolute_error: 0.3712\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 810us/sample - loss: 0.2425 - mean_absolute_error: 0.2877\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 849us/sample - loss: 0.3517 - mean_absolute_error: 0.3782\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 803us/sample - loss: 0.1333 - mean_absolute_error: 0.2673\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 767us/sample - loss: 0.0837 - mean_absolute_error: 0.2066\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 868us/sample - loss: 0.0411 - mean_absolute_error: 0.1295\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 876us/sample - loss: 0.0721 - mean_absolute_error: 0.1327\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 797us/sample - loss: 0.0616 - mean_absolute_error: 0.1474\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 824us/sample - loss: 0.0393 - mean_absolute_error: 0.1234\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 807us/sample - loss: 0.0321 - mean_absolute_error: 0.0986\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 813us/sample - loss: 0.0143 - mean_absolute_error: 0.0692\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 904us/sample - loss: 0.0168 - mean_absolute_error: 0.0589\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 822us/sample - loss: 0.0090 - mean_absolute_error: 0.0431\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 796us/sample - loss: 0.0172 - mean_absolute_error: 0.0474\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 856us/sample - loss: 0.0415 - mean_absolute_error: 0.0681\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 761us/sample - loss: 0.0833 - mean_absolute_error: 0.1165\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0511 - mean_absolute_error: 0.1479\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.1231 - mean_absolute_error: 0.1743\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.1056 - mean_absolute_error: 0.1413\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0356 - mean_absolute_error: 0.1198\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 799us/sample - loss: 0.1581 - mean_absolute_error: 0.1314\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 799us/sample - loss: 0.3070 - mean_absolute_error: 0.2186\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 784us/sample - loss: 0.3466 - mean_absolute_error: 0.2616\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 785us/sample - loss: 0.3796 - mean_absolute_error: 0.2749\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 791us/sample - loss: 0.4347 - mean_absolute_error: 0.2806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 588us/sample - loss: 0.5961 - mean_absolute_error: 0.5319\n",
      "220/220 [==============================] - 0s 202us/sample - loss: 0.4524 - mean_absolute_error: 0.3419\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_205 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4467 - mean_absolute_error: 0.8757\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 722us/sample - loss: 1.0879 - mean_absolute_error: 0.6829\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 731us/sample - loss: 0.6075 - mean_absolute_error: 0.5494\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 726us/sample - loss: 0.3794 - mean_absolute_error: 0.3654\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 725us/sample - loss: 0.2074 - mean_absolute_error: 0.3009\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 723us/sample - loss: 0.4250 - mean_absolute_error: 0.2978\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 727us/sample - loss: 0.2496 - mean_absolute_error: 0.2626\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.2019 - mean_absolute_error: 0.2460\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 728us/sample - loss: 0.2897 - mean_absolute_error: 0.2036\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 723us/sample - loss: 0.3500 - mean_absolute_error: 0.2457\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.1403 - mean_absolute_error: 0.2017\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 765us/sample - loss: 0.5496 - mean_absolute_error: 0.2376\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 862us/sample - loss: 0.3621 - mean_absolute_error: 0.2664\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 845us/sample - loss: 0.2709 - mean_absolute_error: 0.2119\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 788us/sample - loss: 0.1893 - mean_absolute_error: 0.2017\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 803us/sample - loss: 0.0926 - mean_absolute_error: 0.1698\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 788us/sample - loss: 0.1120 - mean_absolute_error: 0.1790\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 764us/sample - loss: 0.1005 - mean_absolute_error: 0.1783\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 760us/sample - loss: 0.2140 - mean_absolute_error: 0.2253\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 746us/sample - loss: 0.0483 - mean_absolute_error: 0.1161\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 815us/sample - loss: 0.0529 - mean_absolute_error: 0.1125\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0729 - mean_absolute_error: 0.1270\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0721 - mean_absolute_error: 0.1109\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 794us/sample - loss: 0.1162 - mean_absolute_error: 0.1289\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 809us/sample - loss: 0.0350 - mean_absolute_error: 0.1093\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 798us/sample - loss: 0.0436 - mean_absolute_error: 0.0980\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.0319 - mean_absolute_error: 0.0703\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.0537 - mean_absolute_error: 0.0719\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 787us/sample - loss: 0.0478 - mean_absolute_error: 0.0791\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0308 - mean_absolute_error: 0.0655\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 763us/sample - loss: 0.0487 - mean_absolute_error: 0.0763\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 794us/sample - loss: 0.0130 - mean_absolute_error: 0.0446\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 792us/sample - loss: 0.0124 - mean_absolute_error: 0.0470\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 818us/sample - loss: 0.0027 - mean_absolute_error: 0.0301\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.0025 - mean_absolute_error: 0.0261\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 723us/sample - loss: 0.0024 - mean_absolute_error: 0.0241\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 771us/sample - loss: 0.0027 - mean_absolute_error: 0.0241\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 772us/sample - loss: 0.0024 - mean_absolute_error: 0.0217\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.0042 - mean_absolute_error: 0.0269\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 760us/sample - loss: 0.0025 - mean_absolute_error: 0.0230\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 800us/sample - loss: 0.0055 - mean_absolute_error: 0.0315\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 827us/sample - loss: 0.0069 - mean_absolute_error: 0.0366\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 794us/sample - loss: 0.0098 - mean_absolute_error: 0.0406\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 723us/sample - loss: 0.0106 - mean_absolute_error: 0.0523\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 715us/sample - loss: 0.0203 - mean_absolute_error: 0.0604\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.0187 - mean_absolute_error: 0.0556\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 768us/sample - loss: 0.0364 - mean_absolute_error: 0.0761\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 779us/sample - loss: 0.0237 - mean_absolute_error: 0.0757\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0559 - mean_absolute_error: 0.0984\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.0244 - mean_absolute_error: 0.0742\n",
      "110/110 [==============================] - 0s 595us/sample - loss: 0.9770 - mean_absolute_error: 0.6833\n",
      "220/220 [==============================] - 0s 206us/sample - loss: 0.0522 - mean_absolute_error: 0.0949\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_210 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.1541 - mean_absolute_error: 0.7797\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 721us/sample - loss: 0.8703 - mean_absolute_error: 0.6828\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 724us/sample - loss: 0.4162 - mean_absolute_error: 0.4609\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.3016 - mean_absolute_error: 0.4101\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.2100 - mean_absolute_error: 0.3408\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.1470 - mean_absolute_error: 0.2694\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.1163 - mean_absolute_error: 0.2320\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 727us/sample - loss: 0.1215 - mean_absolute_error: 0.2050\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 755us/sample - loss: 0.0954 - mean_absolute_error: 0.1744\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 755us/sample - loss: 0.0435 - mean_absolute_error: 0.1345\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 747us/sample - loss: 0.0309 - mean_absolute_error: 0.1092\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 753us/sample - loss: 0.0180 - mean_absolute_error: 0.0853\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.0147 - mean_absolute_error: 0.0790\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 769us/sample - loss: 0.0146 - mean_absolute_error: 0.0826\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 800us/sample - loss: 0.0142 - mean_absolute_error: 0.0667\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 826us/sample - loss: 0.0182 - mean_absolute_error: 0.0649\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 886us/sample - loss: 0.0041 - mean_absolute_error: 0.0452\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 848us/sample - loss: 0.0086 - mean_absolute_error: 0.0446\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 803us/sample - loss: 0.0187 - mean_absolute_error: 0.0485\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 857us/sample - loss: 0.0517 - mean_absolute_error: 0.0747\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 810us/sample - loss: 0.0132 - mean_absolute_error: 0.0693\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 804us/sample - loss: 0.0159 - mean_absolute_error: 0.0659\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 806us/sample - loss: 0.0099 - mean_absolute_error: 0.0548\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 828us/sample - loss: 0.0063 - mean_absolute_error: 0.0462\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0073 - mean_absolute_error: 0.0446\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 747us/sample - loss: 0.0088 - mean_absolute_error: 0.0477\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 830us/sample - loss: 0.0062 - mean_absolute_error: 0.0410\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 824us/sample - loss: 0.0055 - mean_absolute_error: 0.0354\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 796us/sample - loss: 0.0091 - mean_absolute_error: 0.0451\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 864us/sample - loss: 0.0191 - mean_absolute_error: 0.0638\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 777us/sample - loss: 0.0170 - mean_absolute_error: 0.0828\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 758us/sample - loss: 0.0349 - mean_absolute_error: 0.1008\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 746us/sample - loss: 0.0196 - mean_absolute_error: 0.0819\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 774us/sample - loss: 0.0257 - mean_absolute_error: 0.0843\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 813us/sample - loss: 0.0145 - mean_absolute_error: 0.0740\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 751us/sample - loss: 0.0344 - mean_absolute_error: 0.1006\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 823us/sample - loss: 0.0372 - mean_absolute_error: 0.1130\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 828us/sample - loss: 0.0567 - mean_absolute_error: 0.1294\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 749us/sample - loss: 0.0371 - mean_absolute_error: 0.1219\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 791us/sample - loss: 0.0284 - mean_absolute_error: 0.1153\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 792us/sample - loss: 0.0261 - mean_absolute_error: 0.0945\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 824us/sample - loss: 0.0280 - mean_absolute_error: 0.0957\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 762us/sample - loss: 0.0740 - mean_absolute_error: 0.1300\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 760us/sample - loss: 0.0219 - mean_absolute_error: 0.1051\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 751us/sample - loss: 0.0451 - mean_absolute_error: 0.1152\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 771us/sample - loss: 0.0549 - mean_absolute_error: 0.1120\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 821us/sample - loss: 0.0383 - mean_absolute_error: 0.1105\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0757 - mean_absolute_error: 0.1510\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 754us/sample - loss: 0.0573 - mean_absolute_error: 0.1364\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 761us/sample - loss: 0.0656 - mean_absolute_error: 0.1582\n",
      "110/110 [==============================] - 0s 583us/sample - loss: 1.6304 - mean_absolute_error: 0.7464\n",
      "220/220 [==============================] - 0s 202us/sample - loss: 0.1403 - mean_absolute_error: 0.1855\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_215 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.8312 - mean_absolute_error: 0.9705\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 756us/sample - loss: 0.8748 - mean_absolute_error: 0.6737\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.4988 - mean_absolute_error: 0.4795\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.4318 - mean_absolute_error: 0.4545\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 747us/sample - loss: 0.6020 - mean_absolute_error: 0.4295\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 753us/sample - loss: 0.3390 - mean_absolute_error: 0.3960\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.3992 - mean_absolute_error: 0.4062\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.4204 - mean_absolute_error: 0.4272\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.6850 - mean_absolute_error: 0.3831\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.3920 - mean_absolute_error: 0.3085\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 732us/sample - loss: 0.2480 - mean_absolute_error: 0.2513\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.2780 - mean_absolute_error: 0.1953\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.1015 - mean_absolute_error: 0.1607\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 764us/sample - loss: 0.2958 - mean_absolute_error: 0.1858\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.2307 - mean_absolute_error: 0.2026\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.0640 - mean_absolute_error: 0.1626\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 730us/sample - loss: 0.0579 - mean_absolute_error: 0.1357\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 734us/sample - loss: 0.0595 - mean_absolute_error: 0.1097\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.5143 - mean_absolute_error: 0.1860\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 734us/sample - loss: 0.1732 - mean_absolute_error: 0.2342\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 733us/sample - loss: 0.3427 - mean_absolute_error: 0.2096\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 723us/sample - loss: 0.2814 - mean_absolute_error: 0.1726\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 734us/sample - loss: 0.0981 - mean_absolute_error: 0.1227\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.0358 - mean_absolute_error: 0.1054\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.0338 - mean_absolute_error: 0.0861\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 746us/sample - loss: 0.0193 - mean_absolute_error: 0.0677\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.0178 - mean_absolute_error: 0.0619\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.0551 - mean_absolute_error: 0.0689\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 734us/sample - loss: 0.0306 - mean_absolute_error: 0.0843\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0588 - mean_absolute_error: 0.1048\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0212 - mean_absolute_error: 0.0781\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 735us/sample - loss: 0.0325 - mean_absolute_error: 0.0899\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 733us/sample - loss: 0.0264 - mean_absolute_error: 0.0788\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0428 - mean_absolute_error: 0.0793\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0232 - mean_absolute_error: 0.0669\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 731us/sample - loss: 0.0656 - mean_absolute_error: 0.0700\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 729us/sample - loss: 0.0232 - mean_absolute_error: 0.0629\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0434 - mean_absolute_error: 0.0873\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.0227 - mean_absolute_error: 0.0745\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.0482 - mean_absolute_error: 0.0795\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.0143 - mean_absolute_error: 0.0583\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0183 - mean_absolute_error: 0.0587\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0110 - mean_absolute_error: 0.0503\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0089 - mean_absolute_error: 0.0448\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.0040 - mean_absolute_error: 0.0340\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 734us/sample - loss: 0.0071 - mean_absolute_error: 0.0324\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0023 - mean_absolute_error: 0.0272\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 730us/sample - loss: 0.0018 - mean_absolute_error: 0.0250\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0025 - mean_absolute_error: 0.0248\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.0015 - mean_absolute_error: 0.0210\n",
      "110/110 [==============================] - 0s 596us/sample - loss: 0.7733 - mean_absolute_error: 0.6286\n",
      "220/220 [==============================] - 0s 195us/sample - loss: 0.0019 - mean_absolute_error: 0.0240\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_220 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.2619 - mean_absolute_error: 0.8208\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.9633 - mean_absolute_error: 0.6468\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 757us/sample - loss: 0.5975 - mean_absolute_error: 0.4912\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 751us/sample - loss: 0.5176 - mean_absolute_error: 0.4339\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 749us/sample - loss: 0.5203 - mean_absolute_error: 0.4028\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.3550 - mean_absolute_error: 0.3775\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 746us/sample - loss: 0.1964 - mean_absolute_error: 0.2970\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.1693 - mean_absolute_error: 0.2586\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.2226 - mean_absolute_error: 0.2103\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 749us/sample - loss: 0.4486 - mean_absolute_error: 0.3395\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.3055 - mean_absolute_error: 0.2370\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.1992 - mean_absolute_error: 0.2029\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.1704 - mean_absolute_error: 0.2031\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.2445 - mean_absolute_error: 0.2185\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.1447 - mean_absolute_error: 0.2268\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.0783 - mean_absolute_error: 0.1853\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0805 - mean_absolute_error: 0.1608\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0223 - mean_absolute_error: 0.1001\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 730us/sample - loss: 0.0167 - mean_absolute_error: 0.0796\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.0152 - mean_absolute_error: 0.0753\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 738us/sample - loss: 0.0207 - mean_absolute_error: 0.0705\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 725us/sample - loss: 0.0061 - mean_absolute_error: 0.0520\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.0114 - mean_absolute_error: 0.0415\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 732us/sample - loss: 0.0206 - mean_absolute_error: 0.0530\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 731us/sample - loss: 0.0092 - mean_absolute_error: 0.0523\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 746us/sample - loss: 0.0219 - mean_absolute_error: 0.0681\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.0289 - mean_absolute_error: 0.0789\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 735us/sample - loss: 0.0678 - mean_absolute_error: 0.1235\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.0283 - mean_absolute_error: 0.1008\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.1016 - mean_absolute_error: 0.1339\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.1186 - mean_absolute_error: 0.1361\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 722us/sample - loss: 0.0654 - mean_absolute_error: 0.1057\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0162 - mean_absolute_error: 0.0670\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 735us/sample - loss: 0.0318 - mean_absolute_error: 0.0651\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0200 - mean_absolute_error: 0.0943\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0361 - mean_absolute_error: 0.1085\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 734us/sample - loss: 0.0344 - mean_absolute_error: 0.1042\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 758us/sample - loss: 0.1963 - mean_absolute_error: 0.1567\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 753us/sample - loss: 0.2468 - mean_absolute_error: 0.1435\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.2054 - mean_absolute_error: 0.1291\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.1317 - mean_absolute_error: 0.1276\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.6572 - mean_absolute_error: 0.1659\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 737us/sample - loss: 0.5310 - mean_absolute_error: 0.3089\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 729us/sample - loss: 0.3322 - mean_absolute_error: 0.2712\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.3406 - mean_absolute_error: 0.3188\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.3744 - mean_absolute_error: 0.3141\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.3209 - mean_absolute_error: 0.2463\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.1504 - mean_absolute_error: 0.1880\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.2081 - mean_absolute_error: 0.1755\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 730us/sample - loss: 0.1742 - mean_absolute_error: 0.2749\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 735us/sample - loss: 0.2075 - mean_absolute_error: 0.2483\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.3505 - mean_absolute_error: 0.2095\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 730us/sample - loss: 0.1674 - mean_absolute_error: 0.1516\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 728us/sample - loss: 0.0780 - mean_absolute_error: 0.1154\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 733us/sample - loss: 0.1380 - mean_absolute_error: 0.1112\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0340 - mean_absolute_error: 0.0933\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 731us/sample - loss: 0.0567 - mean_absolute_error: 0.0812\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 732us/sample - loss: 0.0371 - mean_absolute_error: 0.0608\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 734us/sample - loss: 0.1382 - mean_absolute_error: 0.0783\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 734us/sample - loss: 0.0968 - mean_absolute_error: 0.0812\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 722us/sample - loss: 0.1345 - mean_absolute_error: 0.1106\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.2565 - mean_absolute_error: 0.1212\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.1996 - mean_absolute_error: 0.1022\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.0558 - mean_absolute_error: 0.0656\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.0423 - mean_absolute_error: 0.0684\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.0351 - mean_absolute_error: 0.0768\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0149 - mean_absolute_error: 0.0554\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 726us/sample - loss: 0.0139 - mean_absolute_error: 0.0413\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.0074 - mean_absolute_error: 0.0329\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0033 - mean_absolute_error: 0.0295\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 732us/sample - loss: 0.0023 - mean_absolute_error: 0.0248\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 6.2645e-04 - mean_absolute_error: 0.0150\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 4.4191e-04 - mean_absolute_error: 0.0131\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 2.5496e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 1.7309e-04 - mean_absolute_error: 0.0075\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 9.3543e-05 - mean_absolute_error: 0.0050\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 7.4165e-05 - mean_absolute_error: 0.0039\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 734us/sample - loss: 1.2164e-04 - mean_absolute_error: 0.0034\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 749us/sample - loss: 2.4262e-04 - mean_absolute_error: 0.0039\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 1.1686e-04 - mean_absolute_error: 0.0036\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 747us/sample - loss: 6.8605e-05 - mean_absolute_error: 0.0032\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 1.3886e-04 - mean_absolute_error: 0.0030\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 732us/sample - loss: 3.5186e-04 - mean_absolute_error: 0.0051\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 735us/sample - loss: 7.8735e-04 - mean_absolute_error: 0.0072\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 5.4259e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 3.5108e-04 - mean_absolute_error: 0.0067\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 5.4989e-04 - mean_absolute_error: 0.0078\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.0010 - mean_absolute_error: 0.0109\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 757us/sample - loss: 0.0027 - mean_absolute_error: 0.0161\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 745us/sample - loss: 0.0061 - mean_absolute_error: 0.0245\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.0065 - mean_absolute_error: 0.0323\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 733us/sample - loss: 0.0051 - mean_absolute_error: 0.0309\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 746us/sample - loss: 0.0089 - mean_absolute_error: 0.0370\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.0078 - mean_absolute_error: 0.0366\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 737us/sample - loss: 0.0132 - mean_absolute_error: 0.0434\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 757us/sample - loss: 0.0076 - mean_absolute_error: 0.0354\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 737us/sample - loss: 0.0154 - mean_absolute_error: 0.0399\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0212 - mean_absolute_error: 0.0368\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 790us/sample - loss: 0.0273 - mean_absolute_error: 0.0405\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.0306 - mean_absolute_error: 0.0377\n",
      "110/110 [==============================] - 0s 577us/sample - loss: 1.0521 - mean_absolute_error: 0.6971\n",
      "220/220 [==============================] - 0s 194us/sample - loss: 0.0091 - mean_absolute_error: 0.0335\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_225 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.9811 - mean_absolute_error: 0.7137\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 726us/sample - loss: 0.8077 - mean_absolute_error: 0.6680\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.4931 - mean_absolute_error: 0.5073\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.3273 - mean_absolute_error: 0.4435\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 737us/sample - loss: 0.1707 - mean_absolute_error: 0.2912\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 747us/sample - loss: 0.1707 - mean_absolute_error: 0.2611\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.1537 - mean_absolute_error: 0.2468\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 747us/sample - loss: 0.0764 - mean_absolute_error: 0.1775\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 737us/sample - loss: 0.0714 - mean_absolute_error: 0.1600\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0384 - mean_absolute_error: 0.1252\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.0466 - mean_absolute_error: 0.1068\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 754us/sample - loss: 0.0346 - mean_absolute_error: 0.0990\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 749us/sample - loss: 0.0799 - mean_absolute_error: 0.1295\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.0217 - mean_absolute_error: 0.1014\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 735us/sample - loss: 0.0378 - mean_absolute_error: 0.1218\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.0192 - mean_absolute_error: 0.0821\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0313 - mean_absolute_error: 0.0869\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.0167 - mean_absolute_error: 0.0686\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 746us/sample - loss: 0.0480 - mean_absolute_error: 0.0947\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0180 - mean_absolute_error: 0.0798\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.0303 - mean_absolute_error: 0.0989\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0145 - mean_absolute_error: 0.0685\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 753us/sample - loss: 0.0188 - mean_absolute_error: 0.0729\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0131 - mean_absolute_error: 0.0666\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0191 - mean_absolute_error: 0.0691\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 757us/sample - loss: 0.0233 - mean_absolute_error: 0.0711\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 753us/sample - loss: 0.0701 - mean_absolute_error: 0.1072\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.0837 - mean_absolute_error: 0.1470\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 736us/sample - loss: 0.2366 - mean_absolute_error: 0.2512\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.1709 - mean_absolute_error: 0.1846\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 746us/sample - loss: 0.0952 - mean_absolute_error: 0.1764\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.1108 - mean_absolute_error: 0.1856\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 755us/sample - loss: 0.1335 - mean_absolute_error: 0.1698\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0959 - mean_absolute_error: 0.1426\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0505 - mean_absolute_error: 0.1301\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 782us/sample - loss: 0.0462 - mean_absolute_error: 0.1139\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 932us/sample - loss: 0.0358 - mean_absolute_error: 0.1189\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 754us/sample - loss: 0.0296 - mean_absolute_error: 0.0992\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0285 - mean_absolute_error: 0.0815\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.0296 - mean_absolute_error: 0.0828\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0341 - mean_absolute_error: 0.0804\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.0429 - mean_absolute_error: 0.0806\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 746us/sample - loss: 0.0376 - mean_absolute_error: 0.0796\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 756us/sample - loss: 0.0157 - mean_absolute_error: 0.0745\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 747us/sample - loss: 0.0140 - mean_absolute_error: 0.0747\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.0119 - mean_absolute_error: 0.0623\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0238 - mean_absolute_error: 0.0753\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 754us/sample - loss: 0.0146 - mean_absolute_error: 0.0692\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 754us/sample - loss: 0.0282 - mean_absolute_error: 0.0826\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.0116 - mean_absolute_error: 0.0523\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 747us/sample - loss: 0.0199 - mean_absolute_error: 0.0605\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 737us/sample - loss: 0.0113 - mean_absolute_error: 0.0539\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.0231 - mean_absolute_error: 0.0557\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 753us/sample - loss: 0.0233 - mean_absolute_error: 0.0667\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 757us/sample - loss: 0.0226 - mean_absolute_error: 0.0543\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 737us/sample - loss: 0.0078 - mean_absolute_error: 0.0470\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.0067 - mean_absolute_error: 0.0370\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 764us/sample - loss: 0.0048 - mean_absolute_error: 0.0370\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0035 - mean_absolute_error: 0.0299\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0029 - mean_absolute_error: 0.0299\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0031 - mean_absolute_error: 0.0264\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.0046 - mean_absolute_error: 0.0260\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0036 - mean_absolute_error: 0.0268\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 751us/sample - loss: 0.0062 - mean_absolute_error: 0.0349\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.0056 - mean_absolute_error: 0.0348\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 739us/sample - loss: 0.0070 - mean_absolute_error: 0.0356\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0074 - mean_absolute_error: 0.0362\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0116 - mean_absolute_error: 0.0441\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 751us/sample - loss: 0.0080 - mean_absolute_error: 0.0414\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 755us/sample - loss: 0.0124 - mean_absolute_error: 0.0506\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0126 - mean_absolute_error: 0.0501\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0172 - mean_absolute_error: 0.0587\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0107 - mean_absolute_error: 0.0500\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 737us/sample - loss: 0.0184 - mean_absolute_error: 0.0562\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 740us/sample - loss: 0.0131 - mean_absolute_error: 0.0592\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 733us/sample - loss: 0.0196 - mean_absolute_error: 0.0672\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 751us/sample - loss: 0.0210 - mean_absolute_error: 0.0606\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 749us/sample - loss: 0.0286 - mean_absolute_error: 0.0706\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 753us/sample - loss: 0.0109 - mean_absolute_error: 0.0554\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.0077 - mean_absolute_error: 0.0523\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.0057 - mean_absolute_error: 0.0456\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.0094 - mean_absolute_error: 0.0522\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.0058 - mean_absolute_error: 0.0465\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.0124 - mean_absolute_error: 0.0604\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0115 - mean_absolute_error: 0.0588\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 746us/sample - loss: 0.0201 - mean_absolute_error: 0.0733\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 738us/sample - loss: 0.0142 - mean_absolute_error: 0.0694\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 731us/sample - loss: 0.0258 - mean_absolute_error: 0.0864\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 753us/sample - loss: 0.0276 - mean_absolute_error: 0.0806\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 750us/sample - loss: 0.0523 - mean_absolute_error: 0.1088\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 743us/sample - loss: 0.0305 - mean_absolute_error: 0.0856\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0378 - mean_absolute_error: 0.0950\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.0183 - mean_absolute_error: 0.0701\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 757us/sample - loss: 0.0186 - mean_absolute_error: 0.0770\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0200 - mean_absolute_error: 0.0738\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.0370 - mean_absolute_error: 0.0853\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 748us/sample - loss: 0.0254 - mean_absolute_error: 0.0832\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 726us/sample - loss: 0.0503 - mean_absolute_error: 0.0972\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0153 - mean_absolute_error: 0.0718\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 741us/sample - loss: 0.0142 - mean_absolute_error: 0.0762\n",
      "110/110 [==============================] - 0s 591us/sample - loss: 1.6457 - mean_absolute_error: 0.7883\n",
      "220/220 [==============================] - 0s 192us/sample - loss: 0.0113 - mean_absolute_error: 0.0645\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_230 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5354 - mean_absolute_error: 0.8999\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 719us/sample - loss: 1.2086 - mean_absolute_error: 0.7756\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 763us/sample - loss: 0.6836 - mean_absolute_error: 0.5924\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 758us/sample - loss: 0.3178 - mean_absolute_error: 0.4257\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 745us/sample - loss: 0.5513 - mean_absolute_error: 0.3920\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 744us/sample - loss: 0.4966 - mean_absolute_error: 0.3959\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 752us/sample - loss: 0.1598 - mean_absolute_error: 0.2603\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 827us/sample - loss: 0.1754 - mean_absolute_error: 0.2658\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 849us/sample - loss: 0.2940 - mean_absolute_error: 0.2516\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 804us/sample - loss: 0.1464 - mean_absolute_error: 0.2344\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 843us/sample - loss: 0.1555 - mean_absolute_error: 0.2477\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 837us/sample - loss: 0.1460 - mean_absolute_error: 0.2301\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 821us/sample - loss: 0.0645 - mean_absolute_error: 0.1619\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 836us/sample - loss: 0.0430 - mean_absolute_error: 0.1321\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 807us/sample - loss: 0.0269 - mean_absolute_error: 0.0936\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 782us/sample - loss: 0.0199 - mean_absolute_error: 0.0808\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 863us/sample - loss: 0.0292 - mean_absolute_error: 0.0856\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 819us/sample - loss: 0.0357 - mean_absolute_error: 0.0802\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 853us/sample - loss: 0.0975 - mean_absolute_error: 0.1145\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 776us/sample - loss: 0.0279 - mean_absolute_error: 0.1013\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 802us/sample - loss: 0.0452 - mean_absolute_error: 0.1048\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 861us/sample - loss: 0.0306 - mean_absolute_error: 0.0999\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 760us/sample - loss: 0.0584 - mean_absolute_error: 0.1292\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 893us/sample - loss: 0.0654 - mean_absolute_error: 0.1451\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 862us/sample - loss: 0.1079 - mean_absolute_error: 0.1991\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 837us/sample - loss: 0.0491 - mean_absolute_error: 0.1341\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 821us/sample - loss: 0.0944 - mean_absolute_error: 0.1569\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 838us/sample - loss: 0.0248 - mean_absolute_error: 0.0990\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 864us/sample - loss: 0.0824 - mean_absolute_error: 0.1208\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 827us/sample - loss: 0.0530 - mean_absolute_error: 0.1148\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 801us/sample - loss: 0.1661 - mean_absolute_error: 0.1824\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 847us/sample - loss: 0.0788 - mean_absolute_error: 0.1300\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 830us/sample - loss: 0.2507 - mean_absolute_error: 0.1638\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 832us/sample - loss: 0.1763 - mean_absolute_error: 0.1544\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 810us/sample - loss: 0.0868 - mean_absolute_error: 0.1298\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 812us/sample - loss: 0.2003 - mean_absolute_error: 0.1681\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 829us/sample - loss: 0.2805 - mean_absolute_error: 0.2466\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 799us/sample - loss: 0.1752 - mean_absolute_error: 0.2079\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 791us/sample - loss: 0.1619 - mean_absolute_error: 0.2168\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 861us/sample - loss: 0.2832 - mean_absolute_error: 0.2145\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 802us/sample - loss: 0.0766 - mean_absolute_error: 0.1685\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 817us/sample - loss: 0.2233 - mean_absolute_error: 0.1865\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 818us/sample - loss: 0.3785 - mean_absolute_error: 0.2621\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 841us/sample - loss: 0.1846 - mean_absolute_error: 0.2439\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 819us/sample - loss: 0.5749 - mean_absolute_error: 0.2976\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 862us/sample - loss: 0.1931 - mean_absolute_error: 0.2366\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 787us/sample - loss: 0.1213 - mean_absolute_error: 0.2156\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.2142 - mean_absolute_error: 0.2552\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 729us/sample - loss: 0.1282 - mean_absolute_error: 0.1869\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 811us/sample - loss: 0.2599 - mean_absolute_error: 0.2280\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 775us/sample - loss: 0.2794 - mean_absolute_error: 0.1889\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 749us/sample - loss: 0.0744 - mean_absolute_error: 0.1473\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 773us/sample - loss: 0.1976 - mean_absolute_error: 0.1736\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 813us/sample - loss: 0.3095 - mean_absolute_error: 0.1960\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 816us/sample - loss: 0.3031 - mean_absolute_error: 0.1914\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 809us/sample - loss: 0.2747 - mean_absolute_error: 0.2724\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 783us/sample - loss: 0.1175 - mean_absolute_error: 0.1937\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 836us/sample - loss: 0.2096 - mean_absolute_error: 0.2142\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 885us/sample - loss: 0.0827 - mean_absolute_error: 0.1441\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 787us/sample - loss: 0.1912 - mean_absolute_error: 0.1236\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 832us/sample - loss: 0.2299 - mean_absolute_error: 0.1277\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 834us/sample - loss: 0.1771 - mean_absolute_error: 0.1036\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 833us/sample - loss: 0.0757 - mean_absolute_error: 0.0848\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 795us/sample - loss: 0.3041 - mean_absolute_error: 0.1187\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 856us/sample - loss: 0.2946 - mean_absolute_error: 0.1710\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 790us/sample - loss: 0.1009 - mean_absolute_error: 0.1444\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 800us/sample - loss: 0.3152 - mean_absolute_error: 0.1720\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 819us/sample - loss: 0.3090 - mean_absolute_error: 0.1634\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 777us/sample - loss: 0.2234 - mean_absolute_error: 0.1165\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 812us/sample - loss: 0.2156 - mean_absolute_error: 0.0882\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 816us/sample - loss: 0.2001 - mean_absolute_error: 0.0669\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 793us/sample - loss: 0.1562 - mean_absolute_error: 0.0609\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 784us/sample - loss: 0.0448 - mean_absolute_error: 0.0514\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 797us/sample - loss: 0.1775 - mean_absolute_error: 0.0585\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 782us/sample - loss: 0.1569 - mean_absolute_error: 0.0489\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 776us/sample - loss: 0.0563 - mean_absolute_error: 0.0354\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 780us/sample - loss: 0.1591 - mean_absolute_error: 0.0568\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 788us/sample - loss: 0.2020 - mean_absolute_error: 0.0726\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 848us/sample - loss: 0.2000 - mean_absolute_error: 0.0610\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 833us/sample - loss: 0.1785 - mean_absolute_error: 0.0500\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 821us/sample - loss: 0.1457 - mean_absolute_error: 0.0461\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 834us/sample - loss: 0.0775 - mean_absolute_error: 0.0362\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 835us/sample - loss: 0.0049 - mean_absolute_error: 0.0191\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 809us/sample - loss: 0.0519 - mean_absolute_error: 0.0276\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 802us/sample - loss: 0.0444 - mean_absolute_error: 0.0278\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 812us/sample - loss: 0.0265 - mean_absolute_error: 0.0200\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 794us/sample - loss: 0.0083 - mean_absolute_error: 0.0136\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 840us/sample - loss: 0.0017 - mean_absolute_error: 0.0099\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 850us/sample - loss: 0.0031 - mean_absolute_error: 0.0092\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 843us/sample - loss: 0.0012 - mean_absolute_error: 0.0070\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 826us/sample - loss: 1.3064e-04 - mean_absolute_error: 0.0050\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 805us/sample - loss: 3.8407e-05 - mean_absolute_error: 0.0039\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 861us/sample - loss: 3.7446e-05 - mean_absolute_error: 0.0035\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 860us/sample - loss: 2.9209e-05 - mean_absolute_error: 0.0031\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 794us/sample - loss: 1.9801e-05 - mean_absolute_error: 0.0030\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 829us/sample - loss: 2.1518e-05 - mean_absolute_error: 0.0023\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 821us/sample - loss: 1.8130e-05 - mean_absolute_error: 0.0019\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 800us/sample - loss: 1.0441e-05 - mean_absolute_error: 0.0017\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 805us/sample - loss: 7.1396e-06 - mean_absolute_error: 0.0014\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 801us/sample - loss: 8.6661e-06 - mean_absolute_error: 0.0014\n",
      "110/110 [==============================] - 0s 662us/sample - loss: 0.7866 - mean_absolute_error: 0.6383\n",
      "220/220 [==============================] - 0s 206us/sample - loss: 7.6081e-06 - mean_absolute_error: 0.0014\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_235 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5406 - mean_absolute_error: 0.9416\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 590us/sample - loss: 1.1565 - mean_absolute_error: 0.7087\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 633us/sample - loss: 0.7299 - mean_absolute_error: 0.5852\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 640us/sample - loss: 0.2705 - mean_absolute_error: 0.3830\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 608us/sample - loss: 0.2424 - mean_absolute_error: 0.3243\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 629us/sample - loss: 0.2496 - mean_absolute_error: 0.2877\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 612us/sample - loss: 0.4616 - mean_absolute_error: 0.2790\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 663us/sample - loss: 0.2589 - mean_absolute_error: 0.2726\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 618us/sample - loss: 0.1313 - mean_absolute_error: 0.2478\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 603us/sample - loss: 0.2793 - mean_absolute_error: 0.2285\n",
      "110/110 [==============================] - 0s 637us/sample - loss: 0.9979 - mean_absolute_error: 0.6772\n",
      "220/220 [==============================] - 0s 175us/sample - loss: 0.1516 - mean_absolute_error: 0.1767\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_240 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.2775 - mean_absolute_error: 0.8829\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 540us/sample - loss: 0.6482 - mean_absolute_error: 0.5557\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 569us/sample - loss: 0.4641 - mean_absolute_error: 0.4869\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 566us/sample - loss: 0.3122 - mean_absolute_error: 0.3683\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 644us/sample - loss: 0.1689 - mean_absolute_error: 0.2829\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 645us/sample - loss: 0.1264 - mean_absolute_error: 0.2443\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 627us/sample - loss: 0.1113 - mean_absolute_error: 0.2263\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 596us/sample - loss: 0.0811 - mean_absolute_error: 0.1957\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 610us/sample - loss: 0.1020 - mean_absolute_error: 0.1891\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 602us/sample - loss: 0.0491 - mean_absolute_error: 0.1522\n",
      "110/110 [==============================] - 0s 559us/sample - loss: 1.6110 - mean_absolute_error: 0.7453\n",
      "220/220 [==============================] - 0s 165us/sample - loss: 0.0216 - mean_absolute_error: 0.1066\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_245 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.7166 - mean_absolute_error: 0.9561\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 722us/sample - loss: 0.8706 - mean_absolute_error: 0.6912\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 742us/sample - loss: 0.6778 - mean_absolute_error: 0.5668\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 678us/sample - loss: 0.3631 - mean_absolute_error: 0.3612\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 722us/sample - loss: 0.4271 - mean_absolute_error: 0.3178\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 699us/sample - loss: 0.1730 - mean_absolute_error: 0.2657\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 694us/sample - loss: 0.1894 - mean_absolute_error: 0.2232\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 728us/sample - loss: 0.1010 - mean_absolute_error: 0.1890\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 704us/sample - loss: 0.1334 - mean_absolute_error: 0.2348\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 702us/sample - loss: 0.1140 - mean_absolute_error: 0.1933\n",
      "110/110 [==============================] - 0s 601us/sample - loss: 0.5423 - mean_absolute_error: 0.5454\n",
      "220/220 [==============================] - 0s 188us/sample - loss: 0.1218 - mean_absolute_error: 0.2051\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_250 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4251 - mean_absolute_error: 0.7965\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 628us/sample - loss: 0.9517 - mean_absolute_error: 0.6568\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 730us/sample - loss: 0.6131 - mean_absolute_error: 0.5291\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 689us/sample - loss: 0.3480 - mean_absolute_error: 0.3889\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 669us/sample - loss: 0.2326 - mean_absolute_error: 0.3009\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 691us/sample - loss: 0.3130 - mean_absolute_error: 0.3009\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 633us/sample - loss: 0.1524 - mean_absolute_error: 0.2537\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 0.1140 - mean_absolute_error: 0.2203\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 616us/sample - loss: 0.0597 - mean_absolute_error: 0.1583\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 684us/sample - loss: 0.0462 - mean_absolute_error: 0.1159\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 694us/sample - loss: 0.0562 - mean_absolute_error: 0.1327\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 634us/sample - loss: 0.0432 - mean_absolute_error: 0.1274\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 634us/sample - loss: 0.0734 - mean_absolute_error: 0.1526\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 620us/sample - loss: 0.0320 - mean_absolute_error: 0.1140\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 629us/sample - loss: 0.0858 - mean_absolute_error: 0.1421\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 608us/sample - loss: 0.0770 - mean_absolute_error: 0.1656\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 620us/sample - loss: 0.0562 - mean_absolute_error: 0.1604\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 634us/sample - loss: 0.0421 - mean_absolute_error: 0.1440\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 628us/sample - loss: 0.0187 - mean_absolute_error: 0.0982\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 629us/sample - loss: 0.0129 - mean_absolute_error: 0.0819\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 0.0112 - mean_absolute_error: 0.0704\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 614us/sample - loss: 0.0193 - mean_absolute_error: 0.0747\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 618us/sample - loss: 0.0337 - mean_absolute_error: 0.0979\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 634us/sample - loss: 0.0163 - mean_absolute_error: 0.0839\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 614us/sample - loss: 0.0213 - mean_absolute_error: 0.0911\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 631us/sample - loss: 0.0098 - mean_absolute_error: 0.0698\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 0.0056 - mean_absolute_error: 0.0575\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 681us/sample - loss: 0.0045 - mean_absolute_error: 0.0518\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 629us/sample - loss: 0.0036 - mean_absolute_error: 0.0466\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 622us/sample - loss: 0.0040 - mean_absolute_error: 0.0393\n",
      "110/110 [==============================] - 0s 559us/sample - loss: 0.9794 - mean_absolute_error: 0.6842\n",
      "220/220 [==============================] - 0s 184us/sample - loss: 0.0041 - mean_absolute_error: 0.0448\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_255 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5310 - mean_absolute_error: 0.9205\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 608us/sample - loss: 0.6764 - mean_absolute_error: 0.6176\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 616us/sample - loss: 0.3700 - mean_absolute_error: 0.4220\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 621us/sample - loss: 0.1277 - mean_absolute_error: 0.2719\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 625us/sample - loss: 0.1004 - mean_absolute_error: 0.2256\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 586us/sample - loss: 0.0729 - mean_absolute_error: 0.1914\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 568us/sample - loss: 0.0893 - mean_absolute_error: 0.2095\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 581us/sample - loss: 0.0548 - mean_absolute_error: 0.1722\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 586us/sample - loss: 0.0700 - mean_absolute_error: 0.1773\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 644us/sample - loss: 0.0302 - mean_absolute_error: 0.1185\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0301 - mean_absolute_error: 0.0979\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 566us/sample - loss: 0.0182 - mean_absolute_error: 0.0822\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 569us/sample - loss: 0.0167 - mean_absolute_error: 0.0745\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 566us/sample - loss: 0.0156 - mean_absolute_error: 0.0688\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 629us/sample - loss: 0.0217 - mean_absolute_error: 0.0829\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 678us/sample - loss: 0.0348 - mean_absolute_error: 0.1040\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 649us/sample - loss: 0.0197 - mean_absolute_error: 0.0981\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 656us/sample - loss: 0.0144 - mean_absolute_error: 0.0822\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 643us/sample - loss: 0.0132 - mean_absolute_error: 0.0799\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 636us/sample - loss: 0.0116 - mean_absolute_error: 0.0626\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 580us/sample - loss: 0.0213 - mean_absolute_error: 0.0864\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 567us/sample - loss: 0.0201 - mean_absolute_error: 0.1079\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.0130 - mean_absolute_error: 0.0878\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 569us/sample - loss: 0.0139 - mean_absolute_error: 0.0854\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 627us/sample - loss: 0.0121 - mean_absolute_error: 0.0780\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 637us/sample - loss: 0.0134 - mean_absolute_error: 0.0808\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 562us/sample - loss: 0.0129 - mean_absolute_error: 0.0774\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 570us/sample - loss: 0.0171 - mean_absolute_error: 0.0751\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 569us/sample - loss: 0.0154 - mean_absolute_error: 0.0692\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 577us/sample - loss: 0.0241 - mean_absolute_error: 0.0901\n",
      "110/110 [==============================] - 0s 585us/sample - loss: 1.6266 - mean_absolute_error: 0.7739\n",
      "220/220 [==============================] - 0s 196us/sample - loss: 0.0183 - mean_absolute_error: 0.0767\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_260 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.7276 - mean_absolute_error: 0.9674\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 624us/sample - loss: 0.8374 - mean_absolute_error: 0.6626\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 603us/sample - loss: 0.6866 - mean_absolute_error: 0.4904\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 643us/sample - loss: 0.5807 - mean_absolute_error: 0.4529\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 675us/sample - loss: 0.2161 - mean_absolute_error: 0.2759\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 659us/sample - loss: 0.1056 - mean_absolute_error: 0.2142\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 654us/sample - loss: 0.1235 - mean_absolute_error: 0.2207\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 640us/sample - loss: 0.0799 - mean_absolute_error: 0.1758\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 618us/sample - loss: 0.0737 - mean_absolute_error: 0.1763\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 596us/sample - loss: 0.0495 - mean_absolute_error: 0.1497\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 651us/sample - loss: 0.0401 - mean_absolute_error: 0.1311\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 700us/sample - loss: 0.0335 - mean_absolute_error: 0.1234\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 675us/sample - loss: 0.0271 - mean_absolute_error: 0.1025\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 638us/sample - loss: 0.0206 - mean_absolute_error: 0.0947\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 633us/sample - loss: 0.0333 - mean_absolute_error: 0.1102\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 663us/sample - loss: 0.0182 - mean_absolute_error: 0.0957\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 623us/sample - loss: 0.0241 - mean_absolute_error: 0.1093\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 650us/sample - loss: 0.0210 - mean_absolute_error: 0.1062\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 642us/sample - loss: 0.0229 - mean_absolute_error: 0.1086\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 644us/sample - loss: 0.0160 - mean_absolute_error: 0.0951\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 0.0178 - mean_absolute_error: 0.0931\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 641us/sample - loss: 0.0257 - mean_absolute_error: 0.0849\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 631us/sample - loss: 0.0553 - mean_absolute_error: 0.1121\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 628us/sample - loss: 0.0743 - mean_absolute_error: 0.1498\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 648us/sample - loss: 0.0805 - mean_absolute_error: 0.1467\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 637us/sample - loss: 0.0611 - mean_absolute_error: 0.1306\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 648us/sample - loss: 0.1366 - mean_absolute_error: 0.1388\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 657us/sample - loss: 0.0410 - mean_absolute_error: 0.1236\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 605us/sample - loss: 0.1009 - mean_absolute_error: 0.1685\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 641us/sample - loss: 0.1330 - mean_absolute_error: 0.1545\n",
      "110/110 [==============================] - 0s 607us/sample - loss: 0.7585 - mean_absolute_error: 0.5975\n",
      "220/220 [==============================] - 0s 177us/sample - loss: 0.0486 - mean_absolute_error: 0.1175\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_265 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5822 - mean_absolute_error: 0.8863\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 570us/sample - loss: 1.2229 - mean_absolute_error: 0.7632\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 597us/sample - loss: 0.6240 - mean_absolute_error: 0.5588\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 661us/sample - loss: 0.4574 - mean_absolute_error: 0.3777\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 662us/sample - loss: 0.4583 - mean_absolute_error: 0.3737\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 579us/sample - loss: 0.1377 - mean_absolute_error: 0.2483\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 583us/sample - loss: 0.0626 - mean_absolute_error: 0.1774\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 645us/sample - loss: 0.0430 - mean_absolute_error: 0.1467\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 675us/sample - loss: 0.0343 - mean_absolute_error: 0.1310\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 593us/sample - loss: 0.0378 - mean_absolute_error: 0.1186\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 571us/sample - loss: 0.0280 - mean_absolute_error: 0.0985\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 572us/sample - loss: 0.0289 - mean_absolute_error: 0.0843\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 570us/sample - loss: 0.0262 - mean_absolute_error: 0.0854\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 0.0355 - mean_absolute_error: 0.0960\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 0.0162 - mean_absolute_error: 0.0820\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 575us/sample - loss: 0.0093 - mean_absolute_error: 0.0638\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 567us/sample - loss: 0.0109 - mean_absolute_error: 0.0585\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.0171 - mean_absolute_error: 0.0697\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 571us/sample - loss: 0.0192 - mean_absolute_error: 0.0671\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 568us/sample - loss: 0.0147 - mean_absolute_error: 0.0688\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 572us/sample - loss: 0.0225 - mean_absolute_error: 0.0806\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 570us/sample - loss: 0.0132 - mean_absolute_error: 0.0607\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 567us/sample - loss: 0.0159 - mean_absolute_error: 0.0685\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 567us/sample - loss: 0.0087 - mean_absolute_error: 0.0580\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.0085 - mean_absolute_error: 0.0562\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 556us/sample - loss: 0.0050 - mean_absolute_error: 0.0412\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 573us/sample - loss: 0.0044 - mean_absolute_error: 0.0348\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 573us/sample - loss: 0.0055 - mean_absolute_error: 0.0324\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 567us/sample - loss: 0.0119 - mean_absolute_error: 0.0493\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 564us/sample - loss: 0.0097 - mean_absolute_error: 0.0526\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 569us/sample - loss: 0.0166 - mean_absolute_error: 0.0612\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 571us/sample - loss: 0.0146 - mean_absolute_error: 0.0565\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 635us/sample - loss: 0.0403 - mean_absolute_error: 0.0811\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 634us/sample - loss: 0.0209 - mean_absolute_error: 0.0806\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 575us/sample - loss: 0.0749 - mean_absolute_error: 0.0953\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.1216 - mean_absolute_error: 0.1422\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 611us/sample - loss: 0.3018 - mean_absolute_error: 0.2693\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 626us/sample - loss: 0.1312 - mean_absolute_error: 0.2115\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 604us/sample - loss: 0.1276 - mean_absolute_error: 0.1978\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.1960 - mean_absolute_error: 0.1616\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 566us/sample - loss: 0.0774 - mean_absolute_error: 0.1635\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 575us/sample - loss: 0.2165 - mean_absolute_error: 0.1974\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 661us/sample - loss: 0.1064 - mean_absolute_error: 0.1876\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 0.2331 - mean_absolute_error: 0.1418\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 575us/sample - loss: 0.1989 - mean_absolute_error: 0.1527\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 594us/sample - loss: 0.1061 - mean_absolute_error: 0.1486\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 585us/sample - loss: 0.3964 - mean_absolute_error: 0.2265\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 633us/sample - loss: 0.3716 - mean_absolute_error: 0.2900\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 599us/sample - loss: 0.2196 - mean_absolute_error: 0.2335\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 598us/sample - loss: 0.2344 - mean_absolute_error: 0.2304\n",
      "110/110 [==============================] - 0s 563us/sample - loss: 1.0466 - mean_absolute_error: 0.7079\n",
      "220/220 [==============================] - 0s 168us/sample - loss: 0.1583 - mean_absolute_error: 0.1617\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_270 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.0873 - mean_absolute_error: 0.7676\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 546us/sample - loss: 0.6129 - mean_absolute_error: 0.5562\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 569us/sample - loss: 0.2868 - mean_absolute_error: 0.3833\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 561us/sample - loss: 0.2239 - mean_absolute_error: 0.3332\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 623us/sample - loss: 0.2061 - mean_absolute_error: 0.3204\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 647us/sample - loss: 0.1525 - mean_absolute_error: 0.2762\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 643us/sample - loss: 0.1589 - mean_absolute_error: 0.2025\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 641us/sample - loss: 0.0647 - mean_absolute_error: 0.1528\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 583us/sample - loss: 0.0252 - mean_absolute_error: 0.1164\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 602us/sample - loss: 0.0152 - mean_absolute_error: 0.0885\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 603us/sample - loss: 0.0109 - mean_absolute_error: 0.0721\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 670us/sample - loss: 0.0099 - mean_absolute_error: 0.0710\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 611us/sample - loss: 0.0108 - mean_absolute_error: 0.0696\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 0.0150 - mean_absolute_error: 0.0753\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 617us/sample - loss: 0.0132 - mean_absolute_error: 0.0679\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 641us/sample - loss: 0.0218 - mean_absolute_error: 0.0837\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 562us/sample - loss: 0.0155 - mean_absolute_error: 0.0882\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 560us/sample - loss: 0.0363 - mean_absolute_error: 0.1086\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 599us/sample - loss: 0.0582 - mean_absolute_error: 0.1090\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 570us/sample - loss: 0.0570 - mean_absolute_error: 0.1389\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 610us/sample - loss: 0.0232 - mean_absolute_error: 0.1095\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 657us/sample - loss: 0.0304 - mean_absolute_error: 0.1179\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 617us/sample - loss: 0.0261 - mean_absolute_error: 0.1077\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 601us/sample - loss: 0.0298 - mean_absolute_error: 0.1157\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 0.0238 - mean_absolute_error: 0.1037\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 635us/sample - loss: 0.0545 - mean_absolute_error: 0.1265\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 637us/sample - loss: 0.0597 - mean_absolute_error: 0.1180\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 609us/sample - loss: 0.0367 - mean_absolute_error: 0.1066\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 629us/sample - loss: 0.0200 - mean_absolute_error: 0.0868\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 633us/sample - loss: 0.0147 - mean_absolute_error: 0.0745\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 615us/sample - loss: 0.0183 - mean_absolute_error: 0.0745\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 635us/sample - loss: 0.0230 - mean_absolute_error: 0.0729\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 585us/sample - loss: 0.0070 - mean_absolute_error: 0.0579\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 643us/sample - loss: 0.0099 - mean_absolute_error: 0.0493\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 628us/sample - loss: 0.0137 - mean_absolute_error: 0.0501\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 642us/sample - loss: 0.0099 - mean_absolute_error: 0.0507\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 638us/sample - loss: 0.0085 - mean_absolute_error: 0.0561\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 604us/sample - loss: 0.0132 - mean_absolute_error: 0.0648\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 653us/sample - loss: 0.0087 - mean_absolute_error: 0.0684\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 605us/sample - loss: 0.0205 - mean_absolute_error: 0.0908\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 637us/sample - loss: 0.0184 - mean_absolute_error: 0.0956\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 650us/sample - loss: 0.0316 - mean_absolute_error: 0.1197\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 0.0193 - mean_absolute_error: 0.0936\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 620us/sample - loss: 0.0301 - mean_absolute_error: 0.1046\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 574us/sample - loss: 0.0311 - mean_absolute_error: 0.1001\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0932 - mean_absolute_error: 0.1836\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 557us/sample - loss: 0.0361 - mean_absolute_error: 0.1476\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 567us/sample - loss: 0.0473 - mean_absolute_error: 0.1485\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 647us/sample - loss: 0.0257 - mean_absolute_error: 0.1096\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 635us/sample - loss: 0.0162 - mean_absolute_error: 0.0815\n",
      "110/110 [==============================] - 0s 646us/sample - loss: 1.6411 - mean_absolute_error: 0.7725\n",
      "220/220 [==============================] - 0s 176us/sample - loss: 0.0070 - mean_absolute_error: 0.0515\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_275 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5704 - mean_absolute_error: 0.8816\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 636us/sample - loss: 0.8865 - mean_absolute_error: 0.6468\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 595us/sample - loss: 0.4006 - mean_absolute_error: 0.4558\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 688us/sample - loss: 0.7164 - mean_absolute_error: 0.5761\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 636us/sample - loss: 0.3747 - mean_absolute_error: 0.4307\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 0.4114 - mean_absolute_error: 0.3962\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 598us/sample - loss: 0.2711 - mean_absolute_error: 0.3026\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 635us/sample - loss: 0.2928 - mean_absolute_error: 0.2951\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 615us/sample - loss: 0.1687 - mean_absolute_error: 0.2275\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 566us/sample - loss: 0.1500 - mean_absolute_error: 0.2379\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 625us/sample - loss: 0.1352 - mean_absolute_error: 0.2299s - loss: 0.1793 - mean_absolute_error: 0.23\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 587us/sample - loss: 0.0987 - mean_absolute_error: 0.2066\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 603us/sample - loss: 0.0543 - mean_absolute_error: 0.1694\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 606us/sample - loss: 0.0412 - mean_absolute_error: 0.1228\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 587us/sample - loss: 0.0390 - mean_absolute_error: 0.1258\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.0394 - mean_absolute_error: 0.1042\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 568us/sample - loss: 0.0278 - mean_absolute_error: 0.0876\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 577us/sample - loss: 0.0359 - mean_absolute_error: 0.0991\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 574us/sample - loss: 0.0361 - mean_absolute_error: 0.1075\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 571us/sample - loss: 0.0502 - mean_absolute_error: 0.1324\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 571us/sample - loss: 0.0337 - mean_absolute_error: 0.1252\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 573us/sample - loss: 0.0518 - mean_absolute_error: 0.1260\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 570us/sample - loss: 0.0358 - mean_absolute_error: 0.1189\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 566us/sample - loss: 0.0926 - mean_absolute_error: 0.1222\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 564us/sample - loss: 0.0475 - mean_absolute_error: 0.1342\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 566us/sample - loss: 0.0917 - mean_absolute_error: 0.1524\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 561us/sample - loss: 0.1429 - mean_absolute_error: 0.1836\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 577us/sample - loss: 0.3855 - mean_absolute_error: 0.2995\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 562us/sample - loss: 0.1178 - mean_absolute_error: 0.2167\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 559us/sample - loss: 0.0587 - mean_absolute_error: 0.1565\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 653us/sample - loss: 0.0375 - mean_absolute_error: 0.1246\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 655us/sample - loss: 0.1143 - mean_absolute_error: 0.1107\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 625us/sample - loss: 0.0249 - mean_absolute_error: 0.1029\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 668us/sample - loss: 0.0188 - mean_absolute_error: 0.0902\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 618us/sample - loss: 0.0103 - mean_absolute_error: 0.0726\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 605us/sample - loss: 0.0105 - mean_absolute_error: 0.0627\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 678us/sample - loss: 0.0103 - mean_absolute_error: 0.0584\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 634us/sample - loss: 0.0123 - mean_absolute_error: 0.0529\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 619us/sample - loss: 0.0074 - mean_absolute_error: 0.0407\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 624us/sample - loss: 0.0077 - mean_absolute_error: 0.0413\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 653us/sample - loss: 0.0065 - mean_absolute_error: 0.0427\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 597us/sample - loss: 0.0084 - mean_absolute_error: 0.0479\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 612us/sample - loss: 0.0206 - mean_absolute_error: 0.0583\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 659us/sample - loss: 0.0452 - mean_absolute_error: 0.0784\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 576us/sample - loss: 0.0183 - mean_absolute_error: 0.0875\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.0629 - mean_absolute_error: 0.0933\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 575us/sample - loss: 0.0391 - mean_absolute_error: 0.0840\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.1216 - mean_absolute_error: 0.0730\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 663us/sample - loss: 0.0791 - mean_absolute_error: 0.0972\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 647us/sample - loss: 0.1030 - mean_absolute_error: 0.1199\n",
      "110/110 [==============================] - 0s 633us/sample - loss: 0.6390 - mean_absolute_error: 0.5706\n",
      "220/220 [==============================] - 0s 180us/sample - loss: 0.0952 - mean_absolute_error: 0.1135\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_280 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5098 - mean_absolute_error: 0.9019\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 681us/sample - loss: 0.9686 - mean_absolute_error: 0.6810\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 700us/sample - loss: 0.5080 - mean_absolute_error: 0.5135\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 665us/sample - loss: 0.2814 - mean_absolute_error: 0.3744\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 652us/sample - loss: 0.3407 - mean_absolute_error: 0.2922\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 0.1065 - mean_absolute_error: 0.2083\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 662us/sample - loss: 0.2272 - mean_absolute_error: 0.2187\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 687us/sample - loss: 0.1017 - mean_absolute_error: 0.2110\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 664us/sample - loss: 0.0729 - mean_absolute_error: 0.1734\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 651us/sample - loss: 0.0703 - mean_absolute_error: 0.1422\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 611us/sample - loss: 0.0285 - mean_absolute_error: 0.1025\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 625us/sample - loss: 0.0316 - mean_absolute_error: 0.0875\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 657us/sample - loss: 0.0158 - mean_absolute_error: 0.0724\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 660us/sample - loss: 0.0279 - mean_absolute_error: 0.0717\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 653us/sample - loss: 0.0453 - mean_absolute_error: 0.0759\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 626us/sample - loss: 0.0580 - mean_absolute_error: 0.1013\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 0.0413 - mean_absolute_error: 0.1068\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 644us/sample - loss: 0.0219 - mean_absolute_error: 0.0924\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 652us/sample - loss: 0.0480 - mean_absolute_error: 0.0910\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 712us/sample - loss: 0.0467 - mean_absolute_error: 0.1083\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 655us/sample - loss: 0.0443 - mean_absolute_error: 0.1258\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 672us/sample - loss: 0.0626 - mean_absolute_error: 0.1324\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 675us/sample - loss: 0.0261 - mean_absolute_error: 0.1131\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 683us/sample - loss: 0.0394 - mean_absolute_error: 0.1225\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 706us/sample - loss: 0.0294 - mean_absolute_error: 0.1221\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 660us/sample - loss: 0.0873 - mean_absolute_error: 0.1411\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 677us/sample - loss: 0.0317 - mean_absolute_error: 0.1225\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 662us/sample - loss: 0.0295 - mean_absolute_error: 0.1184\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 681us/sample - loss: 0.0277 - mean_absolute_error: 0.1032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 674us/sample - loss: 0.0295 - mean_absolute_error: 0.1139\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 714us/sample - loss: 0.0316 - mean_absolute_error: 0.1152\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 692us/sample - loss: 0.0217 - mean_absolute_error: 0.0941\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 698us/sample - loss: 0.0246 - mean_absolute_error: 0.0935\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 708us/sample - loss: 0.0394 - mean_absolute_error: 0.0982\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 639us/sample - loss: 0.0725 - mean_absolute_error: 0.1352\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 628us/sample - loss: 0.0403 - mean_absolute_error: 0.1231\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 619us/sample - loss: 0.0386 - mean_absolute_error: 0.1261\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 659us/sample - loss: 0.0844 - mean_absolute_error: 0.1158\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 704us/sample - loss: 0.0472 - mean_absolute_error: 0.1404\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 0.0870 - mean_absolute_error: 0.1365\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 633us/sample - loss: 0.0869 - mean_absolute_error: 0.1040\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 703us/sample - loss: 0.0403 - mean_absolute_error: 0.0922\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 677us/sample - loss: 0.0473 - mean_absolute_error: 0.1099\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 0.1000 - mean_absolute_error: 0.1401\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 640us/sample - loss: 0.0886 - mean_absolute_error: 0.1549\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 633us/sample - loss: 0.1164 - mean_absolute_error: 0.1511\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 668us/sample - loss: 0.0771 - mean_absolute_error: 0.1797\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 693us/sample - loss: 0.1899 - mean_absolute_error: 0.1751\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 0.2140 - mean_absolute_error: 0.1873\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 0.1388 - mean_absolute_error: 0.1360\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 0.0450 - mean_absolute_error: 0.1145\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 639us/sample - loss: 0.1562 - mean_absolute_error: 0.1515\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 614us/sample - loss: 0.2691 - mean_absolute_error: 0.1860\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 626us/sample - loss: 0.2552 - mean_absolute_error: 0.1880\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 634us/sample - loss: 0.1391 - mean_absolute_error: 0.1786\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 626us/sample - loss: 0.1831 - mean_absolute_error: 0.2207\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 669us/sample - loss: 0.2480 - mean_absolute_error: 0.1882\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 726us/sample - loss: 0.0979 - mean_absolute_error: 0.1726\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 682us/sample - loss: 0.2409 - mean_absolute_error: 0.2106\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 667us/sample - loss: 0.1894 - mean_absolute_error: 0.1502\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 708us/sample - loss: 0.0828 - mean_absolute_error: 0.1281\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 688us/sample - loss: 0.0303 - mean_absolute_error: 0.0956\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 686us/sample - loss: 0.0208 - mean_absolute_error: 0.0849\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 706us/sample - loss: 0.0277 - mean_absolute_error: 0.0681\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 695us/sample - loss: 0.0998 - mean_absolute_error: 0.0931\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 690us/sample - loss: 0.0343 - mean_absolute_error: 0.0879\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 697us/sample - loss: 0.0292 - mean_absolute_error: 0.0851\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 688us/sample - loss: 0.0093 - mean_absolute_error: 0.0542\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 672us/sample - loss: 0.0064 - mean_absolute_error: 0.0423\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 670us/sample - loss: 0.0044 - mean_absolute_error: 0.0368\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 628us/sample - loss: 0.0015 - mean_absolute_error: 0.0221\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 624us/sample - loss: 5.6434e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 9.3416e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 681us/sample - loss: 2.3077e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 687us/sample - loss: 1.9492e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 5.3603e-05 - mean_absolute_error: 0.0049\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 670us/sample - loss: 8.8728e-05 - mean_absolute_error: 0.0041\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 710us/sample - loss: 4.0542e-05 - mean_absolute_error: 0.0030\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 688us/sample - loss: 3.1473e-05 - mean_absolute_error: 0.0027\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 627us/sample - loss: 3.1228e-05 - mean_absolute_error: 0.0023\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 628us/sample - loss: 2.8422e-05 - mean_absolute_error: 0.0023\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 640us/sample - loss: 3.5179e-05 - mean_absolute_error: 0.0025\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 688us/sample - loss: 4.2100e-05 - mean_absolute_error: 0.0026\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 696us/sample - loss: 7.0375e-05 - mean_absolute_error: 0.0030\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 629us/sample - loss: 5.9480e-05 - mean_absolute_error: 0.0035\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 4.5590e-05 - mean_absolute_error: 0.0035\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 660us/sample - loss: 4.1472e-05 - mean_absolute_error: 0.0030\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 706us/sample - loss: 2.2789e-05 - mean_absolute_error: 0.0022\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 692us/sample - loss: 1.1445e-05 - mean_absolute_error: 0.0017\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 679us/sample - loss: 2.3562e-05 - mean_absolute_error: 0.0017\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 663us/sample - loss: 3.5039e-05 - mean_absolute_error: 0.0021\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 698us/sample - loss: 4.5504e-05 - mean_absolute_error: 0.0024\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 664us/sample - loss: 5.9395e-05 - mean_absolute_error: 0.0033\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 765us/sample - loss: 5.6649e-05 - mean_absolute_error: 0.0034\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 707us/sample - loss: 1.0730e-04 - mean_absolute_error: 0.0039\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 672us/sample - loss: 8.2846e-05 - mean_absolute_error: 0.0043\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 658us/sample - loss: 1.2795e-04 - mean_absolute_error: 0.0049\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 658us/sample - loss: 1.5729e-04 - mean_absolute_error: 0.0043\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 677us/sample - loss: 4.0571e-04 - mean_absolute_error: 0.0045\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 727us/sample - loss: 4.7894e-04 - mean_absolute_error: 0.0066\n",
      "110/110 [==============================] - 0s 567us/sample - loss: 1.0046 - mean_absolute_error: 0.7029\n",
      "220/220 [==============================] - 0s 197us/sample - loss: 4.6054e-04 - mean_absolute_error: 0.0070\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_285 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.0215 - mean_absolute_error: 0.7503\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 601us/sample - loss: 0.5680 - mean_absolute_error: 0.5115\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 626us/sample - loss: 0.3242 - mean_absolute_error: 0.4026\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 612us/sample - loss: 0.2917 - mean_absolute_error: 0.3796\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 647us/sample - loss: 0.2138 - mean_absolute_error: 0.3279\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 664us/sample - loss: 0.2724 - mean_absolute_error: 0.3354\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 636us/sample - loss: 0.1174 - mean_absolute_error: 0.2646\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 691us/sample - loss: 0.0840 - mean_absolute_error: 0.2038\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 688us/sample - loss: 0.0641 - mean_absolute_error: 0.1626\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 666us/sample - loss: 0.0345 - mean_absolute_error: 0.1217\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 657us/sample - loss: 0.0247 - mean_absolute_error: 0.0973\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 662us/sample - loss: 0.0196 - mean_absolute_error: 0.0863\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 641us/sample - loss: 0.0164 - mean_absolute_error: 0.0887\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 642us/sample - loss: 0.0277 - mean_absolute_error: 0.0910\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 645us/sample - loss: 0.0302 - mean_absolute_error: 0.0784\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 657us/sample - loss: 0.0111 - mean_absolute_error: 0.0707\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 685us/sample - loss: 0.0144 - mean_absolute_error: 0.0806\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 678us/sample - loss: 0.0187 - mean_absolute_error: 0.0904\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 643us/sample - loss: 0.0303 - mean_absolute_error: 0.1205\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 644us/sample - loss: 0.0311 - mean_absolute_error: 0.1189\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 678us/sample - loss: 0.0466 - mean_absolute_error: 0.1401\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 685us/sample - loss: 0.0302 - mean_absolute_error: 0.1252\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 640us/sample - loss: 0.0256 - mean_absolute_error: 0.1080\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 652us/sample - loss: 0.0179 - mean_absolute_error: 0.0897\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 642us/sample - loss: 0.0314 - mean_absolute_error: 0.1010\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 649us/sample - loss: 0.0239 - mean_absolute_error: 0.1066\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 648us/sample - loss: 0.0382 - mean_absolute_error: 0.1249\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 641us/sample - loss: 0.0148 - mean_absolute_error: 0.0886\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 636us/sample - loss: 0.0111 - mean_absolute_error: 0.0736\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 669us/sample - loss: 0.0090 - mean_absolute_error: 0.0599\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 648us/sample - loss: 0.0107 - mean_absolute_error: 0.0546\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 636us/sample - loss: 0.0044 - mean_absolute_error: 0.0459\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 648us/sample - loss: 0.0039 - mean_absolute_error: 0.0408\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 645us/sample - loss: 0.0026 - mean_absolute_error: 0.0361\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 626us/sample - loss: 0.0050 - mean_absolute_error: 0.0407\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 651us/sample - loss: 0.0050 - mean_absolute_error: 0.0391\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 605us/sample - loss: 0.0094 - mean_absolute_error: 0.0480\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 645us/sample - loss: 0.0060 - mean_absolute_error: 0.0355\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 662us/sample - loss: 0.0049 - mean_absolute_error: 0.0362\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 662us/sample - loss: 0.0042 - mean_absolute_error: 0.0376\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 639us/sample - loss: 0.0058 - mean_absolute_error: 0.0401\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 648us/sample - loss: 0.0030 - mean_absolute_error: 0.0324\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 648us/sample - loss: 0.0027 - mean_absolute_error: 0.0310\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 645us/sample - loss: 0.0025 - mean_absolute_error: 0.0279\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 641us/sample - loss: 0.0044 - mean_absolute_error: 0.0328\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 645us/sample - loss: 0.0063 - mean_absolute_error: 0.0364\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 639us/sample - loss: 0.0101 - mean_absolute_error: 0.0469\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 646us/sample - loss: 0.0088 - mean_absolute_error: 0.0533\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 651us/sample - loss: 0.0187 - mean_absolute_error: 0.0703\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 656us/sample - loss: 0.0138 - mean_absolute_error: 0.0685\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 640us/sample - loss: 0.0234 - mean_absolute_error: 0.0853\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 645us/sample - loss: 0.0290 - mean_absolute_error: 0.0917\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 626us/sample - loss: 0.0404 - mean_absolute_error: 0.1057\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 636us/sample - loss: 0.0377 - mean_absolute_error: 0.0868\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 646us/sample - loss: 0.0887 - mean_absolute_error: 0.1198\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 634us/sample - loss: 0.0245 - mean_absolute_error: 0.0886\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 640us/sample - loss: 0.0251 - mean_absolute_error: 0.0986\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 634us/sample - loss: 0.0272 - mean_absolute_error: 0.0977\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 631us/sample - loss: 0.0400 - mean_absolute_error: 0.1165\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 649us/sample - loss: 0.0413 - mean_absolute_error: 0.1217\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 650us/sample - loss: 0.0210 - mean_absolute_error: 0.1023\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 644us/sample - loss: 0.0248 - mean_absolute_error: 0.1001\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 632us/sample - loss: 0.0415 - mean_absolute_error: 0.1056\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 659us/sample - loss: 0.0336 - mean_absolute_error: 0.0980\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 653us/sample - loss: 0.0625 - mean_absolute_error: 0.1173\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 665us/sample - loss: 0.0380 - mean_absolute_error: 0.1088\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 690us/sample - loss: 0.0625 - mean_absolute_error: 0.1512\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 692us/sample - loss: 0.0309 - mean_absolute_error: 0.1148\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 640us/sample - loss: 0.0450 - mean_absolute_error: 0.1248\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 651us/sample - loss: 0.0582 - mean_absolute_error: 0.1167\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 661us/sample - loss: 0.1234 - mean_absolute_error: 0.1575\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 636us/sample - loss: 0.0898 - mean_absolute_error: 0.1490\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 653us/sample - loss: 0.0813 - mean_absolute_error: 0.1824\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 654us/sample - loss: 0.0598 - mean_absolute_error: 0.1415\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 666us/sample - loss: 0.1631 - mean_absolute_error: 0.2079\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 657us/sample - loss: 0.0693 - mean_absolute_error: 0.1633\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 688us/sample - loss: 0.0683 - mean_absolute_error: 0.1545\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 628us/sample - loss: 0.0689 - mean_absolute_error: 0.1527\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 607us/sample - loss: 0.0561 - mean_absolute_error: 0.1636\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 623us/sample - loss: 0.0605 - mean_absolute_error: 0.1461\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 624us/sample - loss: 0.0360 - mean_absolute_error: 0.1102\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 669us/sample - loss: 0.0182 - mean_absolute_error: 0.0953\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 636us/sample - loss: 0.0122 - mean_absolute_error: 0.0738\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 644us/sample - loss: 0.0061 - mean_absolute_error: 0.0542\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 630us/sample - loss: 0.0051 - mean_absolute_error: 0.0445\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 631us/sample - loss: 0.0049 - mean_absolute_error: 0.0445\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 676us/sample - loss: 0.0047 - mean_absolute_error: 0.0399\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 650us/sample - loss: 0.0027 - mean_absolute_error: 0.0321\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 635us/sample - loss: 0.0016 - mean_absolute_error: 0.0245\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 655us/sample - loss: 0.0014 - mean_absolute_error: 0.0191\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 648us/sample - loss: 0.0016 - mean_absolute_error: 0.0187\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 641us/sample - loss: 0.0017 - mean_absolute_error: 0.0193\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 634us/sample - loss: 0.0030 - mean_absolute_error: 0.0247\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 666us/sample - loss: 0.0039 - mean_absolute_error: 0.0290\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 667us/sample - loss: 0.0060 - mean_absolute_error: 0.0371\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 613us/sample - loss: 0.0053 - mean_absolute_error: 0.0342\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 658us/sample - loss: 0.0058 - mean_absolute_error: 0.0344\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 664us/sample - loss: 0.0041 - mean_absolute_error: 0.0286\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 706us/sample - loss: 0.0072 - mean_absolute_error: 0.0339\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 694us/sample - loss: 0.0047 - mean_absolute_error: 0.0362\n",
      "110/110 [==============================] - 0s 537us/sample - loss: 1.5767 - mean_absolute_error: 0.7763\n",
      "220/220 [==============================] - 0s 169us/sample - loss: 0.0050 - mean_absolute_error: 0.0437\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_290 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5944 - mean_absolute_error: 0.8798\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 611us/sample - loss: 1.0055 - mean_absolute_error: 0.7179\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 612us/sample - loss: 0.5979 - mean_absolute_error: 0.5534\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 619us/sample - loss: 0.5616 - mean_absolute_error: 0.4882\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 618us/sample - loss: 0.2365 - mean_absolute_error: 0.3455\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 665us/sample - loss: 0.1380 - mean_absolute_error: 0.2602\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 614us/sample - loss: 0.1679 - mean_absolute_error: 0.2101\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 576us/sample - loss: 0.1145 - mean_absolute_error: 0.2205\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 576us/sample - loss: 0.3061 - mean_absolute_error: 0.2264\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 583us/sample - loss: 0.1389 - mean_absolute_error: 0.1996\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 573us/sample - loss: 0.0567 - mean_absolute_error: 0.1455\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 587us/sample - loss: 0.1276 - mean_absolute_error: 0.1752\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 669us/sample - loss: 0.1893 - mean_absolute_error: 0.2023\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 665us/sample - loss: 0.2323 - mean_absolute_error: 0.2109\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 610us/sample - loss: 0.1641 - mean_absolute_error: 0.1579\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0615 - mean_absolute_error: 0.1413\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 624us/sample - loss: 0.1627 - mean_absolute_error: 0.1394\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 648us/sample - loss: 0.1922 - mean_absolute_error: 0.1916\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 615us/sample - loss: 0.1744 - mean_absolute_error: 0.1560\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 621us/sample - loss: 0.0977 - mean_absolute_error: 0.1476\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 605us/sample - loss: 0.0405 - mean_absolute_error: 0.1245\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 620us/sample - loss: 0.3137 - mean_absolute_error: 0.1486\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 618us/sample - loss: 0.2670 - mean_absolute_error: 0.1976\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 656us/sample - loss: 0.2065 - mean_absolute_error: 0.1618\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 647us/sample - loss: 0.1340 - mean_absolute_error: 0.1194\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 639us/sample - loss: 0.0274 - mean_absolute_error: 0.1038\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 608us/sample - loss: 0.0352 - mean_absolute_error: 0.0882\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 583us/sample - loss: 0.0354 - mean_absolute_error: 0.0761\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 580us/sample - loss: 0.0274 - mean_absolute_error: 0.0712\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 572us/sample - loss: 0.0392 - mean_absolute_error: 0.0999\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 596us/sample - loss: 0.0265 - mean_absolute_error: 0.1000\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 629us/sample - loss: 0.0360 - mean_absolute_error: 0.1087\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 638us/sample - loss: 0.0291 - mean_absolute_error: 0.0931\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 579us/sample - loss: 0.0206 - mean_absolute_error: 0.0897\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 579us/sample - loss: 0.0154 - mean_absolute_error: 0.0795\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 574us/sample - loss: 0.0095 - mean_absolute_error: 0.0599\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 575us/sample - loss: 0.0061 - mean_absolute_error: 0.0479\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 572us/sample - loss: 0.0190 - mean_absolute_error: 0.0557\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 573us/sample - loss: 0.0233 - mean_absolute_error: 0.0587\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 576us/sample - loss: 0.0165 - mean_absolute_error: 0.0571\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 571us/sample - loss: 0.0249 - mean_absolute_error: 0.0533\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 581us/sample - loss: 0.0222 - mean_absolute_error: 0.0687\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 590us/sample - loss: 0.0342 - mean_absolute_error: 0.0967\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 572us/sample - loss: 0.0223 - mean_absolute_error: 0.0872\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0248 - mean_absolute_error: 0.0830\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 583us/sample - loss: 0.0123 - mean_absolute_error: 0.0661\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 573us/sample - loss: 0.0097 - mean_absolute_error: 0.0684\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 577us/sample - loss: 0.0094 - mean_absolute_error: 0.0644\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0139 - mean_absolute_error: 0.0723\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 581us/sample - loss: 0.0136 - mean_absolute_error: 0.0657\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 576us/sample - loss: 0.0168 - mean_absolute_error: 0.0799\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0317 - mean_absolute_error: 0.0719\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0104 - mean_absolute_error: 0.0556\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 574us/sample - loss: 0.0044 - mean_absolute_error: 0.0431\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0050 - mean_absolute_error: 0.0382\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 575us/sample - loss: 0.0143 - mean_absolute_error: 0.0414\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 573us/sample - loss: 0.0152 - mean_absolute_error: 0.0454\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 583us/sample - loss: 0.0507 - mean_absolute_error: 0.0806\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 595us/sample - loss: 0.1680 - mean_absolute_error: 0.1108\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 603us/sample - loss: 0.1247 - mean_absolute_error: 0.1103\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 560us/sample - loss: 0.0930 - mean_absolute_error: 0.1374\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 577us/sample - loss: 0.0796 - mean_absolute_error: 0.1110\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 573us/sample - loss: 0.1036 - mean_absolute_error: 0.1273\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 576us/sample - loss: 0.0868 - mean_absolute_error: 0.1139\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 583us/sample - loss: 0.0398 - mean_absolute_error: 0.0935\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 573us/sample - loss: 0.0510 - mean_absolute_error: 0.1088\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 575us/sample - loss: 0.0886 - mean_absolute_error: 0.1338\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 583us/sample - loss: 0.0371 - mean_absolute_error: 0.1228\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 564us/sample - loss: 0.0651 - mean_absolute_error: 0.1337\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 577us/sample - loss: 0.0901 - mean_absolute_error: 0.1173\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 589us/sample - loss: 0.0466 - mean_absolute_error: 0.1254\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0315 - mean_absolute_error: 0.1210\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 581us/sample - loss: 0.0177 - mean_absolute_error: 0.0945\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 581us/sample - loss: 0.0181 - mean_absolute_error: 0.0876\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 582us/sample - loss: 0.0214 - mean_absolute_error: 0.0811\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 569us/sample - loss: 0.0510 - mean_absolute_error: 0.1036\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0331 - mean_absolute_error: 0.0854\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 569us/sample - loss: 0.0328 - mean_absolute_error: 0.0865\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.0531 - mean_absolute_error: 0.0861\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 582us/sample - loss: 0.1133 - mean_absolute_error: 0.1160\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 586us/sample - loss: 0.0981 - mean_absolute_error: 0.1336\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 570us/sample - loss: 0.1450 - mean_absolute_error: 0.1748\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 572us/sample - loss: 0.0849 - mean_absolute_error: 0.1408\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 578us/sample - loss: 0.0486 - mean_absolute_error: 0.1284\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.0624 - mean_absolute_error: 0.1487\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 582us/sample - loss: 0.0280 - mean_absolute_error: 0.0997\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 589us/sample - loss: 0.0423 - mean_absolute_error: 0.0835\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 621us/sample - loss: 0.0147 - mean_absolute_error: 0.0750\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 580us/sample - loss: 0.0170 - mean_absolute_error: 0.0755\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 566us/sample - loss: 0.0117 - mean_absolute_error: 0.0631\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 571us/sample - loss: 0.0142 - mean_absolute_error: 0.0663\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 566us/sample - loss: 0.0089 - mean_absolute_error: 0.0570\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 571us/sample - loss: 0.0125 - mean_absolute_error: 0.0608\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 576us/sample - loss: 0.0122 - mean_absolute_error: 0.0526\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 571us/sample - loss: 0.0250 - mean_absolute_error: 0.0692\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 572us/sample - loss: 0.0133 - mean_absolute_error: 0.0645\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 576us/sample - loss: 0.0155 - mean_absolute_error: 0.0676\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 576us/sample - loss: 0.0129 - mean_absolute_error: 0.0517\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 574us/sample - loss: 0.0157 - mean_absolute_error: 0.0556\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 577us/sample - loss: 0.0103 - mean_absolute_error: 0.0516\n",
      "110/110 [==============================] - 0s 558us/sample - loss: 0.7103 - mean_absolute_error: 0.5961\n",
      "220/220 [==============================] - 0s 175us/sample - loss: 0.0102 - mean_absolute_error: 0.0530\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_295 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.2745 - mean_absolute_error: 0.8116\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 1.1659 - mean_absolute_error: 0.6882\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 0.4260 - mean_absolute_error: 0.4736\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 538us/sample - loss: 0.4051 - mean_absolute_error: 0.3819\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 590us/sample - loss: 0.2486 - mean_absolute_error: 0.2933\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 588us/sample - loss: 0.2945 - mean_absolute_error: 0.2536\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 548us/sample - loss: 0.2232 - mean_absolute_error: 0.3098\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 561us/sample - loss: 0.1746 - mean_absolute_error: 0.2753\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 652us/sample - loss: 0.0996 - mean_absolute_error: 0.2198\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 624us/sample - loss: 0.2305 - mean_absolute_error: 0.1900\n",
      "110/110 [==============================] - 0s 626us/sample - loss: 1.0148 - mean_absolute_error: 0.6800\n",
      "220/220 [==============================] - 0s 225us/sample - loss: 0.1539 - mean_absolute_error: 0.1343\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_300 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4091 - mean_absolute_error: 0.8825\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 493us/sample - loss: 0.6852 - mean_absolute_error: 0.5998\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 479us/sample - loss: 0.3976 - mean_absolute_error: 0.4320\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.2152 - mean_absolute_error: 0.3258\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 472us/sample - loss: 0.1451 - mean_absolute_error: 0.2608\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0948 - mean_absolute_error: 0.2018\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0703 - mean_absolute_error: 0.1879\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0381 - mean_absolute_error: 0.1429\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0458 - mean_absolute_error: 0.1537\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.0425 - mean_absolute_error: 0.1453\n",
      "110/110 [==============================] - 0s 555us/sample - loss: 1.6002 - mean_absolute_error: 0.7642\n",
      "220/220 [==============================] - 0s 179us/sample - loss: 0.0249 - mean_absolute_error: 0.1018\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_305 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.7615 - mean_absolute_error: 1.0121\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 1.1990 - mean_absolute_error: 0.8022\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.5710 - mean_absolute_error: 0.5053\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 0.4459 - mean_absolute_error: 0.4103\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 482us/sample - loss: 0.3324 - mean_absolute_error: 0.3520\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 510us/sample - loss: 0.1757 - mean_absolute_error: 0.2762\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.1200 - mean_absolute_error: 0.2129\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0962 - mean_absolute_error: 0.1790\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.0485 - mean_absolute_error: 0.1400\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 493us/sample - loss: 0.0944 - mean_absolute_error: 0.1552\n",
      "110/110 [==============================] - 0s 563us/sample - loss: 0.7081 - mean_absolute_error: 0.6073\n",
      "220/220 [==============================] - 0s 156us/sample - loss: 0.0338 - mean_absolute_error: 0.1264\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_310 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4085 - mean_absolute_error: 0.7972\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 1.0491 - mean_absolute_error: 0.6147\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.5138 - mean_absolute_error: 0.5020\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.3288 - mean_absolute_error: 0.3635\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.1656 - mean_absolute_error: 0.2572\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0796 - mean_absolute_error: 0.1851\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0618 - mean_absolute_error: 0.1623\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0771 - mean_absolute_error: 0.1848\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.1164 - mean_absolute_error: 0.2315\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.0807 - mean_absolute_error: 0.2126\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0907 - mean_absolute_error: 0.2200\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0688 - mean_absolute_error: 0.1864\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 0.0817 - mean_absolute_error: 0.1957\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0530 - mean_absolute_error: 0.1821\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.0329 - mean_absolute_error: 0.1420\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 0.0274 - mean_absolute_error: 0.1045\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0120 - mean_absolute_error: 0.0668\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0128 - mean_absolute_error: 0.0491\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 0.0138 - mean_absolute_error: 0.0393\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0098 - mean_absolute_error: 0.0487\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0066 - mean_absolute_error: 0.0497\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0042 - mean_absolute_error: 0.0391\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 510us/sample - loss: 0.0030 - mean_absolute_error: 0.0313\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.0017 - mean_absolute_error: 0.0235\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0012 - mean_absolute_error: 0.0163\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0018 - mean_absolute_error: 0.0181\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0012 - mean_absolute_error: 0.0186\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0025 - mean_absolute_error: 0.0205\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0041 - mean_absolute_error: 0.0265\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0060 - mean_absolute_error: 0.0337\n",
      "110/110 [==============================] - 0s 557us/sample - loss: 1.0145 - mean_absolute_error: 0.7037\n",
      "220/220 [==============================] - 0s 167us/sample - loss: 0.0023 - mean_absolute_error: 0.0185\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_315 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.0455 - mean_absolute_error: 0.7575\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 511us/sample - loss: 0.5913 - mean_absolute_error: 0.5245\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.4356 - mean_absolute_error: 0.4870\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.3790 - mean_absolute_error: 0.4555\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.2305 - mean_absolute_error: 0.3483\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0632 - mean_absolute_error: 0.1858\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 524us/sample - loss: 0.0551 - mean_absolute_error: 0.1480\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 480us/sample - loss: 0.0367 - mean_absolute_error: 0.1172\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 480us/sample - loss: 0.0285 - mean_absolute_error: 0.1067\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 482us/sample - loss: 0.0202 - mean_absolute_error: 0.0977\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0185 - mean_absolute_error: 0.0917\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0112 - mean_absolute_error: 0.0736\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0118 - mean_absolute_error: 0.0650\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0095 - mean_absolute_error: 0.0607\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 500us/sample - loss: 0.0111 - mean_absolute_error: 0.0641\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 480us/sample - loss: 0.0094 - mean_absolute_error: 0.0594\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 480us/sample - loss: 0.0070 - mean_absolute_error: 0.0551\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 475us/sample - loss: 0.0073 - mean_absolute_error: 0.0571\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.0056 - mean_absolute_error: 0.0476\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 472us/sample - loss: 0.0051 - mean_absolute_error: 0.0498\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 481us/sample - loss: 0.0049 - mean_absolute_error: 0.0440\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0040 - mean_absolute_error: 0.0409\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 476us/sample - loss: 0.0096 - mean_absolute_error: 0.0515\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0083 - mean_absolute_error: 0.0550\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.0156 - mean_absolute_error: 0.0689\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0177 - mean_absolute_error: 0.0896\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 470us/sample - loss: 0.0307 - mean_absolute_error: 0.0970\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.0303 - mean_absolute_error: 0.0901\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0466 - mean_absolute_error: 0.0965\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 473us/sample - loss: 0.0237 - mean_absolute_error: 0.0913\n",
      "110/110 [==============================] - 0s 561us/sample - loss: 1.5911 - mean_absolute_error: 0.7609\n",
      "220/220 [==============================] - 0s 157us/sample - loss: 0.0909 - mean_absolute_error: 0.1079\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_320 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5243 - mean_absolute_error: 0.8523\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.9276 - mean_absolute_error: 0.6416\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.4339 - mean_absolute_error: 0.4541\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 491us/sample - loss: 0.4663 - mean_absolute_error: 0.4271\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.2042 - mean_absolute_error: 0.3117\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.2965 - mean_absolute_error: 0.2580\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.2430 - mean_absolute_error: 0.2470\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.1773 - mean_absolute_error: 0.2430\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.0882 - mean_absolute_error: 0.1793\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.2091 - mean_absolute_error: 0.2646\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.1478 - mean_absolute_error: 0.2530\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0752 - mean_absolute_error: 0.1860\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0422 - mean_absolute_error: 0.1563\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0586 - mean_absolute_error: 0.1350\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0438 - mean_absolute_error: 0.1161\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0258 - mean_absolute_error: 0.1050\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0225 - mean_absolute_error: 0.0765\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0236 - mean_absolute_error: 0.0877\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0407 - mean_absolute_error: 0.0951\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0207 - mean_absolute_error: 0.0830\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0303 - mean_absolute_error: 0.0999\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0193 - mean_absolute_error: 0.1054\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 484us/sample - loss: 0.0600 - mean_absolute_error: 0.1046\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0373 - mean_absolute_error: 0.0978\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0552 - mean_absolute_error: 0.0865\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0215 - mean_absolute_error: 0.0831\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 0.0312 - mean_absolute_error: 0.0883\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0549 - mean_absolute_error: 0.1044\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 0.0419 - mean_absolute_error: 0.1210\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0808 - mean_absolute_error: 0.1335\n",
      "110/110 [==============================] - 0s 545us/sample - loss: 0.7652 - mean_absolute_error: 0.6529\n",
      "220/220 [==============================] - 0s 176us/sample - loss: 0.0614 - mean_absolute_error: 0.1453\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_325 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.2936 - mean_absolute_error: 0.8449\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 0.6539 - mean_absolute_error: 0.5533\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.5306 - mean_absolute_error: 0.4593\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 519us/sample - loss: 0.5164 - mean_absolute_error: 0.3986\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.2985 - mean_absolute_error: 0.3667\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.2542 - mean_absolute_error: 0.3458\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.1575 - mean_absolute_error: 0.2658\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.1172 - mean_absolute_error: 0.2126\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.1191 - mean_absolute_error: 0.2018\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.1626 - mean_absolute_error: 0.1982\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 493us/sample - loss: 0.0586 - mean_absolute_error: 0.1789\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0588 - mean_absolute_error: 0.1437\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0570 - mean_absolute_error: 0.1069\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0281 - mean_absolute_error: 0.0907\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 484us/sample - loss: 0.0743 - mean_absolute_error: 0.1361\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0488 - mean_absolute_error: 0.1534\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 484us/sample - loss: 0.0645 - mean_absolute_error: 0.1793\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0764 - mean_absolute_error: 0.1818\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 0.0247 - mean_absolute_error: 0.1132\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 491us/sample - loss: 0.0153 - mean_absolute_error: 0.0860\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0192 - mean_absolute_error: 0.0774\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 493us/sample - loss: 0.0283 - mean_absolute_error: 0.0835\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.0391 - mean_absolute_error: 0.0837\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0247 - mean_absolute_error: 0.0978\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0549 - mean_absolute_error: 0.1268\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0321 - mean_absolute_error: 0.1216\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0354 - mean_absolute_error: 0.1176\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0288 - mean_absolute_error: 0.1158\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.0278 - mean_absolute_error: 0.0963\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0220 - mean_absolute_error: 0.0874\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.0291 - mean_absolute_error: 0.0899\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0162 - mean_absolute_error: 0.0796\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0212 - mean_absolute_error: 0.0833\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 493us/sample - loss: 0.0309 - mean_absolute_error: 0.0968\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0263 - mean_absolute_error: 0.1104\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0313 - mean_absolute_error: 0.1073\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 493us/sample - loss: 0.0297 - mean_absolute_error: 0.0888\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0365 - mean_absolute_error: 0.0724\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 491us/sample - loss: 0.0123 - mean_absolute_error: 0.0619\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0146 - mean_absolute_error: 0.0661\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 510us/sample - loss: 0.0060 - mean_absolute_error: 0.0522\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0052 - mean_absolute_error: 0.0428\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0054 - mean_absolute_error: 0.0350\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0159 - mean_absolute_error: 0.0399\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0173 - mean_absolute_error: 0.0474\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0404 - mean_absolute_error: 0.0755\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0239 - mean_absolute_error: 0.0914\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0688 - mean_absolute_error: 0.1186\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 0.0458 - mean_absolute_error: 0.0902\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.0191 - mean_absolute_error: 0.0817\n",
      "110/110 [==============================] - 0s 542us/sample - loss: 0.9478 - mean_absolute_error: 0.6807\n",
      "220/220 [==============================] - 0s 170us/sample - loss: 0.0225 - mean_absolute_error: 0.0855\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_330 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.0818 - mean_absolute_error: 0.8015\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 545us/sample - loss: 0.7681 - mean_absolute_error: 0.6387\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 517us/sample - loss: 0.3893 - mean_absolute_error: 0.4313\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 513us/sample - loss: 0.1886 - mean_absolute_error: 0.3216\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 617us/sample - loss: 0.0992 - mean_absolute_error: 0.2321\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0884 - mean_absolute_error: 0.1946\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0781 - mean_absolute_error: 0.1832\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0923 - mean_absolute_error: 0.1996\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0428 - mean_absolute_error: 0.1483\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0443 - mean_absolute_error: 0.1208\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 575us/sample - loss: 0.0560 - mean_absolute_error: 0.1012\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 541us/sample - loss: 0.0198 - mean_absolute_error: 0.0914\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 0.0225 - mean_absolute_error: 0.1049\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 543us/sample - loss: 0.0124 - mean_absolute_error: 0.0884\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.0161 - mean_absolute_error: 0.0823\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 523us/sample - loss: 0.0131 - mean_absolute_error: 0.0830\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0286 - mean_absolute_error: 0.0800\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 478us/sample - loss: 0.0324 - mean_absolute_error: 0.0842\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 538us/sample - loss: 0.0134 - mean_absolute_error: 0.0687\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 559us/sample - loss: 0.0109 - mean_absolute_error: 0.0624\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 515us/sample - loss: 0.0074 - mean_absolute_error: 0.0531\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0038 - mean_absolute_error: 0.0405\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 546us/sample - loss: 0.0060 - mean_absolute_error: 0.0432\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0046 - mean_absolute_error: 0.0404\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0023 - mean_absolute_error: 0.0355\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0034 - mean_absolute_error: 0.0367\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.0023 - mean_absolute_error: 0.0300\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0017 - mean_absolute_error: 0.0234\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 491us/sample - loss: 9.6824e-04 - mean_absolute_error: 0.0230\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0011 - mean_absolute_error: 0.0228\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.0011 - mean_absolute_error: 0.0231\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 493us/sample - loss: 0.0013 - mean_absolute_error: 0.0264\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0015 - mean_absolute_error: 0.0264\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0014 - mean_absolute_error: 0.0267\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0033 - mean_absolute_error: 0.0342\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0064 - mean_absolute_error: 0.0422\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0188 - mean_absolute_error: 0.0628\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0125 - mean_absolute_error: 0.0607\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0209 - mean_absolute_error: 0.0734\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0080 - mean_absolute_error: 0.0620\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 0.0104 - mean_absolute_error: 0.0659\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0099 - mean_absolute_error: 0.0600\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0089 - mean_absolute_error: 0.0629\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 0.0082 - mean_absolute_error: 0.0592\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 0.0103 - mean_absolute_error: 0.0589\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0058 - mean_absolute_error: 0.0500\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0061 - mean_absolute_error: 0.0497\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0062 - mean_absolute_error: 0.0509\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.0066 - mean_absolute_error: 0.0519\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0030 - mean_absolute_error: 0.0382\n",
      "110/110 [==============================] - 0s 550us/sample - loss: 1.6028 - mean_absolute_error: 0.7785\n",
      "220/220 [==============================] - 0s 155us/sample - loss: 0.0020 - mean_absolute_error: 0.0359\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_335 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4551 - mean_absolute_error: 0.8647\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 482us/sample - loss: 1.1337 - mean_absolute_error: 0.7500\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.7675 - mean_absolute_error: 0.6686\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.7548 - mean_absolute_error: 0.5935\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.3290 - mean_absolute_error: 0.4140\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.2123 - mean_absolute_error: 0.3257\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.1874 - mean_absolute_error: 0.2497\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0953 - mean_absolute_error: 0.2172\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.1109 - mean_absolute_error: 0.1815\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 513us/sample - loss: 0.0704 - mean_absolute_error: 0.1662\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 512us/sample - loss: 0.1019 - mean_absolute_error: 0.1530\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0567 - mean_absolute_error: 0.1430\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.1068 - mean_absolute_error: 0.1688\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0601 - mean_absolute_error: 0.1620\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0615 - mean_absolute_error: 0.1378\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0350 - mean_absolute_error: 0.1256\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 0.0796 - mean_absolute_error: 0.1158\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0944 - mean_absolute_error: 0.0884\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0556 - mean_absolute_error: 0.1136\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.0620 - mean_absolute_error: 0.1250\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0202 - mean_absolute_error: 0.0944\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0187 - mean_absolute_error: 0.0645\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0114 - mean_absolute_error: 0.0600\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0063 - mean_absolute_error: 0.0492\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0299 - mean_absolute_error: 0.0607\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0412 - mean_absolute_error: 0.0516\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.0235 - mean_absolute_error: 0.0808\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0667 - mean_absolute_error: 0.0885\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.0145 - mean_absolute_error: 0.0655\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0266 - mean_absolute_error: 0.0655\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 493us/sample - loss: 0.0475 - mean_absolute_error: 0.0616\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.0199 - mean_absolute_error: 0.0762\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0246 - mean_absolute_error: 0.0882\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0114 - mean_absolute_error: 0.0709\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0166 - mean_absolute_error: 0.0675\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0142 - mean_absolute_error: 0.0621\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0129 - mean_absolute_error: 0.0534\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 480us/sample - loss: 0.0152 - mean_absolute_error: 0.0718\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0424 - mean_absolute_error: 0.0930\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0220 - mean_absolute_error: 0.0843\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0141 - mean_absolute_error: 0.0646\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0104 - mean_absolute_error: 0.0568\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 482us/sample - loss: 0.0038 - mean_absolute_error: 0.0358\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0123 - mean_absolute_error: 0.0435\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0028 - mean_absolute_error: 0.0325\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0118 - mean_absolute_error: 0.0364\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 491us/sample - loss: 0.0044 - mean_absolute_error: 0.0288\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0018 - mean_absolute_error: 0.0249\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 484us/sample - loss: 0.0061 - mean_absolute_error: 0.0211\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0018 - mean_absolute_error: 0.0219\n",
      "110/110 [==============================] - 0s 596us/sample - loss: 0.7606 - mean_absolute_error: 0.6328\n",
      "220/220 [==============================] - 0s 162us/sample - loss: 0.0024 - mean_absolute_error: 0.0217\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_340 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_344 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.2598 - mean_absolute_error: 0.7702\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 1.1426 - mean_absolute_error: 0.6866\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.4572 - mean_absolute_error: 0.4643\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.2495 - mean_absolute_error: 0.3474\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 0.2206 - mean_absolute_error: 0.3601\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.2910 - mean_absolute_error: 0.3589\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 514us/sample - loss: 0.1399 - mean_absolute_error: 0.2765\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 512us/sample - loss: 0.1045 - mean_absolute_error: 0.1769\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 518us/sample - loss: 0.1455 - mean_absolute_error: 0.2222\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 518us/sample - loss: 0.1344 - mean_absolute_error: 0.2614\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0954 - mean_absolute_error: 0.2164\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 514us/sample - loss: 0.0309 - mean_absolute_error: 0.1318\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0393 - mean_absolute_error: 0.1106\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 515us/sample - loss: 0.0094 - mean_absolute_error: 0.0649\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 0.0085 - mean_absolute_error: 0.0537\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0069 - mean_absolute_error: 0.0468\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 520us/sample - loss: 0.0073 - mean_absolute_error: 0.0429\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 524us/sample - loss: 0.0121 - mean_absolute_error: 0.0500\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0082 - mean_absolute_error: 0.0644\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 543us/sample - loss: 0.0094 - mean_absolute_error: 0.0715\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.0100 - mean_absolute_error: 0.0731\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0164 - mean_absolute_error: 0.0846\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0217 - mean_absolute_error: 0.0843\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 514us/sample - loss: 0.0451 - mean_absolute_error: 0.1037\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0265 - mean_absolute_error: 0.1025\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 518us/sample - loss: 0.0280 - mean_absolute_error: 0.1117\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0195 - mean_absolute_error: 0.0945\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0133 - mean_absolute_error: 0.0784\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 511us/sample - loss: 0.0189 - mean_absolute_error: 0.0689\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0071 - mean_absolute_error: 0.0472\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0054 - mean_absolute_error: 0.0388\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0066 - mean_absolute_error: 0.0369\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 507us/sample - loss: 0.0111 - mean_absolute_error: 0.0386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0079 - mean_absolute_error: 0.0494\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 507us/sample - loss: 0.0286 - mean_absolute_error: 0.0756\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0161 - mean_absolute_error: 0.0801\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 507us/sample - loss: 0.0431 - mean_absolute_error: 0.1181\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 510us/sample - loss: 0.0280 - mean_absolute_error: 0.1100\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0427 - mean_absolute_error: 0.1173\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0386 - mean_absolute_error: 0.1221\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 507us/sample - loss: 0.0980 - mean_absolute_error: 0.1381\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0461 - mean_absolute_error: 0.1326\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0520 - mean_absolute_error: 0.1274\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0500 - mean_absolute_error: 0.1330\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.1074 - mean_absolute_error: 0.1677\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0431 - mean_absolute_error: 0.1465\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0499 - mean_absolute_error: 0.1280\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0681 - mean_absolute_error: 0.1396\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0454 - mean_absolute_error: 0.1092\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.0267 - mean_absolute_error: 0.0827\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0461 - mean_absolute_error: 0.1173\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0216 - mean_absolute_error: 0.0888\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0623 - mean_absolute_error: 0.1232\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0318 - mean_absolute_error: 0.1249\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 0.0168 - mean_absolute_error: 0.0935\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 507us/sample - loss: 0.0257 - mean_absolute_error: 0.1009\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.0417 - mean_absolute_error: 0.1149\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 0.0582 - mean_absolute_error: 0.1191\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.1019 - mean_absolute_error: 0.1049\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 507us/sample - loss: 0.0601 - mean_absolute_error: 0.1087\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0956 - mean_absolute_error: 0.1226\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0544 - mean_absolute_error: 0.1271\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.0278 - mean_absolute_error: 0.1096\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 510us/sample - loss: 0.0224 - mean_absolute_error: 0.0952\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0374 - mean_absolute_error: 0.0955\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0336 - mean_absolute_error: 0.1050\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0708 - mean_absolute_error: 0.1247\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 510us/sample - loss: 0.0555 - mean_absolute_error: 0.1227\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.1361 - mean_absolute_error: 0.1607\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0960 - mean_absolute_error: 0.1622\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 513us/sample - loss: 0.1110 - mean_absolute_error: 0.1567\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.1579 - mean_absolute_error: 0.1540\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.1120 - mean_absolute_error: 0.1613\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.1375 - mean_absolute_error: 0.1890\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.2420 - mean_absolute_error: 0.2230\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0897 - mean_absolute_error: 0.1637\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.2334 - mean_absolute_error: 0.1821\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0449 - mean_absolute_error: 0.1256\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0484 - mean_absolute_error: 0.1206\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.1347 - mean_absolute_error: 0.1571\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0354 - mean_absolute_error: 0.1120\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 511us/sample - loss: 0.0339 - mean_absolute_error: 0.0821\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0560 - mean_absolute_error: 0.0878\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0172 - mean_absolute_error: 0.0693\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.0177 - mean_absolute_error: 0.0608\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0044 - mean_absolute_error: 0.0425\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0068 - mean_absolute_error: 0.0400\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0084 - mean_absolute_error: 0.0416\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 515us/sample - loss: 0.0051 - mean_absolute_error: 0.0346\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0031 - mean_absolute_error: 0.0258\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 512us/sample - loss: 0.0014 - mean_absolute_error: 0.0219\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 510us/sample - loss: 0.0010 - mean_absolute_error: 0.0200\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 9.7740e-04 - mean_absolute_error: 0.0190\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 8.1870e-04 - mean_absolute_error: 0.0192\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 6.2140e-04 - mean_absolute_error: 0.0188\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 3.8905e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 2.0337e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 1.1009e-04 - mean_absolute_error: 0.0072\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 1.0066e-04 - mean_absolute_error: 0.0065\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 5.3746e-05 - mean_absolute_error: 0.0050\n",
      "110/110 [==============================] - 0s 546us/sample - loss: 1.0487 - mean_absolute_error: 0.7589\n",
      "220/220 [==============================] - 0s 165us/sample - loss: 1.9018e-05 - mean_absolute_error: 0.0030\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_345 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_348 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_349 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.0091 - mean_absolute_error: 0.7484\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 528us/sample - loss: 0.6165 - mean_absolute_error: 0.5697\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 524us/sample - loss: 0.4215 - mean_absolute_error: 0.4762\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.3178 - mean_absolute_error: 0.3835\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 520us/sample - loss: 0.1212 - mean_absolute_error: 0.2553\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.1126 - mean_absolute_error: 0.2236\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.1164 - mean_absolute_error: 0.2165\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.0561 - mean_absolute_error: 0.1627\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 528us/sample - loss: 0.0676 - mean_absolute_error: 0.1770\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 523us/sample - loss: 0.0721 - mean_absolute_error: 0.1656\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 527us/sample - loss: 0.0523 - mean_absolute_error: 0.1481\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.0363 - mean_absolute_error: 0.1329\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0279 - mean_absolute_error: 0.1175\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 522us/sample - loss: 0.0177 - mean_absolute_error: 0.0967\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 532us/sample - loss: 0.0191 - mean_absolute_error: 0.1009\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.0165 - mean_absolute_error: 0.0962\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0157 - mean_absolute_error: 0.0906\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 527us/sample - loss: 0.0092 - mean_absolute_error: 0.0730\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 511us/sample - loss: 0.0117 - mean_absolute_error: 0.0738\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 528us/sample - loss: 0.0111 - mean_absolute_error: 0.0682\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 531us/sample - loss: 0.0203 - mean_absolute_error: 0.0841\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 529us/sample - loss: 0.0159 - mean_absolute_error: 0.0946\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 525us/sample - loss: 0.0109 - mean_absolute_error: 0.0782\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0062 - mean_absolute_error: 0.0530\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 528us/sample - loss: 0.0036 - mean_absolute_error: 0.0396\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 531us/sample - loss: 0.0029 - mean_absolute_error: 0.0298\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 518us/sample - loss: 0.0068 - mean_absolute_error: 0.0330\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 524us/sample - loss: 0.0156 - mean_absolute_error: 0.0392\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 531us/sample - loss: 0.0419 - mean_absolute_error: 0.0713\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0207 - mean_absolute_error: 0.0913\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 524us/sample - loss: 0.0150 - mean_absolute_error: 0.0866\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.0125 - mean_absolute_error: 0.0766\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 522us/sample - loss: 0.0067 - mean_absolute_error: 0.0512\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0067 - mean_absolute_error: 0.0496\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 0.0037 - mean_absolute_error: 0.0389\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 527us/sample - loss: 0.0047 - mean_absolute_error: 0.0384\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.0020 - mean_absolute_error: 0.0303\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 531us/sample - loss: 0.0043 - mean_absolute_error: 0.0310\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 0.0043 - mean_absolute_error: 0.0361\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 529us/sample - loss: 0.0057 - mean_absolute_error: 0.0478\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 532us/sample - loss: 0.0050 - mean_absolute_error: 0.0442\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 539us/sample - loss: 0.0049 - mean_absolute_error: 0.0437\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 533us/sample - loss: 0.0057 - mean_absolute_error: 0.0459\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 523us/sample - loss: 0.0044 - mean_absolute_error: 0.0400\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 522us/sample - loss: 0.0035 - mean_absolute_error: 0.0369\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 0.0054 - mean_absolute_error: 0.0404\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 525us/sample - loss: 0.0043 - mean_absolute_error: 0.0378\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.0044 - mean_absolute_error: 0.0395\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 528us/sample - loss: 0.0044 - mean_absolute_error: 0.0466\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 527us/sample - loss: 0.0040 - mean_absolute_error: 0.0447\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 525us/sample - loss: 0.0055 - mean_absolute_error: 0.0489\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0064 - mean_absolute_error: 0.0477\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 536us/sample - loss: 0.0052 - mean_absolute_error: 0.0436\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0099 - mean_absolute_error: 0.0632\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 515us/sample - loss: 0.0085 - mean_absolute_error: 0.0633\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 532us/sample - loss: 0.0100 - mean_absolute_error: 0.0678\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 565us/sample - loss: 0.0061 - mean_absolute_error: 0.0596\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 538us/sample - loss: 0.0087 - mean_absolute_error: 0.0706\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 527us/sample - loss: 0.0094 - mean_absolute_error: 0.0717\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 529us/sample - loss: 0.0074 - mean_absolute_error: 0.0542\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 533us/sample - loss: 0.0081 - mean_absolute_error: 0.0539\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.0149 - mean_absolute_error: 0.0680\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0137 - mean_absolute_error: 0.0790\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0220 - mean_absolute_error: 0.0894\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.0219 - mean_absolute_error: 0.0808\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 527us/sample - loss: 0.0376 - mean_absolute_error: 0.0948\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.0185 - mean_absolute_error: 0.0802\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 523us/sample - loss: 0.0344 - mean_absolute_error: 0.0970\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 525us/sample - loss: 0.0292 - mean_absolute_error: 0.0955\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 515us/sample - loss: 0.0481 - mean_absolute_error: 0.1178\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 528us/sample - loss: 0.0263 - mean_absolute_error: 0.1197\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0371 - mean_absolute_error: 0.1276\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 520us/sample - loss: 0.0480 - mean_absolute_error: 0.1405\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 525us/sample - loss: 0.1060 - mean_absolute_error: 0.1876\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.0516 - mean_absolute_error: 0.1498\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 533us/sample - loss: 0.0775 - mean_absolute_error: 0.1846\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 537us/sample - loss: 0.0474 - mean_absolute_error: 0.1515\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 562us/sample - loss: 0.0330 - mean_absolute_error: 0.1184\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0345 - mean_absolute_error: 0.1102\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 544us/sample - loss: 0.0798 - mean_absolute_error: 0.1137\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.0903 - mean_absolute_error: 0.1409\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 515us/sample - loss: 0.0935 - mean_absolute_error: 0.1344\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 535us/sample - loss: 0.0393 - mean_absolute_error: 0.1307\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0546 - mean_absolute_error: 0.1529\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 524us/sample - loss: 0.1558 - mean_absolute_error: 0.2287\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.1619 - mean_absolute_error: 0.2150\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 524us/sample - loss: 0.0963 - mean_absolute_error: 0.1798\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.0426 - mean_absolute_error: 0.1416\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 513us/sample - loss: 0.1239 - mean_absolute_error: 0.1725\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0500 - mean_absolute_error: 0.1450\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 524us/sample - loss: 0.0508 - mean_absolute_error: 0.1320\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 529us/sample - loss: 0.0866 - mean_absolute_error: 0.1294\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 527us/sample - loss: 0.0695 - mean_absolute_error: 0.1142\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 525us/sample - loss: 0.0556 - mean_absolute_error: 0.1118\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0303 - mean_absolute_error: 0.0883\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 512us/sample - loss: 0.0209 - mean_absolute_error: 0.0854\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 528us/sample - loss: 0.0204 - mean_absolute_error: 0.0811\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 0.0144 - mean_absolute_error: 0.0563\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0206 - mean_absolute_error: 0.0621\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.0115 - mean_absolute_error: 0.0633\n",
      "110/110 [==============================] - 0s 562us/sample - loss: 1.6348 - mean_absolute_error: 0.7767\n",
      "220/220 [==============================] - 0s 165us/sample - loss: 0.0082 - mean_absolute_error: 0.0591\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_350 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_351 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_352 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.8222 - mean_absolute_error: 0.9830\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 520us/sample - loss: 0.9765 - mean_absolute_error: 0.7238\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 522us/sample - loss: 0.4674 - mean_absolute_error: 0.4927\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 548us/sample - loss: 0.4085 - mean_absolute_error: 0.4348\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 539us/sample - loss: 0.3540 - mean_absolute_error: 0.3412\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 540us/sample - loss: 0.3721 - mean_absolute_error: 0.3242\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 542us/sample - loss: 0.1102 - mean_absolute_error: 0.2363\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 542us/sample - loss: 0.1617 - mean_absolute_error: 0.2540\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 540us/sample - loss: 0.2411 - mean_absolute_error: 0.2424\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 545us/sample - loss: 0.2998 - mean_absolute_error: 0.2310\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 551us/sample - loss: 0.1839 - mean_absolute_error: 0.2406\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 554us/sample - loss: 0.0956 - mean_absolute_error: 0.1830\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 549us/sample - loss: 0.0545 - mean_absolute_error: 0.1408\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 542us/sample - loss: 0.0391 - mean_absolute_error: 0.1211\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 548us/sample - loss: 0.0356 - mean_absolute_error: 0.1013\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 541us/sample - loss: 0.0165 - mean_absolute_error: 0.0862\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0099 - mean_absolute_error: 0.0674\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 546us/sample - loss: 0.0322 - mean_absolute_error: 0.0755\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 532us/sample - loss: 0.0188 - mean_absolute_error: 0.0688\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0452 - mean_absolute_error: 0.0817\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 547us/sample - loss: 0.0123 - mean_absolute_error: 0.0587\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 544us/sample - loss: 0.0158 - mean_absolute_error: 0.0596\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 527us/sample - loss: 0.0309 - mean_absolute_error: 0.0881\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0190 - mean_absolute_error: 0.0959\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 547us/sample - loss: 0.0325 - mean_absolute_error: 0.1160\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 549us/sample - loss: 0.0350 - mean_absolute_error: 0.1188\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 543us/sample - loss: 0.0274 - mean_absolute_error: 0.1007\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 561us/sample - loss: 0.0121 - mean_absolute_error: 0.0791\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.0426 - mean_absolute_error: 0.0792\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 535us/sample - loss: 0.0223 - mean_absolute_error: 0.0921\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 555us/sample - loss: 0.0263 - mean_absolute_error: 0.1140\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 543us/sample - loss: 0.0318 - mean_absolute_error: 0.1315\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 562us/sample - loss: 0.0539 - mean_absolute_error: 0.1584\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 559us/sample - loss: 0.0598 - mean_absolute_error: 0.1715\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 637us/sample - loss: 0.1186 - mean_absolute_error: 0.1824\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 571us/sample - loss: 0.0860 - mean_absolute_error: 0.1954\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 600us/sample - loss: 0.1989 - mean_absolute_error: 0.2265\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 556us/sample - loss: 0.2110 - mean_absolute_error: 0.1967\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 539us/sample - loss: 0.0737 - mean_absolute_error: 0.1309\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 552us/sample - loss: 0.0774 - mean_absolute_error: 0.1379\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 600us/sample - loss: 0.0825 - mean_absolute_error: 0.1435\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 562us/sample - loss: 0.0424 - mean_absolute_error: 0.1131\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 554us/sample - loss: 0.0379 - mean_absolute_error: 0.1124\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 554us/sample - loss: 0.0501 - mean_absolute_error: 0.1061\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 547us/sample - loss: 0.0515 - mean_absolute_error: 0.1071\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 548us/sample - loss: 0.0564 - mean_absolute_error: 0.0990\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 551us/sample - loss: 0.0767 - mean_absolute_error: 0.1289\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 548us/sample - loss: 0.0838 - mean_absolute_error: 0.1369\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 543us/sample - loss: 0.0824 - mean_absolute_error: 0.1347\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 541us/sample - loss: 0.0218 - mean_absolute_error: 0.0968\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 549us/sample - loss: 0.0222 - mean_absolute_error: 0.0825\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 550us/sample - loss: 0.0130 - mean_absolute_error: 0.0668\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 536us/sample - loss: 0.0080 - mean_absolute_error: 0.0494\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 539us/sample - loss: 0.0039 - mean_absolute_error: 0.0418\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 522us/sample - loss: 0.0035 - mean_absolute_error: 0.0352\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 531us/sample - loss: 0.0019 - mean_absolute_error: 0.0267\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 541us/sample - loss: 0.0039 - mean_absolute_error: 0.0277\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 539us/sample - loss: 0.0033 - mean_absolute_error: 0.0307\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 543us/sample - loss: 0.0018 - mean_absolute_error: 0.0291\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 540us/sample - loss: 0.0023 - mean_absolute_error: 0.0280\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 548us/sample - loss: 0.0015 - mean_absolute_error: 0.0235\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 542us/sample - loss: 0.0020 - mean_absolute_error: 0.0197\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 538us/sample - loss: 0.0023 - mean_absolute_error: 0.0183\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 524us/sample - loss: 0.0033 - mean_absolute_error: 0.0258\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 531us/sample - loss: 0.0077 - mean_absolute_error: 0.0416\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 553us/sample - loss: 0.0053 - mean_absolute_error: 0.0397\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 544us/sample - loss: 0.0054 - mean_absolute_error: 0.0425\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 540us/sample - loss: 0.0041 - mean_absolute_error: 0.0409\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0044 - mean_absolute_error: 0.0420\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 539us/sample - loss: 0.0079 - mean_absolute_error: 0.0491\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 543us/sample - loss: 0.0085 - mean_absolute_error: 0.0498\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 545us/sample - loss: 0.0131 - mean_absolute_error: 0.0585\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 544us/sample - loss: 0.0091 - mean_absolute_error: 0.0548\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 540us/sample - loss: 0.0203 - mean_absolute_error: 0.0648\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 544us/sample - loss: 0.0147 - mean_absolute_error: 0.0582\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 532us/sample - loss: 0.0096 - mean_absolute_error: 0.0523\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 540us/sample - loss: 0.0152 - mean_absolute_error: 0.0558\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 536us/sample - loss: 0.0188 - mean_absolute_error: 0.0577\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.0294 - mean_absolute_error: 0.0815\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 541us/sample - loss: 0.0623 - mean_absolute_error: 0.1315\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 546us/sample - loss: 0.0617 - mean_absolute_error: 0.1449\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 545us/sample - loss: 0.1152 - mean_absolute_error: 0.1775\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 542us/sample - loss: 0.0786 - mean_absolute_error: 0.1697\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 545us/sample - loss: 0.0806 - mean_absolute_error: 0.1597\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0388 - mean_absolute_error: 0.1365\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 0.0553 - mean_absolute_error: 0.1233\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 544us/sample - loss: 0.0215 - mean_absolute_error: 0.0991\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 537us/sample - loss: 0.0787 - mean_absolute_error: 0.1012\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 531us/sample - loss: 0.0493 - mean_absolute_error: 0.0885\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 530us/sample - loss: 0.0394 - mean_absolute_error: 0.0845\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 544us/sample - loss: 0.0161 - mean_absolute_error: 0.0615\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 528us/sample - loss: 0.0411 - mean_absolute_error: 0.0774\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 542us/sample - loss: 0.0805 - mean_absolute_error: 0.0965\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 554us/sample - loss: 0.0206 - mean_absolute_error: 0.0767\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 545us/sample - loss: 0.0595 - mean_absolute_error: 0.1005\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 529us/sample - loss: 0.0915 - mean_absolute_error: 0.1367\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 536us/sample - loss: 0.0431 - mean_absolute_error: 0.1052\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 541us/sample - loss: 0.0179 - mean_absolute_error: 0.0708\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 543us/sample - loss: 0.0166 - mean_absolute_error: 0.0625\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 553us/sample - loss: 0.0159 - mean_absolute_error: 0.0664\n",
      "110/110 [==============================] - 0s 553us/sample - loss: 0.8055 - mean_absolute_error: 0.6551\n",
      "220/220 [==============================] - 0s 148us/sample - loss: 0.0148 - mean_absolute_error: 0.0818\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_355 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_357 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_359 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.6218 - mean_absolute_error: 0.9618\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 476us/sample - loss: 0.8810 - mean_absolute_error: 0.5680\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 484us/sample - loss: 0.6131 - mean_absolute_error: 0.5701\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 0.3678 - mean_absolute_error: 0.3585\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.3938 - mean_absolute_error: 0.3217\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.1626 - mean_absolute_error: 0.2655\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0910 - mean_absolute_error: 0.2243\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.1710 - mean_absolute_error: 0.2293\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 0.1571 - mean_absolute_error: 0.2173\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.1046 - mean_absolute_error: 0.2056\n",
      "110/110 [==============================] - 0s 549us/sample - loss: 1.0670 - mean_absolute_error: 0.6959\n",
      "220/220 [==============================] - 0s 154us/sample - loss: 0.0220 - mean_absolute_error: 0.1054\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_360 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_361 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_363 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_364 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.0714 - mean_absolute_error: 0.7897\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.6884 - mean_absolute_error: 0.5798\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 539us/sample - loss: 0.4289 - mean_absolute_error: 0.4987\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 520us/sample - loss: 0.2323 - mean_absolute_error: 0.3567\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 484us/sample - loss: 0.1462 - mean_absolute_error: 0.2656\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 481us/sample - loss: 0.1518 - mean_absolute_error: 0.2842\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.1387 - mean_absolute_error: 0.2922\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 479us/sample - loss: 0.0858 - mean_absolute_error: 0.2078\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.1490 - mean_absolute_error: 0.2094\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 479us/sample - loss: 0.1061 - mean_absolute_error: 0.2051\n",
      "110/110 [==============================] - 0s 557us/sample - loss: 1.5569 - mean_absolute_error: 0.7718\n",
      "220/220 [==============================] - 0s 167us/sample - loss: 0.0839 - mean_absolute_error: 0.2193\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_365 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_366 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_367 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_368 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_369 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.6397 - mean_absolute_error: 0.9483\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 457us/sample - loss: 0.7102 - mean_absolute_error: 0.5806\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.7708 - mean_absolute_error: 0.4881\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.5785 - mean_absolute_error: 0.4372\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.5701 - mean_absolute_error: 0.5164\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.2240 - mean_absolute_error: 0.3708\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.2672 - mean_absolute_error: 0.2950\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.1568 - mean_absolute_error: 0.2599\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.1210 - mean_absolute_error: 0.2473\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0712 - mean_absolute_error: 0.1804\n",
      "110/110 [==============================] - 0s 552us/sample - loss: 0.7593 - mean_absolute_error: 0.5882\n",
      "220/220 [==============================] - 0s 165us/sample - loss: 0.0460 - mean_absolute_error: 0.1529\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_370 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_371 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_372 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_373 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_374 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.4466 - mean_absolute_error: 0.8235\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.8723 - mean_absolute_error: 0.6171\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 446us/sample - loss: 0.5155 - mean_absolute_error: 0.4903\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.9165 - mean_absolute_error: 0.6872\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.6234 - mean_absolute_error: 0.5290\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.2978 - mean_absolute_error: 0.3960\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 465us/sample - loss: 0.1531 - mean_absolute_error: 0.2510\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0903 - mean_absolute_error: 0.1834\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0285 - mean_absolute_error: 0.1200\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0368 - mean_absolute_error: 0.1035\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.0968 - mean_absolute_error: 0.1147\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0283 - mean_absolute_error: 0.1004\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0293 - mean_absolute_error: 0.1036\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 0.0317 - mean_absolute_error: 0.1133\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.0312 - mean_absolute_error: 0.1247\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 0.0154 - mean_absolute_error: 0.1011\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0145 - mean_absolute_error: 0.0744\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0211 - mean_absolute_error: 0.0718\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0295 - mean_absolute_error: 0.0658\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0106 - mean_absolute_error: 0.0514\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0580 - mean_absolute_error: 0.0667\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0464 - mean_absolute_error: 0.0948\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0396 - mean_absolute_error: 0.1034\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 453us/sample - loss: 0.0140 - mean_absolute_error: 0.0828\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 453us/sample - loss: 0.0093 - mean_absolute_error: 0.0716\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 472us/sample - loss: 0.0133 - mean_absolute_error: 0.0495\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.0079 - mean_absolute_error: 0.0448\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0059 - mean_absolute_error: 0.0453\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.0067 - mean_absolute_error: 0.0382\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 452us/sample - loss: 0.0024 - mean_absolute_error: 0.0327\n",
      "110/110 [==============================] - 0s 538us/sample - loss: 0.9841 - mean_absolute_error: 0.6903\n",
      "220/220 [==============================] - 0s 162us/sample - loss: 0.0019 - mean_absolute_error: 0.0221\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_375 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_376 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_377 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_378 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_379 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 995us/sample - loss: 1.4001 - mean_absolute_error: 0.9144\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 442us/sample - loss: 0.6098 - mean_absolute_error: 0.5427\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.4295 - mean_absolute_error: 0.5247\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.2445 - mean_absolute_error: 0.3604\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 0.2223 - mean_absolute_error: 0.3104\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.2633 - mean_absolute_error: 0.3103\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.1314 - mean_absolute_error: 0.2312\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 452us/sample - loss: 0.0483 - mean_absolute_error: 0.1498\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0437 - mean_absolute_error: 0.1366\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0473 - mean_absolute_error: 0.1557\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 468us/sample - loss: 0.0525 - mean_absolute_error: 0.1763\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0432 - mean_absolute_error: 0.1654\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 458us/sample - loss: 0.0349 - mean_absolute_error: 0.1354\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 459us/sample - loss: 0.0150 - mean_absolute_error: 0.0790\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.0129 - mean_absolute_error: 0.0595\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 473us/sample - loss: 0.0067 - mean_absolute_error: 0.0548\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0111 - mean_absolute_error: 0.0586\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0067 - mean_absolute_error: 0.0566\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 443us/sample - loss: 0.0029 - mean_absolute_error: 0.0344\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.0070 - mean_absolute_error: 0.0367\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 456us/sample - loss: 0.0033 - mean_absolute_error: 0.0283\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 456us/sample - loss: 0.0014 - mean_absolute_error: 0.0214\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 453us/sample - loss: 0.0025 - mean_absolute_error: 0.0229\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 0.0026 - mean_absolute_error: 0.0231\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 441us/sample - loss: 0.0026 - mean_absolute_error: 0.0198\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 481us/sample - loss: 0.0028 - mean_absolute_error: 0.0239\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.0046 - mean_absolute_error: 0.0298\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 470us/sample - loss: 0.0035 - mean_absolute_error: 0.0287\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0045 - mean_absolute_error: 0.0296\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.0027 - mean_absolute_error: 0.0292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 533us/sample - loss: 1.6767 - mean_absolute_error: 0.7497\n",
      "220/220 [==============================] - 0s 166us/sample - loss: 0.0018 - mean_absolute_error: 0.0309\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_380 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_381 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_382 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_383 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_384 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5894 - mean_absolute_error: 0.9133\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 1.1385 - mean_absolute_error: 0.7621\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.6275 - mean_absolute_error: 0.5669\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 478us/sample - loss: 0.3204 - mean_absolute_error: 0.3932\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.2370 - mean_absolute_error: 0.3027\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 470us/sample - loss: 0.1175 - mean_absolute_error: 0.2303\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.1515 - mean_absolute_error: 0.1925\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.1226 - mean_absolute_error: 0.1872\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.1009 - mean_absolute_error: 0.1552\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 481us/sample - loss: 0.0553 - mean_absolute_error: 0.1433\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 479us/sample - loss: 0.0716 - mean_absolute_error: 0.1709\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 472us/sample - loss: 0.0646 - mean_absolute_error: 0.1714\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.0541 - mean_absolute_error: 0.1793\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 478us/sample - loss: 0.0709 - mean_absolute_error: 0.1561\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.0778 - mean_absolute_error: 0.1677\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 482us/sample - loss: 0.0766 - mean_absolute_error: 0.1716\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0801 - mean_absolute_error: 0.1640\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.1834 - mean_absolute_error: 0.1609\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 480us/sample - loss: 0.1112 - mean_absolute_error: 0.1837\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.1311 - mean_absolute_error: 0.1669\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0952 - mean_absolute_error: 0.1347\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.1296 - mean_absolute_error: 0.1567\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0998 - mean_absolute_error: 0.1594\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.1227 - mean_absolute_error: 0.2198\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.0527 - mean_absolute_error: 0.1509\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 475us/sample - loss: 0.0433 - mean_absolute_error: 0.1285\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0826 - mean_absolute_error: 0.1596\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.0630 - mean_absolute_error: 0.1223\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.1678 - mean_absolute_error: 0.1524\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0481 - mean_absolute_error: 0.1382\n",
      "110/110 [==============================] - 0s 542us/sample - loss: 0.7658 - mean_absolute_error: 0.6108\n",
      "220/220 [==============================] - 0s 162us/sample - loss: 0.0324 - mean_absolute_error: 0.0912\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_385 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_386 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_387 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_388 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_389 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5282 - mean_absolute_error: 0.9034\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.9833 - mean_absolute_error: 0.6681\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.5117 - mean_absolute_error: 0.5091\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 456us/sample - loss: 0.5620 - mean_absolute_error: 0.4080\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 453us/sample - loss: 0.2547 - mean_absolute_error: 0.3525\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.4219 - mean_absolute_error: 0.3047\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.3072 - mean_absolute_error: 0.3394\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.2388 - mean_absolute_error: 0.3008\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 457us/sample - loss: 0.1597 - mean_absolute_error: 0.2732\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 457us/sample - loss: 0.1020 - mean_absolute_error: 0.2054\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.0799 - mean_absolute_error: 0.1985\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 472us/sample - loss: 0.0706 - mean_absolute_error: 0.1869\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0417 - mean_absolute_error: 0.1668\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0234 - mean_absolute_error: 0.1117\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0171 - mean_absolute_error: 0.0719\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0415 - mean_absolute_error: 0.0683\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 473us/sample - loss: 0.1494 - mean_absolute_error: 0.0902\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 465us/sample - loss: 0.0863 - mean_absolute_error: 0.0951\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.0144 - mean_absolute_error: 0.0838\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 476us/sample - loss: 0.0257 - mean_absolute_error: 0.0773\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0112 - mean_absolute_error: 0.0508\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 452us/sample - loss: 0.0146 - mean_absolute_error: 0.0471\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.0071 - mean_absolute_error: 0.0363\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.0076 - mean_absolute_error: 0.0384\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.0070 - mean_absolute_error: 0.0393\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0038 - mean_absolute_error: 0.0317\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 452us/sample - loss: 0.0043 - mean_absolute_error: 0.0373\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0028 - mean_absolute_error: 0.0338\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0017 - mean_absolute_error: 0.0294\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 459us/sample - loss: 0.0013 - mean_absolute_error: 0.0234\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 9.6305e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 7.5174e-04 - mean_absolute_error: 0.0149\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 6.5584e-04 - mean_absolute_error: 0.0120\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0015 - mean_absolute_error: 0.0139\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.0010 - mean_absolute_error: 0.0194\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 459us/sample - loss: 0.0073 - mean_absolute_error: 0.0249\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 9.2122e-04 - mean_absolute_error: 0.0194\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0208 - mean_absolute_error: 0.0277\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 470us/sample - loss: 0.0280 - mean_absolute_error: 0.0873\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.1844 - mean_absolute_error: 0.1902\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 465us/sample - loss: 0.1872 - mean_absolute_error: 0.2072\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.1409 - mean_absolute_error: 0.2189\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.1670 - mean_absolute_error: 0.2005\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 458us/sample - loss: 0.0770 - mean_absolute_error: 0.2044\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 481us/sample - loss: 0.0830 - mean_absolute_error: 0.1820\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0733 - mean_absolute_error: 0.1586\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.1910 - mean_absolute_error: 0.1669\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 476us/sample - loss: 0.0874 - mean_absolute_error: 0.1438\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 475us/sample - loss: 0.0357 - mean_absolute_error: 0.1127\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0275 - mean_absolute_error: 0.0867\n",
      "110/110 [==============================] - 0s 542us/sample - loss: 1.0145 - mean_absolute_error: 0.6750\n",
      "220/220 [==============================] - 0s 154us/sample - loss: 0.0134 - mean_absolute_error: 0.0775\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_390 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_391 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_392 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_393 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_394 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.8893 - mean_absolute_error: 0.7085\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.7092 - mean_absolute_error: 0.5816\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.4940 - mean_absolute_error: 0.5006\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.5460 - mean_absolute_error: 0.5701\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.2165 - mean_absolute_error: 0.3570\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 457us/sample - loss: 0.1158 - mean_absolute_error: 0.2564\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.0406 - mean_absolute_error: 0.1528\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0333 - mean_absolute_error: 0.1221\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0281 - mean_absolute_error: 0.1044\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 459us/sample - loss: 0.0132 - mean_absolute_error: 0.0724\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0139 - mean_absolute_error: 0.0628\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.0081 - mean_absolute_error: 0.0551\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0185 - mean_absolute_error: 0.0720\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 468us/sample - loss: 0.0158 - mean_absolute_error: 0.0785\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0112 - mean_absolute_error: 0.0794\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0175 - mean_absolute_error: 0.0851\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 472us/sample - loss: 0.0132 - mean_absolute_error: 0.0782\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 465us/sample - loss: 0.0174 - mean_absolute_error: 0.0798\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 442us/sample - loss: 0.0112 - mean_absolute_error: 0.0705\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 470us/sample - loss: 0.0099 - mean_absolute_error: 0.0609\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 468us/sample - loss: 0.0083 - mean_absolute_error: 0.0575\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.0071 - mean_absolute_error: 0.0570\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0067 - mean_absolute_error: 0.0614\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.0089 - mean_absolute_error: 0.0648\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 468us/sample - loss: 0.0114 - mean_absolute_error: 0.0612\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.1043 - mean_absolute_error: 0.1332\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0744 - mean_absolute_error: 0.2106\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 448us/sample - loss: 0.1110 - mean_absolute_error: 0.2488\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.0818 - mean_absolute_error: 0.2187\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 449us/sample - loss: 0.0962 - mean_absolute_error: 0.1642\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0479 - mean_absolute_error: 0.1325\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0558 - mean_absolute_error: 0.1314\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 0.0275 - mean_absolute_error: 0.1070\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 0.0313 - mean_absolute_error: 0.0969\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 468us/sample - loss: 0.0138 - mean_absolute_error: 0.0820\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.0110 - mean_absolute_error: 0.0749\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 452us/sample - loss: 0.0055 - mean_absolute_error: 0.0579\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 452us/sample - loss: 0.0041 - mean_absolute_error: 0.0488\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.0020 - mean_absolute_error: 0.0320\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 482us/sample - loss: 0.0025 - mean_absolute_error: 0.0309\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0020 - mean_absolute_error: 0.0254\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.0021 - mean_absolute_error: 0.0216\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 5.3948e-04 - mean_absolute_error: 0.0144\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.0019 - mean_absolute_error: 0.0153\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 458us/sample - loss: 0.0019 - mean_absolute_error: 0.0205\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 9.7085e-04 - mean_absolute_error: 0.0181\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 8.6066e-04 - mean_absolute_error: 0.0152\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 459us/sample - loss: 5.0499e-04 - mean_absolute_error: 0.0140\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 449us/sample - loss: 4.9968e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 468us/sample - loss: 3.8475e-04 - mean_absolute_error: 0.0131\n",
      "110/110 [==============================] - 0s 531us/sample - loss: 1.5547 - mean_absolute_error: 0.7552\n",
      "220/220 [==============================] - 0s 160us/sample - loss: 2.7621e-04 - mean_absolute_error: 0.0115\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_395 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_396 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_397 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_398 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_399 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5858 - mean_absolute_error: 0.8849\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.9988 - mean_absolute_error: 0.6703\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 442us/sample - loss: 0.5856 - mean_absolute_error: 0.5527\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.5228 - mean_absolute_error: 0.4559\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 473us/sample - loss: 0.1832 - mean_absolute_error: 0.3178\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 456us/sample - loss: 0.2378 - mean_absolute_error: 0.3488\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 459us/sample - loss: 0.1440 - mean_absolute_error: 0.2619\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0995 - mean_absolute_error: 0.1932\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0806 - mean_absolute_error: 0.1948\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 457us/sample - loss: 0.1074 - mean_absolute_error: 0.2266\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.0632 - mean_absolute_error: 0.1749\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0501 - mean_absolute_error: 0.1446\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 456us/sample - loss: 0.0304 - mean_absolute_error: 0.1279\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0434 - mean_absolute_error: 0.1253\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 443us/sample - loss: 0.0488 - mean_absolute_error: 0.1266\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0796 - mean_absolute_error: 0.1121\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 465us/sample - loss: 0.0619 - mean_absolute_error: 0.1147\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.0285 - mean_absolute_error: 0.1252\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 459us/sample - loss: 0.0400 - mean_absolute_error: 0.1313\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 470us/sample - loss: 0.0406 - mean_absolute_error: 0.1407\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 447us/sample - loss: 0.0380 - mean_absolute_error: 0.1336\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 453us/sample - loss: 0.0237 - mean_absolute_error: 0.1069\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0242 - mean_absolute_error: 0.1015\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0228 - mean_absolute_error: 0.1023\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 470us/sample - loss: 0.0383 - mean_absolute_error: 0.1157\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 476us/sample - loss: 0.0917 - mean_absolute_error: 0.1730\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.4473 - mean_absolute_error: 0.3628\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.2770 - mean_absolute_error: 0.3510\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0936 - mean_absolute_error: 0.2250\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 449us/sample - loss: 0.1758 - mean_absolute_error: 0.2129\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 515us/sample - loss: 0.1698 - mean_absolute_error: 0.1543\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.0570 - mean_absolute_error: 0.1416\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 453us/sample - loss: 0.1135 - mean_absolute_error: 0.1582\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.1160 - mean_absolute_error: 0.1728\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 456us/sample - loss: 0.1144 - mean_absolute_error: 0.2089\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 475us/sample - loss: 0.1494 - mean_absolute_error: 0.1709\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0464 - mean_absolute_error: 0.1091\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.0548 - mean_absolute_error: 0.0982\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0394 - mean_absolute_error: 0.0762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 446us/sample - loss: 0.0159 - mean_absolute_error: 0.0574\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 457us/sample - loss: 0.0277 - mean_absolute_error: 0.0559\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 449us/sample - loss: 0.1313 - mean_absolute_error: 0.1069\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 453us/sample - loss: 0.1327 - mean_absolute_error: 0.1040\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 457us/sample - loss: 0.0618 - mean_absolute_error: 0.0656\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 459us/sample - loss: 0.0194 - mean_absolute_error: 0.0657\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.0106 - mean_absolute_error: 0.0546\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.0060 - mean_absolute_error: 0.0439\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 0.0026 - mean_absolute_error: 0.0292\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.0108 - mean_absolute_error: 0.0455\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 457us/sample - loss: 0.0078 - mean_absolute_error: 0.0430\n",
      "110/110 [==============================] - 0s 559us/sample - loss: 0.6846 - mean_absolute_error: 0.5963\n",
      "220/220 [==============================] - 0s 174us/sample - loss: 5.4939e-04 - mean_absolute_error: 0.0159\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_400 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_401 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_402 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_403 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_404 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.3334 - mean_absolute_error: 0.7436\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.9689 - mean_absolute_error: 0.7005\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.5456 - mean_absolute_error: 0.4974\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.3670 - mean_absolute_error: 0.3764\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 517us/sample - loss: 0.3188 - mean_absolute_error: 0.3264\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 511us/sample - loss: 0.1076 - mean_absolute_error: 0.2327\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0822 - mean_absolute_error: 0.1895\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 479us/sample - loss: 0.0849 - mean_absolute_error: 0.1752\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.0594 - mean_absolute_error: 0.1784\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.3241 - mean_absolute_error: 0.2092\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.1992 - mean_absolute_error: 0.2070\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0506 - mean_absolute_error: 0.1522\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.1628 - mean_absolute_error: 0.1618\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 548us/sample - loss: 0.1382 - mean_absolute_error: 0.1905\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.0750 - mean_absolute_error: 0.1862\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0426 - mean_absolute_error: 0.1495\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0319 - mean_absolute_error: 0.1305\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0254 - mean_absolute_error: 0.1027\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.0119 - mean_absolute_error: 0.0797\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 511us/sample - loss: 0.0178 - mean_absolute_error: 0.0703\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0101 - mean_absolute_error: 0.0535\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0096 - mean_absolute_error: 0.0479\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 514us/sample - loss: 0.0077 - mean_absolute_error: 0.0393\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.0109 - mean_absolute_error: 0.0364\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 512us/sample - loss: 0.0051 - mean_absolute_error: 0.0392\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 520us/sample - loss: 0.0094 - mean_absolute_error: 0.0343\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0271 - mean_absolute_error: 0.0380\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 510us/sample - loss: 0.0089 - mean_absolute_error: 0.0366\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0024 - mean_absolute_error: 0.0306\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0055 - mean_absolute_error: 0.0283\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.0031 - mean_absolute_error: 0.0269\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0011 - mean_absolute_error: 0.0201\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 507us/sample - loss: 0.0025 - mean_absolute_error: 0.0222\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0015 - mean_absolute_error: 0.0208\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 5.6331e-04 - mean_absolute_error: 0.0162\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 8.5866e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 577us/sample - loss: 9.5826e-04 - mean_absolute_error: 0.0126\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 537us/sample - loss: 0.0011 - mean_absolute_error: 0.0150\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 6.8035e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0011 - mean_absolute_error: 0.0189\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0017 - mean_absolute_error: 0.0213\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0013 - mean_absolute_error: 0.0167\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0011 - mean_absolute_error: 0.0186\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 513us/sample - loss: 0.0044 - mean_absolute_error: 0.0310\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 652us/sample - loss: 0.0047 - mean_absolute_error: 0.0388\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 518us/sample - loss: 0.0064 - mean_absolute_error: 0.0508\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 521us/sample - loss: 0.0073 - mean_absolute_error: 0.0522\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 612us/sample - loss: 0.0146 - mean_absolute_error: 0.0736\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 654us/sample - loss: 0.0103 - mean_absolute_error: 0.0764\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 573us/sample - loss: 0.0145 - mean_absolute_error: 0.0837\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 593us/sample - loss: 0.0106 - mean_absolute_error: 0.0699\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 601us/sample - loss: 0.0099 - mean_absolute_error: 0.0658\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 695us/sample - loss: 0.0145 - mean_absolute_error: 0.0783\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 519us/sample - loss: 0.0260 - mean_absolute_error: 0.0907\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 558us/sample - loss: 0.0233 - mean_absolute_error: 0.0944\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 607us/sample - loss: 0.0313 - mean_absolute_error: 0.1060\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 553us/sample - loss: 0.0356 - mean_absolute_error: 0.1184\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0562 - mean_absolute_error: 0.1497\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 533us/sample - loss: 0.0523 - mean_absolute_error: 0.1443\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 522us/sample - loss: 0.0687 - mean_absolute_error: 0.1382\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 538us/sample - loss: 0.0337 - mean_absolute_error: 0.1275\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 0.1217 - mean_absolute_error: 0.1655\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 582us/sample - loss: 0.1616 - mean_absolute_error: 0.1540\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 536us/sample - loss: 0.0974 - mean_absolute_error: 0.1331\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 520us/sample - loss: 0.0836 - mean_absolute_error: 0.1897\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 550us/sample - loss: 0.7952 - mean_absolute_error: 0.3529\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 525us/sample - loss: 0.4044 - mean_absolute_error: 0.3817\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 538us/sample - loss: 0.2795 - mean_absolute_error: 0.2523\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 520us/sample - loss: 0.4221 - mean_absolute_error: 0.2760\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 533us/sample - loss: 0.3524 - mean_absolute_error: 0.2358\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.2149 - mean_absolute_error: 0.1861\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 589us/sample - loss: 0.0671 - mean_absolute_error: 0.1744\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0562 - mean_absolute_error: 0.1367\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 481us/sample - loss: 0.2067 - mean_absolute_error: 0.1145\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.2917 - mean_absolute_error: 0.1795\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 524us/sample - loss: 0.1937 - mean_absolute_error: 0.2152\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 532us/sample - loss: 0.0774 - mean_absolute_error: 0.1693\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.1314 - mean_absolute_error: 0.1798\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.2055 - mean_absolute_error: 0.1903\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 531us/sample - loss: 0.2545 - mean_absolute_error: 0.2244\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 520us/sample - loss: 0.1228 - mean_absolute_error: 0.1684\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0487 - mean_absolute_error: 0.1345\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 0.0858 - mean_absolute_error: 0.1322\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 513us/sample - loss: 0.1085 - mean_absolute_error: 0.1015\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0305 - mean_absolute_error: 0.0921\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 514us/sample - loss: 0.0261 - mean_absolute_error: 0.0692\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0086 - mean_absolute_error: 0.0552\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.0065 - mean_absolute_error: 0.0442\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0029 - mean_absolute_error: 0.0297\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 510us/sample - loss: 0.0021 - mean_absolute_error: 0.0286\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0017 - mean_absolute_error: 0.0203\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0015 - mean_absolute_error: 0.0167\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 480us/sample - loss: 3.9496e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 4.0983e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 505us/sample - loss: 4.0230e-04 - mean_absolute_error: 0.0100\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 1.6664e-04 - mean_absolute_error: 0.0071\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 510us/sample - loss: 1.0170e-04 - mean_absolute_error: 0.0056\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 4.9143e-05 - mean_absolute_error: 0.0048\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 3.6247e-05 - mean_absolute_error: 0.0039\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 1.9944e-05 - mean_absolute_error: 0.0030\n",
      "110/110 [==============================] - 0s 587us/sample - loss: 0.9369 - mean_absolute_error: 0.6743\n",
      "220/220 [==============================] - 0s 161us/sample - loss: 1.5105e-05 - mean_absolute_error: 0.0022\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_405 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_406 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_407 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_408 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.0929 - mean_absolute_error: 0.8003\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 490us/sample - loss: 1.0071 - mean_absolute_error: 0.7564\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 501us/sample - loss: 0.4890 - mean_absolute_error: 0.5034\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.2439 - mean_absolute_error: 0.3937\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.1298 - mean_absolute_error: 0.2723\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 514us/sample - loss: 0.0894 - mean_absolute_error: 0.2303\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 481us/sample - loss: 0.1084 - mean_absolute_error: 0.2290\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0736 - mean_absolute_error: 0.1869\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 539us/sample - loss: 0.0747 - mean_absolute_error: 0.1702\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0352 - mean_absolute_error: 0.1394\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0260 - mean_absolute_error: 0.1171\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 0.0258 - mean_absolute_error: 0.1086\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 534us/sample - loss: 0.0150 - mean_absolute_error: 0.0833\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 532us/sample - loss: 0.0089 - mean_absolute_error: 0.0658\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 525us/sample - loss: 0.0117 - mean_absolute_error: 0.0508\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0071 - mean_absolute_error: 0.0508\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0109 - mean_absolute_error: 0.0570\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0057 - mean_absolute_error: 0.0494\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 511us/sample - loss: 0.0056 - mean_absolute_error: 0.0479\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 508us/sample - loss: 0.0045 - mean_absolute_error: 0.0382\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 523us/sample - loss: 0.0052 - mean_absolute_error: 0.0353\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 512us/sample - loss: 0.0038 - mean_absolute_error: 0.0323\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.0025 - mean_absolute_error: 0.0284\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 506us/sample - loss: 0.0037 - mean_absolute_error: 0.0257\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 533us/sample - loss: 0.0018 - mean_absolute_error: 0.0277\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 492us/sample - loss: 0.0131 - mean_absolute_error: 0.0421\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 512us/sample - loss: 0.0174 - mean_absolute_error: 0.0561\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.0074 - mean_absolute_error: 0.0468\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 479us/sample - loss: 0.0091 - mean_absolute_error: 0.0507\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0042 - mean_absolute_error: 0.0345\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 476us/sample - loss: 0.0037 - mean_absolute_error: 0.0356\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0033 - mean_absolute_error: 0.0353\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 480us/sample - loss: 0.0018 - mean_absolute_error: 0.0274\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0026 - mean_absolute_error: 0.0258\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 476us/sample - loss: 0.0030 - mean_absolute_error: 0.0344\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 480us/sample - loss: 0.0037 - mean_absolute_error: 0.0406\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0068 - mean_absolute_error: 0.0410\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0039 - mean_absolute_error: 0.0408\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.0036 - mean_absolute_error: 0.0333\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 526us/sample - loss: 0.0028 - mean_absolute_error: 0.0288\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 493us/sample - loss: 0.0026 - mean_absolute_error: 0.0244\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0018 - mean_absolute_error: 0.0205\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0056 - mean_absolute_error: 0.0227\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.0030 - mean_absolute_error: 0.0264\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 468us/sample - loss: 0.0022 - mean_absolute_error: 0.0290\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.0031 - mean_absolute_error: 0.0324\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.0040 - mean_absolute_error: 0.0363\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0083 - mean_absolute_error: 0.0433\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.0077 - mean_absolute_error: 0.0521\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 458us/sample - loss: 0.0535 - mean_absolute_error: 0.0898\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0640 - mean_absolute_error: 0.1120\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.0395 - mean_absolute_error: 0.1026\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0291 - mean_absolute_error: 0.1203\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 473us/sample - loss: 0.0594 - mean_absolute_error: 0.1522\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 479us/sample - loss: 0.0604 - mean_absolute_error: 0.1357\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 0.0318 - mean_absolute_error: 0.1124\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 494us/sample - loss: 0.0341 - mean_absolute_error: 0.1101\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 511us/sample - loss: 0.0318 - mean_absolute_error: 0.1112\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 515us/sample - loss: 0.0263 - mean_absolute_error: 0.1085\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.0371 - mean_absolute_error: 0.1209\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0214 - mean_absolute_error: 0.0925\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 515us/sample - loss: 0.0200 - mean_absolute_error: 0.0958\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 465us/sample - loss: 0.0270 - mean_absolute_error: 0.0931\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.0207 - mean_absolute_error: 0.0998\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0359 - mean_absolute_error: 0.1053\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.0353 - mean_absolute_error: 0.1300\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.0700 - mean_absolute_error: 0.1707\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.0597 - mean_absolute_error: 0.1803\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0440 - mean_absolute_error: 0.1511\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 489us/sample - loss: 0.0401 - mean_absolute_error: 0.1438\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0363 - mean_absolute_error: 0.1374\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.0310 - mean_absolute_error: 0.1148\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.0187 - mean_absolute_error: 0.0878\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 484us/sample - loss: 0.0937 - mean_absolute_error: 0.1008\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.0661 - mean_absolute_error: 0.0849\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0246 - mean_absolute_error: 0.0842\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0487 - mean_absolute_error: 0.0865\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 460us/sample - loss: 0.0953 - mean_absolute_error: 0.1154\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 491us/sample - loss: 0.0659 - mean_absolute_error: 0.1171\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 535us/sample - loss: 0.0313 - mean_absolute_error: 0.0821\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 520us/sample - loss: 0.0591 - mean_absolute_error: 0.0790\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.0245 - mean_absolute_error: 0.0705\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0506 - mean_absolute_error: 0.0636\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.0204 - mean_absolute_error: 0.0505\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 509us/sample - loss: 0.0099 - mean_absolute_error: 0.0415\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.0182 - mean_absolute_error: 0.0387\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 497us/sample - loss: 0.0151 - mean_absolute_error: 0.0472\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.0262 - mean_absolute_error: 0.0747\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 479us/sample - loss: 0.0308 - mean_absolute_error: 0.0864\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.0244 - mean_absolute_error: 0.0727\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 514us/sample - loss: 0.0084 - mean_absolute_error: 0.0528\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 504us/sample - loss: 0.0060 - mean_absolute_error: 0.0387\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 507us/sample - loss: 0.0030 - mean_absolute_error: 0.0319\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 472us/sample - loss: 0.0027 - mean_absolute_error: 0.0318\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 500us/sample - loss: 0.0015 - mean_absolute_error: 0.0248\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 7.4432e-04 - mean_absolute_error: 0.0169\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 503us/sample - loss: 4.4293e-04 - mean_absolute_error: 0.0138\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 3.2830e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 1.6797e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 478us/sample - loss: 1.1595e-04 - mean_absolute_error: 0.0070\n",
      "110/110 [==============================] - 0s 523us/sample - loss: 1.6046 - mean_absolute_error: 0.7893\n",
      "220/220 [==============================] - 0s 167us/sample - loss: 4.2342e-05 - mean_absolute_error: 0.0045\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_410 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_411 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_412 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_413 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_414 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5057 - mean_absolute_error: 0.8419\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 440us/sample - loss: 0.9206 - mean_absolute_error: 0.6882\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.4930 - mean_absolute_error: 0.5225\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 471us/sample - loss: 0.8248 - mean_absolute_error: 0.5973\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.3342 - mean_absolute_error: 0.4267\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 472us/sample - loss: 0.1778 - mean_absolute_error: 0.2797\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 478us/sample - loss: 0.1728 - mean_absolute_error: 0.2686\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 502us/sample - loss: 0.1530 - mean_absolute_error: 0.2659\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 517us/sample - loss: 0.1104 - mean_absolute_error: 0.1971\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 496us/sample - loss: 0.1049 - mean_absolute_error: 0.2103\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 484us/sample - loss: 0.0689 - mean_absolute_error: 0.1656\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 472us/sample - loss: 0.0431 - mean_absolute_error: 0.1362\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 486us/sample - loss: 0.0319 - mean_absolute_error: 0.1137\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.0169 - mean_absolute_error: 0.0873\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 498us/sample - loss: 0.0087 - mean_absolute_error: 0.0631\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.0113 - mean_absolute_error: 0.0556\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0215 - mean_absolute_error: 0.0629\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 467us/sample - loss: 0.0198 - mean_absolute_error: 0.0798\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 499us/sample - loss: 0.0268 - mean_absolute_error: 0.0914\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 487us/sample - loss: 0.0110 - mean_absolute_error: 0.0801\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 453us/sample - loss: 0.0334 - mean_absolute_error: 0.0882\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - ETA: 0s - loss: 0.0114 - mean_absolute_error: 0.079 - 0s 458us/sample - loss: 0.0109 - mean_absolute_error: 0.0742\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 450us/sample - loss: 0.0312 - mean_absolute_error: 0.0656\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 473us/sample - loss: 0.0879 - mean_absolute_error: 0.0686\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 476us/sample - loss: 0.0630 - mean_absolute_error: 0.0800\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 516us/sample - loss: 0.0214 - mean_absolute_error: 0.0686\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 517us/sample - loss: 0.0437 - mean_absolute_error: 0.0710\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 479us/sample - loss: 0.0829 - mean_absolute_error: 0.0950\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 473us/sample - loss: 0.0562 - mean_absolute_error: 0.1255\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 453us/sample - loss: 0.0359 - mean_absolute_error: 0.1246\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0385 - mean_absolute_error: 0.1356\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 456us/sample - loss: 0.0516 - mean_absolute_error: 0.1428\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0331 - mean_absolute_error: 0.1315\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 447us/sample - loss: 0.0493 - mean_absolute_error: 0.1499\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0580 - mean_absolute_error: 0.1517\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0656 - mean_absolute_error: 0.1303\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 467us/sample - loss: 0.0404 - mean_absolute_error: 0.1205\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 458us/sample - loss: 0.0466 - mean_absolute_error: 0.1247\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0378 - mean_absolute_error: 0.1107\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0416 - mean_absolute_error: 0.1155\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 459us/sample - loss: 0.0277 - mean_absolute_error: 0.1100\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 459us/sample - loss: 0.0336 - mean_absolute_error: 0.1107\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.0324 - mean_absolute_error: 0.1118\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 448us/sample - loss: 0.0219 - mean_absolute_error: 0.0840\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0317 - mean_absolute_error: 0.0881\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 449us/sample - loss: 0.0695 - mean_absolute_error: 0.0869\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0716 - mean_absolute_error: 0.0962\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.0355 - mean_absolute_error: 0.0884\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 450us/sample - loss: 0.0141 - mean_absolute_error: 0.0531\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 448us/sample - loss: 0.0070 - mean_absolute_error: 0.0439\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 450us/sample - loss: 0.0091 - mean_absolute_error: 0.0427\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 450us/sample - loss: 0.0023 - mean_absolute_error: 0.0250\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 448us/sample - loss: 0.0028 - mean_absolute_error: 0.0231\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 464us/sample - loss: 0.0010 - mean_absolute_error: 0.0183\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 0.0018 - mean_absolute_error: 0.0198\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 9.3821e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 4.3562e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 4.3555e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 2.3963e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 449us/sample - loss: 2.7891e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 2.3799e-04 - mean_absolute_error: 0.0070\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 457us/sample - loss: 2.5356e-04 - mean_absolute_error: 0.0065\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 456us/sample - loss: 4.2863e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 483us/sample - loss: 0.0031 - mean_absolute_error: 0.0217\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 456us/sample - loss: 0.0053 - mean_absolute_error: 0.0323\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 470us/sample - loss: 0.0087 - mean_absolute_error: 0.0425\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 468us/sample - loss: 0.0041 - mean_absolute_error: 0.0331\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0030 - mean_absolute_error: 0.0305\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0086 - mean_absolute_error: 0.0387\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 442us/sample - loss: 0.0147 - mean_absolute_error: 0.0482\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 448us/sample - loss: 0.0103 - mean_absolute_error: 0.0580\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 474us/sample - loss: 0.0164 - mean_absolute_error: 0.0723\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 463us/sample - loss: 0.0136 - mean_absolute_error: 0.0672\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 485us/sample - loss: 0.0189 - mean_absolute_error: 0.0818\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 450us/sample - loss: 0.0103 - mean_absolute_error: 0.0742\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.0106 - mean_absolute_error: 0.0617\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0114 - mean_absolute_error: 0.0693\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 495us/sample - loss: 0.0107 - mean_absolute_error: 0.0632\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 470us/sample - loss: 0.0074 - mean_absolute_error: 0.0584\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 457us/sample - loss: 0.0054 - mean_absolute_error: 0.0502\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 466us/sample - loss: 0.0042 - mean_absolute_error: 0.0406\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 462us/sample - loss: 0.0054 - mean_absolute_error: 0.0432\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 488us/sample - loss: 0.0046 - mean_absolute_error: 0.0396\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 447us/sample - loss: 0.0081 - mean_absolute_error: 0.0431\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 460us/sample - loss: 0.0121 - mean_absolute_error: 0.0483\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 461us/sample - loss: 0.0145 - mean_absolute_error: 0.0573\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 443us/sample - loss: 0.0090 - mean_absolute_error: 0.0549\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 450us/sample - loss: 0.0107 - mean_absolute_error: 0.0554\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 469us/sample - loss: 0.0205 - mean_absolute_error: 0.0769\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 468us/sample - loss: 0.0370 - mean_absolute_error: 0.1035\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 477us/sample - loss: 0.0216 - mean_absolute_error: 0.0841\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 454us/sample - loss: 0.0351 - mean_absolute_error: 0.0891\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 442us/sample - loss: 0.0396 - mean_absolute_error: 0.1162\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 456us/sample - loss: 0.0363 - mean_absolute_error: 0.1172\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 445us/sample - loss: 0.0357 - mean_absolute_error: 0.1329\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 475us/sample - loss: 0.0428 - mean_absolute_error: 0.1411\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 455us/sample - loss: 0.0275 - mean_absolute_error: 0.1316\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 448us/sample - loss: 0.0415 - mean_absolute_error: 0.1331\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 451us/sample - loss: 0.0410 - mean_absolute_error: 0.1231\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 465us/sample - loss: 0.0202 - mean_absolute_error: 0.0923\n",
      "110/110 [==============================] - 0s 549us/sample - loss: 0.7037 - mean_absolute_error: 0.6022\n",
      "220/220 [==============================] - 0s 166us/sample - loss: 0.0049 - mean_absolute_error: 0.0478\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_415 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_416 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_417 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_418 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_419 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5945 - mean_absolute_error: 0.8845\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 0.8772 - mean_absolute_error: 0.7250\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.4577 - mean_absolute_error: 0.4829\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.2553 - mean_absolute_error: 0.3651\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 0.2213 - mean_absolute_error: 0.3348\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.2209 - mean_absolute_error: 0.3072\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 0.1899 - mean_absolute_error: 0.2753\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0654 - mean_absolute_error: 0.1782\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.0689 - mean_absolute_error: 0.1393\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0693 - mean_absolute_error: 0.1226\n",
      "110/110 [==============================] - 0s 541us/sample - loss: 0.9876 - mean_absolute_error: 0.6732\n",
      "220/220 [==============================] - 0s 144us/sample - loss: 0.0256 - mean_absolute_error: 0.0911\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_420 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_421 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_423 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_424 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 922us/sample - loss: 1.1615 - mean_absolute_error: 0.8564\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 359us/sample - loss: 0.7746 - mean_absolute_error: 0.6289\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.5667 - mean_absolute_error: 0.5661\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 0.2579 - mean_absolute_error: 0.3616\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.1732 - mean_absolute_error: 0.3140\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.1844 - mean_absolute_error: 0.2978\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.1229 - mean_absolute_error: 0.2654\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.1277 - mean_absolute_error: 0.2466\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 0.0771 - mean_absolute_error: 0.1967\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 0.0354 - mean_absolute_error: 0.1189\n",
      "110/110 [==============================] - 0s 534us/sample - loss: 1.6656 - mean_absolute_error: 0.7470\n",
      "220/220 [==============================] - 0s 137us/sample - loss: 0.0321 - mean_absolute_error: 0.1289\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_425 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_426 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_427 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_428 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_429 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 0s 914us/sample - loss: 1.5556 - mean_absolute_error: 0.8568\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.8686 - mean_absolute_error: 0.6830\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.3907 - mean_absolute_error: 0.4292\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.1678 - mean_absolute_error: 0.3020\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 0s 368us/sample - loss: 0.1431 - mean_absolute_error: 0.2376\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 0s 376us/sample - loss: 0.0987 - mean_absolute_error: 0.2180\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 0s 359us/sample - loss: 0.1165 - mean_absolute_error: 0.2112\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.1048 - mean_absolute_error: 0.1821\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.1342 - mean_absolute_error: 0.2576\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.1462 - mean_absolute_error: 0.2690\n",
      "110/110 [==============================] - 0s 534us/sample - loss: 0.9203 - mean_absolute_error: 0.7556\n",
      "220/220 [==============================] - 0s 161us/sample - loss: 0.1994 - mean_absolute_error: 0.3925\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_430 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_431 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_432 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_433 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_434 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 916us/sample - loss: 1.4613 - mean_absolute_error: 0.8358\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 0.7071 - mean_absolute_error: 0.6091\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.3987 - mean_absolute_error: 0.4104\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.4312 - mean_absolute_error: 0.4881\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 358us/sample - loss: 0.6481 - mean_absolute_error: 0.5089\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 0.5999 - mean_absolute_error: 0.6505\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 324us/sample - loss: 0.2809 - mean_absolute_error: 0.3820\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 377us/sample - loss: 0.1393 - mean_absolute_error: 0.2642\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 381us/sample - loss: 0.1328 - mean_absolute_error: 0.2738\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0534 - mean_absolute_error: 0.1702\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 367us/sample - loss: 0.1177 - mean_absolute_error: 0.1505\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 0.0771 - mean_absolute_error: 0.1850\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0220 - mean_absolute_error: 0.0964\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 359us/sample - loss: 0.0370 - mean_absolute_error: 0.1235\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 0.0128 - mean_absolute_error: 0.0688\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 0.0101 - mean_absolute_error: 0.0677\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 368us/sample - loss: 0.0074 - mean_absolute_error: 0.0467\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 0.0034 - mean_absolute_error: 0.0397\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0021 - mean_absolute_error: 0.0311\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 0.0024 - mean_absolute_error: 0.0283\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 0.0028 - mean_absolute_error: 0.0309\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 0.0045 - mean_absolute_error: 0.0270\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.0026 - mean_absolute_error: 0.0304\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 8.2962e-04 - mean_absolute_error: 0.0184\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0024 - mean_absolute_error: 0.0239\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 8.8587e-04 - mean_absolute_error: 0.0189\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 6.9016e-04 - mean_absolute_error: 0.0157\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 8.2956e-04 - mean_absolute_error: 0.0159\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 2.5308e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 2.8603e-04 - mean_absolute_error: 0.0107\n",
      "110/110 [==============================] - 0s 549us/sample - loss: 1.0032 - mean_absolute_error: 0.7103\n",
      "220/220 [==============================] - 0s 142us/sample - loss: 1.3607e-04 - mean_absolute_error: 0.0072\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_435 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_436 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_437 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_438 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_439 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 926us/sample - loss: 0.9559 - mean_absolute_error: 0.7589\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 387us/sample - loss: 0.5198 - mean_absolute_error: 0.4851\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 359us/sample - loss: 0.1989 - mean_absolute_error: 0.3249\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 373us/sample - loss: 0.1347 - mean_absolute_error: 0.2522\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 367us/sample - loss: 0.1335 - mean_absolute_error: 0.2579\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 376us/sample - loss: 0.1610 - mean_absolute_error: 0.2706\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 385us/sample - loss: 0.1108 - mean_absolute_error: 0.2568\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 369us/sample - loss: 0.0882 - mean_absolute_error: 0.2050\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 381us/sample - loss: 0.0572 - mean_absolute_error: 0.1712\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 392us/sample - loss: 0.0509 - mean_absolute_error: 0.1626\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 381us/sample - loss: 0.0265 - mean_absolute_error: 0.1128\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 0.0269 - mean_absolute_error: 0.1148\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 405us/sample - loss: 0.0159 - mean_absolute_error: 0.0967\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 369us/sample - loss: 0.0364 - mean_absolute_error: 0.1052\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 370us/sample - loss: 0.0813 - mean_absolute_error: 0.1769\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 0.0864 - mean_absolute_error: 0.2196\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 360us/sample - loss: 0.0515 - mean_absolute_error: 0.1749\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0345 - mean_absolute_error: 0.1468\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 379us/sample - loss: 0.0168 - mean_absolute_error: 0.0919\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 384us/sample - loss: 0.0110 - mean_absolute_error: 0.0702\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 380us/sample - loss: 0.0067 - mean_absolute_error: 0.0603\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 388us/sample - loss: 0.0065 - mean_absolute_error: 0.0574\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 404us/sample - loss: 0.0041 - mean_absolute_error: 0.0426\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 367us/sample - loss: 0.0034 - mean_absolute_error: 0.0385\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 365us/sample - loss: 0.0027 - mean_absolute_error: 0.0346\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 367us/sample - loss: 0.0031 - mean_absolute_error: 0.0378\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 379us/sample - loss: 0.0027 - mean_absolute_error: 0.0357\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 382us/sample - loss: 0.0010 - mean_absolute_error: 0.0242\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 379us/sample - loss: 0.0013 - mean_absolute_error: 0.0248\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 8.2352e-04 - mean_absolute_error: 0.0192\n",
      "110/110 [==============================] - 0s 566us/sample - loss: 1.5694 - mean_absolute_error: 0.7517\n",
      "220/220 [==============================] - 0s 142us/sample - loss: 9.9298e-04 - mean_absolute_error: 0.0221\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_440 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_441 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_442 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_443 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_444 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "220/220 [==============================] - 0s 921us/sample - loss: 1.8360 - mean_absolute_error: 0.9887\n",
      "Epoch 2/30\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 1.0276 - mean_absolute_error: 0.7538\n",
      "Epoch 3/30\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 0.4763 - mean_absolute_error: 0.4891\n",
      "Epoch 4/30\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.3122 - mean_absolute_error: 0.3671\n",
      "Epoch 5/30\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 0.2746 - mean_absolute_error: 0.2892\n",
      "Epoch 6/30\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 0.0846 - mean_absolute_error: 0.2255\n",
      "Epoch 7/30\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 0.0768 - mean_absolute_error: 0.2045\n",
      "Epoch 8/30\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.0737 - mean_absolute_error: 0.2072\n",
      "Epoch 9/30\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.1498 - mean_absolute_error: 0.2352\n",
      "Epoch 10/30\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0737 - mean_absolute_error: 0.2202\n",
      "Epoch 11/30\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0567 - mean_absolute_error: 0.1717\n",
      "Epoch 12/30\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.0304 - mean_absolute_error: 0.1238\n",
      "Epoch 13/30\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0335 - mean_absolute_error: 0.1136\n",
      "Epoch 14/30\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0280 - mean_absolute_error: 0.1072\n",
      "Epoch 15/30\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0206 - mean_absolute_error: 0.0912\n",
      "Epoch 16/30\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0078 - mean_absolute_error: 0.0563\n",
      "Epoch 17/30\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0044 - mean_absolute_error: 0.0473\n",
      "Epoch 18/30\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0055 - mean_absolute_error: 0.0478\n",
      "Epoch 19/30\n",
      "220/220 [==============================] - 0s 356us/sample - loss: 0.0044 - mean_absolute_error: 0.0436\n",
      "Epoch 20/30\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0031 - mean_absolute_error: 0.0327\n",
      "Epoch 21/30\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 0.0017 - mean_absolute_error: 0.0262\n",
      "Epoch 22/30\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 0.0037 - mean_absolute_error: 0.0292\n",
      "Epoch 23/30\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 0.0011 - mean_absolute_error: 0.0220\n",
      "Epoch 24/30\n",
      "220/220 [==============================] - 0s 371us/sample - loss: 0.0011 - mean_absolute_error: 0.0199\n",
      "Epoch 25/30\n",
      "220/220 [==============================] - 0s 370us/sample - loss: 5.8599e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 26/30\n",
      "220/220 [==============================] - 0s 374us/sample - loss: 6.1959e-04 - mean_absolute_error: 0.0158\n",
      "Epoch 27/30\n",
      "220/220 [==============================] - 0s 363us/sample - loss: 4.2649e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 28/30\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 2.8530e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 29/30\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 3.9436e-04 - mean_absolute_error: 0.0110\n",
      "Epoch 30/30\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 2.6746e-04 - mean_absolute_error: 0.0109\n",
      "110/110 [==============================] - 0s 530us/sample - loss: 0.6958 - mean_absolute_error: 0.5896\n",
      "220/220 [==============================] - 0s 151us/sample - loss: 2.4671e-04 - mean_absolute_error: 0.0111\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_445 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_446 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_447 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_448 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_449 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.6512 - mean_absolute_error: 0.9415\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.9091 - mean_absolute_error: 0.7686\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.5910 - mean_absolute_error: 0.5152\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.7907 - mean_absolute_error: 0.6029\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 368us/sample - loss: 0.3421 - mean_absolute_error: 0.3863\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.4552 - mean_absolute_error: 0.3493\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.3086 - mean_absolute_error: 0.3714\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.1105 - mean_absolute_error: 0.2353\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0394 - mean_absolute_error: 0.1467\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 375us/sample - loss: 0.0455 - mean_absolute_error: 0.1547\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 359us/sample - loss: 0.0283 - mean_absolute_error: 0.1205\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 0.0171 - mean_absolute_error: 0.0933\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 371us/sample - loss: 0.0102 - mean_absolute_error: 0.0675\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 367us/sample - loss: 0.0121 - mean_absolute_error: 0.0661\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 360us/sample - loss: 0.0082 - mean_absolute_error: 0.0684\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0125 - mean_absolute_error: 0.0520\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 367us/sample - loss: 0.0227 - mean_absolute_error: 0.0837\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 0.0220 - mean_absolute_error: 0.0862\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 0.0063 - mean_absolute_error: 0.0503\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 360us/sample - loss: 0.0107 - mean_absolute_error: 0.0676\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0048 - mean_absolute_error: 0.0455\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0034 - mean_absolute_error: 0.0380\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.0064 - mean_absolute_error: 0.0406\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0041 - mean_absolute_error: 0.0368\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 0.0023 - mean_absolute_error: 0.0268\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 376us/sample - loss: 0.0013 - mean_absolute_error: 0.0250\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0029 - mean_absolute_error: 0.0249\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 0.0013 - mean_absolute_error: 0.0250\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 365us/sample - loss: 0.0010 - mean_absolute_error: 0.0187\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 362us/sample - loss: 0.0010 - mean_absolute_error: 0.0207\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 358us/sample - loss: 0.0022 - mean_absolute_error: 0.0250\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 0.0026 - mean_absolute_error: 0.0240\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 9.0423e-04 - mean_absolute_error: 0.0179\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 8.6420e-04 - mean_absolute_error: 0.0222\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 9.7921e-04 - mean_absolute_error: 0.0191\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 8.1334e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0012 - mean_absolute_error: 0.0152\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 8.2668e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 2.2531e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0027 - mean_absolute_error: 0.0142\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 3.5256e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0042 - mean_absolute_error: 0.0159\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 6.2320e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0012 - mean_absolute_error: 0.0153\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 5.1153e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 7.1375e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 6.0905e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 3.0999e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0012 - mean_absolute_error: 0.0139\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 8.3464e-04 - mean_absolute_error: 0.0122\n",
      "110/110 [==============================] - 0s 538us/sample - loss: 0.9870 - mean_absolute_error: 0.6714\n",
      "220/220 [==============================] - 0s 141us/sample - loss: 4.5797e-04 - mean_absolute_error: 0.0152\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_450 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_451 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_452 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_453 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_454 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.6117 - mean_absolute_error: 0.9264\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 1.0260 - mean_absolute_error: 0.8359\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 384us/sample - loss: 0.6379 - mean_absolute_error: 0.5653\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 371us/sample - loss: 0.3561 - mean_absolute_error: 0.4912\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.1372 - mean_absolute_error: 0.2719\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0486 - mean_absolute_error: 0.1655\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0535 - mean_absolute_error: 0.1675\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0446 - mean_absolute_error: 0.1539\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0304 - mean_absolute_error: 0.1204\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.0446 - mean_absolute_error: 0.0983\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 0.0239 - mean_absolute_error: 0.1049\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 0.0298 - mean_absolute_error: 0.1173\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 0.0153 - mean_absolute_error: 0.0798\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 0.0199 - mean_absolute_error: 0.0727\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.0347 - mean_absolute_error: 0.0892\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0170 - mean_absolute_error: 0.0927\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 0.0113 - mean_absolute_error: 0.0833\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 359us/sample - loss: 0.0061 - mean_absolute_error: 0.0507\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 0.0066 - mean_absolute_error: 0.0577\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 363us/sample - loss: 0.0068 - mean_absolute_error: 0.0608\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 374us/sample - loss: 0.0039 - mean_absolute_error: 0.0427\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.0024 - mean_absolute_error: 0.0346\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0041 - mean_absolute_error: 0.0449\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 0.0042 - mean_absolute_error: 0.0493\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 367us/sample - loss: 0.0024 - mean_absolute_error: 0.0357\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 384us/sample - loss: 0.0018 - mean_absolute_error: 0.0313\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 375us/sample - loss: 0.0029 - mean_absolute_error: 0.0349\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 375us/sample - loss: 0.0023 - mean_absolute_error: 0.0321\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 0.0012 - mean_absolute_error: 0.0231\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 0.0030 - mean_absolute_error: 0.0246\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 0.0021 - mean_absolute_error: 0.0330\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 365us/sample - loss: 0.0015 - mean_absolute_error: 0.0290\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 337us/sample - loss: 9.0875e-04 - mean_absolute_error: 0.0194\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 0.0022 - mean_absolute_error: 0.0241\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.0013 - mean_absolute_error: 0.0212\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 8.8555e-04 - mean_absolute_error: 0.0176\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 8.9008e-04 - mean_absolute_error: 0.0180\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 3.5161e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 347us/sample - loss: 7.2250e-04 - mean_absolute_error: 0.0147\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 5.8607e-04 - mean_absolute_error: 0.0149\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 9.8213e-04 - mean_absolute_error: 0.0201\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 5.8074e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 4.1385e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.0010 - mean_absolute_error: 0.0172\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 5.9651e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 6.2824e-04 - mean_absolute_error: 0.0153\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 4.7182e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 48/50\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 9.3253e-04 - mean_absolute_error: 0.0151\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0014 - mean_absolute_error: 0.0160\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 8.9341e-04 - mean_absolute_error: 0.0173\n",
      "110/110 [==============================] - 0s 533us/sample - loss: 1.6785 - mean_absolute_error: 0.7635\n",
      "220/220 [==============================] - 0s 149us/sample - loss: 0.0010 - mean_absolute_error: 0.0231\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_455 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_456 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_457 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_458 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_459 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.5105 - mean_absolute_error: 0.8963\n",
      "Epoch 2/50\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.7439 - mean_absolute_error: 0.5926\n",
      "Epoch 3/50\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 0.3071 - mean_absolute_error: 0.4016\n",
      "Epoch 4/50\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 0.2274 - mean_absolute_error: 0.3330\n",
      "Epoch 5/50\n",
      "220/220 [==============================] - 0s 356us/sample - loss: 0.2102 - mean_absolute_error: 0.2854\n",
      "Epoch 6/50\n",
      "220/220 [==============================] - 0s 373us/sample - loss: 0.1252 - mean_absolute_error: 0.2644\n",
      "Epoch 7/50\n",
      "220/220 [==============================] - 0s 363us/sample - loss: 0.1131 - mean_absolute_error: 0.2483\n",
      "Epoch 8/50\n",
      "220/220 [==============================] - 0s 358us/sample - loss: 0.1680 - mean_absolute_error: 0.2463\n",
      "Epoch 9/50\n",
      "220/220 [==============================] - 0s 363us/sample - loss: 0.1140 - mean_absolute_error: 0.2469\n",
      "Epoch 10/50\n",
      "220/220 [==============================] - 0s 358us/sample - loss: 0.1004 - mean_absolute_error: 0.2251\n",
      "Epoch 11/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0683 - mean_absolute_error: 0.1870\n",
      "Epoch 12/50\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 0.0470 - mean_absolute_error: 0.1590\n",
      "Epoch 13/50\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 0.0699 - mean_absolute_error: 0.1822\n",
      "Epoch 14/50\n",
      "220/220 [==============================] - 0s 371us/sample - loss: 0.0412 - mean_absolute_error: 0.1419\n",
      "Epoch 15/50\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.1177 - mean_absolute_error: 0.1395\n",
      "Epoch 16/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0787 - mean_absolute_error: 0.1502\n",
      "Epoch 17/50\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.0572 - mean_absolute_error: 0.1648\n",
      "Epoch 18/50\n",
      "220/220 [==============================] - 0s 375us/sample - loss: 0.0303 - mean_absolute_error: 0.1290\n",
      "Epoch 19/50\n",
      "220/220 [==============================] - 0s 374us/sample - loss: 0.0315 - mean_absolute_error: 0.1080\n",
      "Epoch 20/50\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 0.0282 - mean_absolute_error: 0.1028\n",
      "Epoch 21/50\n",
      "220/220 [==============================] - 0s 370us/sample - loss: 0.0166 - mean_absolute_error: 0.1002\n",
      "Epoch 22/50\n",
      "220/220 [==============================] - 0s 383us/sample - loss: 0.0164 - mean_absolute_error: 0.0880\n",
      "Epoch 23/50\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 0.0124 - mean_absolute_error: 0.0682\n",
      "Epoch 24/50\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 0.0064 - mean_absolute_error: 0.0499\n",
      "Epoch 25/50\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.0041 - mean_absolute_error: 0.0408\n",
      "Epoch 26/50\n",
      "220/220 [==============================] - 0s 365us/sample - loss: 0.0034 - mean_absolute_error: 0.0382\n",
      "Epoch 27/50\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 0.0033 - mean_absolute_error: 0.0383\n",
      "Epoch 28/50\n",
      "220/220 [==============================] - 0s 371us/sample - loss: 0.0030 - mean_absolute_error: 0.0380\n",
      "Epoch 29/50\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0015 - mean_absolute_error: 0.0274\n",
      "Epoch 30/50\n",
      "220/220 [==============================] - 0s 390us/sample - loss: 9.1921e-04 - mean_absolute_error: 0.0206\n",
      "Epoch 31/50\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0010 - mean_absolute_error: 0.0222\n",
      "Epoch 32/50\n",
      "220/220 [==============================] - 0s 368us/sample - loss: 0.0011 - mean_absolute_error: 0.0242\n",
      "Epoch 33/50\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 9.6208e-04 - mean_absolute_error: 0.0224\n",
      "Epoch 34/50\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 0.0010 - mean_absolute_error: 0.0193\n",
      "Epoch 35/50\n",
      "220/220 [==============================] - 0s 337us/sample - loss: 5.1112e-04 - mean_absolute_error: 0.0146\n",
      "Epoch 36/50\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 7.4382e-04 - mean_absolute_error: 0.0150\n",
      "Epoch 37/50\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 5.5503e-04 - mean_absolute_error: 0.0145\n",
      "Epoch 38/50\n",
      "220/220 [==============================] - 0s 376us/sample - loss: 0.0010 - mean_absolute_error: 0.0189\n",
      "Epoch 39/50\n",
      "220/220 [==============================] - 0s 380us/sample - loss: 5.9205e-04 - mean_absolute_error: 0.0186\n",
      "Epoch 40/50\n",
      "220/220 [==============================] - 0s 386us/sample - loss: 9.2298e-04 - mean_absolute_error: 0.0188\n",
      "Epoch 41/50\n",
      "220/220 [==============================] - 0s 375us/sample - loss: 0.0013 - mean_absolute_error: 0.0229\n",
      "Epoch 42/50\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 0.0059 - mean_absolute_error: 0.0291\n",
      "Epoch 43/50\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.0043 - mean_absolute_error: 0.0323\n",
      "Epoch 44/50\n",
      "220/220 [==============================] - 0s 358us/sample - loss: 0.0084 - mean_absolute_error: 0.0461\n",
      "Epoch 45/50\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.0085 - mean_absolute_error: 0.0587\n",
      "Epoch 46/50\n",
      "220/220 [==============================] - 0s 359us/sample - loss: 0.0045 - mean_absolute_error: 0.0540\n",
      "Epoch 47/50\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0088 - mean_absolute_error: 0.0590\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0036 - mean_absolute_error: 0.0409\n",
      "Epoch 49/50\n",
      "220/220 [==============================] - 0s 372us/sample - loss: 0.0143 - mean_absolute_error: 0.0460\n",
      "Epoch 50/50\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.0023 - mean_absolute_error: 0.0324\n",
      "110/110 [==============================] - 0s 529us/sample - loss: 0.7723 - mean_absolute_error: 0.6106\n",
      "220/220 [==============================] - 0s 137us/sample - loss: 0.0042 - mean_absolute_error: 0.0366\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_460 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_461 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_462 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_463 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_464 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 1.7608 - mean_absolute_error: 0.9565\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.7739 - mean_absolute_error: 0.7026\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 356us/sample - loss: 0.5296 - mean_absolute_error: 0.4849\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.4659 - mean_absolute_error: 0.4590\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.4467 - mean_absolute_error: 0.3485\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.2808 - mean_absolute_error: 0.3333\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.1465 - mean_absolute_error: 0.2880\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 356us/sample - loss: 0.1932 - mean_absolute_error: 0.3154\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 356us/sample - loss: 0.1324 - mean_absolute_error: 0.2700\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0763 - mean_absolute_error: 0.1920\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0572 - mean_absolute_error: 0.1881\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 356us/sample - loss: 0.0553 - mean_absolute_error: 0.1706\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 0.0214 - mean_absolute_error: 0.0952\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 360us/sample - loss: 0.0290 - mean_absolute_error: 0.1089\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 358us/sample - loss: 0.0338 - mean_absolute_error: 0.1081\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 0.0128 - mean_absolute_error: 0.0630\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0399 - mean_absolute_error: 0.0932\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.0250 - mean_absolute_error: 0.1066\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.1190 - mean_absolute_error: 0.0961\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.1169 - mean_absolute_error: 0.1168\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0545 - mean_absolute_error: 0.0726\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 356us/sample - loss: 0.0139 - mean_absolute_error: 0.0660\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.0391 - mean_absolute_error: 0.0691\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0089 - mean_absolute_error: 0.0569\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0077 - mean_absolute_error: 0.0419\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 0.0055 - mean_absolute_error: 0.0445\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0033 - mean_absolute_error: 0.0278\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0045 - mean_absolute_error: 0.0282\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 368us/sample - loss: 0.0022 - mean_absolute_error: 0.0199\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.0043 - mean_absolute_error: 0.0214\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0024 - mean_absolute_error: 0.0199\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 0.0021 - mean_absolute_error: 0.0179\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0013 - mean_absolute_error: 0.0191\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0012 - mean_absolute_error: 0.0165\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 6.8536e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 3.3808e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 337us/sample - loss: 4.9742e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 2.1689e-04 - mean_absolute_error: 0.0077\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 363us/sample - loss: 1.7364e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 6.0842e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 365us/sample - loss: 2.1967e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 363us/sample - loss: 1.7951e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 1.1891e-04 - mean_absolute_error: 0.0051\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 1.1362e-04 - mean_absolute_error: 0.0057\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 1.3892e-04 - mean_absolute_error: 0.0050\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 4.7748e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 3.5106e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 2.5312e-04 - mean_absolute_error: 0.0077\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 3.2229e-04 - mean_absolute_error: 0.0102\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 360us/sample - loss: 1.4028e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 3.2376e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 362us/sample - loss: 1.8496e-04 - mean_absolute_error: 0.0072\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 9.0966e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 6.0668e-04 - mean_absolute_error: 0.0119\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 3.9585e-04 - mean_absolute_error: 0.0117\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 2.0861e-04 - mean_absolute_error: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 3.4720e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 1.7465e-04 - mean_absolute_error: 0.0075\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 3.4989e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 1.7611e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 5.0758e-04 - mean_absolute_error: 0.0080\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 1.4442e-04 - mean_absolute_error: 0.0068\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0011 - mean_absolute_error: 0.0115\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 1.5641e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 8.2924e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 2.2104e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 4.8784e-04 - mean_absolute_error: 0.0105\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 1.5796e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 6.7444e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 9.6825e-04 - mean_absolute_error: 0.0130\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0046 - mean_absolute_error: 0.0172\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 7.4908e-04 - mean_absolute_error: 0.0155\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 357us/sample - loss: 0.0085 - mean_absolute_error: 0.0220\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.0048 - mean_absolute_error: 0.0278\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0057 - mean_absolute_error: 0.0316\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 0.0146 - mean_absolute_error: 0.0414\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 369us/sample - loss: 0.0075 - mean_absolute_error: 0.0414\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 324us/sample - loss: 0.0062 - mean_absolute_error: 0.0434\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 327us/sample - loss: 0.0046 - mean_absolute_error: 0.0344\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 360us/sample - loss: 0.0065 - mean_absolute_error: 0.0448\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 377us/sample - loss: 0.0059 - mean_absolute_error: 0.0402\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 360us/sample - loss: 0.0050 - mean_absolute_error: 0.0457\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0063 - mean_absolute_error: 0.0443\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0084 - mean_absolute_error: 0.0425\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 0.0036 - mean_absolute_error: 0.0442\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.0090 - mean_absolute_error: 0.0604\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.0046 - mean_absolute_error: 0.0419\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.0044 - mean_absolute_error: 0.0407\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0036 - mean_absolute_error: 0.0419\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0026 - mean_absolute_error: 0.0396\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0033 - mean_absolute_error: 0.0301\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0021 - mean_absolute_error: 0.0276\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.0019 - mean_absolute_error: 0.0266\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0014 - mean_absolute_error: 0.0212\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 379us/sample - loss: 0.0018 - mean_absolute_error: 0.0214\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 403us/sample - loss: 0.0032 - mean_absolute_error: 0.0259\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.0024 - mean_absolute_error: 0.0276\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0026 - mean_absolute_error: 0.0339\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.0106 - mean_absolute_error: 0.0373\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.0053 - mean_absolute_error: 0.0411\n",
      "110/110 [==============================] - 0s 538us/sample - loss: 1.0108 - mean_absolute_error: 0.6989\n",
      "220/220 [==============================] - 0s 160us/sample - loss: 0.0169 - mean_absolute_error: 0.0519\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_465 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_466 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_467 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_468 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_469 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 1ms/sample - loss: 0.9591 - mean_absolute_error: 0.7300\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 0.5967 - mean_absolute_error: 0.5232\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.3615 - mean_absolute_error: 0.4506\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 0.2525 - mean_absolute_error: 0.3889\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 0.1556 - mean_absolute_error: 0.2908\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.1431 - mean_absolute_error: 0.2659\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0840 - mean_absolute_error: 0.2307\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 377us/sample - loss: 0.0641 - mean_absolute_error: 0.1818\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 378us/sample - loss: 0.0445 - mean_absolute_error: 0.1404\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 354us/sample - loss: 0.0360 - mean_absolute_error: 0.1278\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 370us/sample - loss: 0.0267 - mean_absolute_error: 0.1235\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 0.0236 - mean_absolute_error: 0.1090\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 0.0186 - mean_absolute_error: 0.0878\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 0.0168 - mean_absolute_error: 0.0947\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 0.0135 - mean_absolute_error: 0.0883\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 359us/sample - loss: 0.0095 - mean_absolute_error: 0.0692\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 374us/sample - loss: 0.0052 - mean_absolute_error: 0.0485\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0077 - mean_absolute_error: 0.0521\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0078 - mean_absolute_error: 0.0562\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0042 - mean_absolute_error: 0.0415\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0019 - mean_absolute_error: 0.0295\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 0.0016 - mean_absolute_error: 0.0256\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0024 - mean_absolute_error: 0.0280\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 356us/sample - loss: 0.0027 - mean_absolute_error: 0.0270\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0018 - mean_absolute_error: 0.0227\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0014 - mean_absolute_error: 0.0178\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 6.7997e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0023 - mean_absolute_error: 0.0240\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0017 - mean_absolute_error: 0.0294\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 402us/sample - loss: 0.0020 - mean_absolute_error: 0.0268\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 358us/sample - loss: 0.0012 - mean_absolute_error: 0.0233\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 374us/sample - loss: 0.0012 - mean_absolute_error: 0.0230\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0013 - mean_absolute_error: 0.0241\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 371us/sample - loss: 0.0014 - mean_absolute_error: 0.0231\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0014 - mean_absolute_error: 0.0231\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 9.3234e-04 - mean_absolute_error: 0.0199\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 337us/sample - loss: 0.0011 - mean_absolute_error: 0.0201\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 5.3780e-04 - mean_absolute_error: 0.0171\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 5.3088e-04 - mean_absolute_error: 0.0142\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 4.2663e-04 - mean_absolute_error: 0.0149\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 5.7680e-04 - mean_absolute_error: 0.0164\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 7.3262e-04 - mean_absolute_error: 0.0194\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 6.3021e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 0s 366us/sample - loss: 6.8231e-04 - mean_absolute_error: 0.0168\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 356us/sample - loss: 4.8528e-04 - mean_absolute_error: 0.0144\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 4.8592e-04 - mean_absolute_error: 0.0136\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0013 - mean_absolute_error: 0.0162\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 8.4525e-04 - mean_absolute_error: 0.0178\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0014 - mean_absolute_error: 0.0227\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 0.0012 - mean_absolute_error: 0.0248\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0020 - mean_absolute_error: 0.0310\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 0.0019 - mean_absolute_error: 0.0313\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.0022 - mean_absolute_error: 0.0301\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 0.0019 - mean_absolute_error: 0.0310\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 335us/sample - loss: 0.0019 - mean_absolute_error: 0.0320\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 365us/sample - loss: 0.0022 - mean_absolute_error: 0.0349\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0045 - mean_absolute_error: 0.0474\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0081 - mean_absolute_error: 0.0649\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0153 - mean_absolute_error: 0.0827\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 355us/sample - loss: 0.0217 - mean_absolute_error: 0.1071\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0276 - mean_absolute_error: 0.1228\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0279 - mean_absolute_error: 0.1377\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0250 - mean_absolute_error: 0.1211\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 0.0190 - mean_absolute_error: 0.1015\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0191 - mean_absolute_error: 0.0896\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.0188 - mean_absolute_error: 0.0818\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 0.0142 - mean_absolute_error: 0.0787\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 0.0276 - mean_absolute_error: 0.0785\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 368us/sample - loss: 0.0108 - mean_absolute_error: 0.0663\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 371us/sample - loss: 0.0124 - mean_absolute_error: 0.0651\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0148 - mean_absolute_error: 0.0645\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0216 - mean_absolute_error: 0.0867\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 335us/sample - loss: 0.0800 - mean_absolute_error: 0.0982\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0475 - mean_absolute_error: 0.0765\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 0.0212 - mean_absolute_error: 0.0796\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 0.0290 - mean_absolute_error: 0.0836\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0206 - mean_absolute_error: 0.0788\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0124 - mean_absolute_error: 0.0769\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 351us/sample - loss: 0.0142 - mean_absolute_error: 0.0798\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0097 - mean_absolute_error: 0.0694\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 0.0109 - mean_absolute_error: 0.0610\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 356us/sample - loss: 0.0059 - mean_absolute_error: 0.0511\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0155 - mean_absolute_error: 0.0515\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 365us/sample - loss: 0.0109 - mean_absolute_error: 0.0620\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 338us/sample - loss: 0.0223 - mean_absolute_error: 0.0715\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0154 - mean_absolute_error: 0.0674\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.0077 - mean_absolute_error: 0.0516\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0079 - mean_absolute_error: 0.0543\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0066 - mean_absolute_error: 0.0511\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0029 - mean_absolute_error: 0.0330\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 0.0067 - mean_absolute_error: 0.0386\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0035 - mean_absolute_error: 0.0304\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.0041 - mean_absolute_error: 0.0310\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0040 - mean_absolute_error: 0.0294\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0049 - mean_absolute_error: 0.0415\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0057 - mean_absolute_error: 0.0344\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 0.0073 - mean_absolute_error: 0.0377\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 353us/sample - loss: 0.0027 - mean_absolute_error: 0.0284\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0021 - mean_absolute_error: 0.0266\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0015 - mean_absolute_error: 0.0230\n",
      "110/110 [==============================] - 0s 523us/sample - loss: 1.6555 - mean_absolute_error: 0.7803\n",
      "220/220 [==============================] - 0s 144us/sample - loss: 6.3882e-04 - mean_absolute_error: 0.0163\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_470 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_471 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_472 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_473 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_474 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "220/220 [==============================] - 0s 925us/sample - loss: 1.7496 - mean_absolute_error: 0.9392\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 0s 334us/sample - loss: 0.8768 - mean_absolute_error: 0.6277\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 0s 331us/sample - loss: 0.4702 - mean_absolute_error: 0.5218\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 0s 334us/sample - loss: 0.3818 - mean_absolute_error: 0.4790\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 0s 329us/sample - loss: 0.3217 - mean_absolute_error: 0.4364\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 0s 335us/sample - loss: 0.3786 - mean_absolute_error: 0.4592\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 0.4306 - mean_absolute_error: 0.5582\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 0.3951 - mean_absolute_error: 0.3973\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 0.1643 - mean_absolute_error: 0.2882\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 0.3293 - mean_absolute_error: 0.2957\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 0s 334us/sample - loss: 0.1637 - mean_absolute_error: 0.1900\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 0.0489 - mean_absolute_error: 0.1471\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 0s 336us/sample - loss: 0.0572 - mean_absolute_error: 0.1265\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 0s 337us/sample - loss: 0.0209 - mean_absolute_error: 0.0913\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 0s 333us/sample - loss: 0.0213 - mean_absolute_error: 0.0889\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 0s 364us/sample - loss: 0.0185 - mean_absolute_error: 0.0844\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 0.0126 - mean_absolute_error: 0.0698\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 0.0092 - mean_absolute_error: 0.0495\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 0.0052 - mean_absolute_error: 0.0532\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 0s 326us/sample - loss: 0.0039 - mean_absolute_error: 0.0484\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 0.0017 - mean_absolute_error: 0.0302\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 0s 333us/sample - loss: 0.0044 - mean_absolute_error: 0.0418\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 0s 336us/sample - loss: 0.0035 - mean_absolute_error: 0.0409\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 0.0039 - mean_absolute_error: 0.0325\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 0.0017 - mean_absolute_error: 0.0289\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0023 - mean_absolute_error: 0.0301\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 7.6689e-04 - mean_absolute_error: 0.0174\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 0.0024 - mean_absolute_error: 0.0196\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 5.8468e-04 - mean_absolute_error: 0.0137\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 0s 336us/sample - loss: 6.5370e-04 - mean_absolute_error: 0.0139\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 5.0193e-04 - mean_absolute_error: 0.0115\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 4.3129e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 4.0363e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0029 - mean_absolute_error: 0.0156\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 0s 350us/sample - loss: 5.2650e-04 - mean_absolute_error: 0.0112\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 0.0021 - mean_absolute_error: 0.0157\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 0s 348us/sample - loss: 7.9849e-04 - mean_absolute_error: 0.0121\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 0.0015 - mean_absolute_error: 0.0156\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 2.1961e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 2.9113e-04 - mean_absolute_error: 0.0097\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 2.9430e-04 - mean_absolute_error: 0.0091\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 3.5768e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 5.4195e-04 - mean_absolute_error: 0.0072\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 0s 342us/sample - loss: 2.0564e-04 - mean_absolute_error: 0.0065\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 0s 346us/sample - loss: 1.5326e-04 - mean_absolute_error: 0.0065\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 0s 336us/sample - loss: 8.9838e-05 - mean_absolute_error: 0.0049\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 7.4461e-05 - mean_absolute_error: 0.0048\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 1.0400e-04 - mean_absolute_error: 0.0047\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 3.3536e-05 - mean_absolute_error: 0.0035\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 6.9300e-05 - mean_absolute_error: 0.0040\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 3.0694e-05 - mean_absolute_error: 0.0034\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 2.6092e-05 - mean_absolute_error: 0.0033\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 3.2417e-05 - mean_absolute_error: 0.0035\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 2.2011e-05 - mean_absolute_error: 0.0027\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 2.2601e-05 - mean_absolute_error: 0.0028\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 3.1232e-05 - mean_absolute_error: 0.0032\n",
      "Epoch 57/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 3.0475e-05 - mean_absolute_error: 0.0032\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 0s 335us/sample - loss: 1.6731e-05 - mean_absolute_error: 0.0026\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 0s 337us/sample - loss: 2.6360e-05 - mean_absolute_error: 0.0032\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 0s 333us/sample - loss: 2.2462e-05 - mean_absolute_error: 0.0028\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 2.5686e-05 - mean_absolute_error: 0.0029\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 0s 337us/sample - loss: 8.1547e-05 - mean_absolute_error: 0.0034\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 3.6564e-05 - mean_absolute_error: 0.0030\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 1.2862e-04 - mean_absolute_error: 0.0036\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 3.5417e-05 - mean_absolute_error: 0.0031\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 2.3427e-05 - mean_absolute_error: 0.0028\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 2.3904e-05 - mean_absolute_error: 0.0028\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 0s 332us/sample - loss: 9.1649e-06 - mean_absolute_error: 0.0021\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 4.8632e-05 - mean_absolute_error: 0.0027\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 3.2152e-05 - mean_absolute_error: 0.0033\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 4.9757e-05 - mean_absolute_error: 0.0030\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 3.1959e-05 - mean_absolute_error: 0.0031\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 3.0931e-05 - mean_absolute_error: 0.0030\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 0s 345us/sample - loss: 2.5107e-05 - mean_absolute_error: 0.0026\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 0s 342us/sample - loss: 2.5819e-05 - mean_absolute_error: 0.0026\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 2.1280e-05 - mean_absolute_error: 0.0028\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 0s 343us/sample - loss: 2.8955e-05 - mean_absolute_error: 0.0031\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 0s 336us/sample - loss: 2.2037e-05 - mean_absolute_error: 0.0026\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 2.3583e-05 - mean_absolute_error: 0.0026\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 2.7304e-05 - mean_absolute_error: 0.0030\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 0s 335us/sample - loss: 4.0615e-05 - mean_absolute_error: 0.0035\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 0s 352us/sample - loss: 1.9732e-05 - mean_absolute_error: 0.0026\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 0s 338us/sample - loss: 7.6893e-05 - mean_absolute_error: 0.0036\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 1.3097e-04 - mean_absolute_error: 0.0042\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 0s 344us/sample - loss: 3.3266e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 6.2530e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 0s 336us/sample - loss: 0.0068 - mean_absolute_error: 0.0169\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 0.0023 - mean_absolute_error: 0.0241\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 0s 340us/sample - loss: 0.0059 - mean_absolute_error: 0.0433\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 0s 336us/sample - loss: 0.0087 - mean_absolute_error: 0.0633\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0067 - mean_absolute_error: 0.0617\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 0s 341us/sample - loss: 0.0239 - mean_absolute_error: 0.0576\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0098 - mean_absolute_error: 0.0629\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 0s 347us/sample - loss: 0.0107 - mean_absolute_error: 0.0765\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 0s 361us/sample - loss: 0.0148 - mean_absolute_error: 0.0824\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 0s 349us/sample - loss: 0.0143 - mean_absolute_error: 0.0782\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 0s 337us/sample - loss: 0.0225 - mean_absolute_error: 0.0885\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 0.0590 - mean_absolute_error: 0.1119\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 0s 327us/sample - loss: 0.0220 - mean_absolute_error: 0.1228\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 0s 339us/sample - loss: 0.0447 - mean_absolute_error: 0.1316\n",
      "110/110 [==============================] - 0s 539us/sample - loss: 0.5849 - mean_absolute_error: 0.5449\n",
      "220/220 [==============================] - 0s 157us/sample - loss: 0.0172 - mean_absolute_error: 0.0726\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_475 (Dense)            (None, 128)               2190336   \n",
      "_________________________________________________________________\n",
      "dense_476 (Dense)            (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_477 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_478 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_479 (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,355,201\n",
      "Trainable params: 2,355,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "330/330 [==============================] - 0s 1ms/sample - loss: 1.2375 - mean_absolute_error: 0.7700\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/330 [==============================] - 0s 651us/sample - loss: 0.8018 - mean_absolute_error: 0.6156\n",
      "Epoch 3/10\n",
      "330/330 [==============================] - 0s 628us/sample - loss: 0.5761 - mean_absolute_error: 0.5217\n",
      "Epoch 4/10\n",
      "330/330 [==============================] - 0s 622us/sample - loss: 0.5949 - mean_absolute_error: 0.4774\n",
      "Epoch 5/10\n",
      "330/330 [==============================] - 0s 631us/sample - loss: 0.2406 - mean_absolute_error: 0.3435\n",
      "Epoch 6/10\n",
      "330/330 [==============================] - 0s 622us/sample - loss: 0.1970 - mean_absolute_error: 0.3136\n",
      "Epoch 7/10\n",
      "330/330 [==============================] - 0s 630us/sample - loss: 0.1680 - mean_absolute_error: 0.2643\n",
      "Epoch 8/10\n",
      "330/330 [==============================] - 0s 637us/sample - loss: 0.1433 - mean_absolute_error: 0.2108\n",
      "Epoch 9/10\n",
      "330/330 [==============================] - 0s 626us/sample - loss: 0.1247 - mean_absolute_error: 0.1854\n",
      "Epoch 10/10\n",
      "330/330 [==============================] - 0s 623us/sample - loss: 0.0815 - mean_absolute_error: 0.1536\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -1.050404 using {'batch_size': 20, 'epochs': 10}\n",
      "-1.241700 (0.328443) with: {'batch_size': 5, 'epochs': 10}\n",
      "-1.110920 (0.297094) with: {'batch_size': 5, 'epochs': 30}\n",
      "-1.321543 (0.484619) with: {'batch_size': 5, 'epochs': 50}\n",
      "-1.130270 (0.308333) with: {'batch_size': 5, 'epochs': 100}\n",
      "-1.074981 (0.408385) with: {'batch_size': 10, 'epochs': 10}\n",
      "-1.074549 (0.393052) with: {'batch_size': 10, 'epochs': 30}\n",
      "-1.063173 (0.339616) with: {'batch_size': 10, 'epochs': 50}\n",
      "-1.097214 (0.355023) with: {'batch_size': 10, 'epochs': 100}\n",
      "-1.068698 (0.405135) with: {'batch_size': 15, 'epochs': 10}\n",
      "-1.058400 (0.420550) with: {'batch_size': 15, 'epochs': 30}\n",
      "-1.126886 (0.365642) with: {'batch_size': 15, 'epochs': 50}\n",
      "-1.161477 (0.359158) with: {'batch_size': 15, 'epochs': 100}\n",
      "-1.050404 (0.437890) with: {'batch_size': 20, 'epochs': 10}\n",
      "-1.121483 (0.368356) with: {'batch_size': 20, 'epochs': 30}\n",
      "-1.108895 (0.411464) with: {'batch_size': 20, 'epochs': 50}\n",
      "-1.097228 (0.359724) with: {'batch_size': 20, 'epochs': 100}\n",
      "-1.107699 (0.370060) with: {'batch_size': 25, 'epochs': 10}\n",
      "-1.123585 (0.345881) with: {'batch_size': 25, 'epochs': 30}\n",
      "-1.103733 (0.361089) with: {'batch_size': 25, 'epochs': 50}\n",
      "-1.163007 (0.348041) with: {'batch_size': 25, 'epochs': 100}\n",
      "-1.127723 (0.328450) with: {'batch_size': 30, 'epochs': 10}\n",
      "-1.142190 (0.388325) with: {'batch_size': 30, 'epochs': 30}\n",
      "-1.084582 (0.358650) with: {'batch_size': 30, 'epochs': 50}\n",
      "-1.081755 (0.381764) with: {'batch_size': 30, 'epochs': 100}\n",
      "-1.191167 (0.336596) with: {'batch_size': 50, 'epochs': 10}\n",
      "-1.089476 (0.361833) with: {'batch_size': 50, 'epochs': 30}\n",
      "-1.145933 (0.386627) with: {'batch_size': 50, 'epochs': 50}\n",
      "-1.083723 (0.440100) with: {'batch_size': 50, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = KerasRegressor(build_fn=baseline_model, batch_size=20, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "330/330 [==============================] - 0s 966us/sample - loss: 1.4463 - mean_absolute_error: 0.8397\n",
      "Epoch 2/10\n",
      "330/330 [==============================] - 0s 593us/sample - loss: 0.8581 - mean_absolute_error: 0.6476\n",
      "Epoch 3/10\n",
      "330/330 [==============================] - 0s 611us/sample - loss: 0.5511 - mean_absolute_error: 0.5147\n",
      "Epoch 4/10\n",
      "330/330 [==============================] - 0s 599us/sample - loss: 0.6008 - mean_absolute_error: 0.4463\n",
      "Epoch 5/10\n",
      "330/330 [==============================] - 0s 600us/sample - loss: 0.2924 - mean_absolute_error: 0.3811\n",
      "Epoch 6/10\n",
      "330/330 [==============================] - 0s 602us/sample - loss: 0.3572 - mean_absolute_error: 0.3621\n",
      "Epoch 7/10\n",
      "330/330 [==============================] - 0s 595us/sample - loss: 0.1940 - mean_absolute_error: 0.2943\n",
      "Epoch 8/10\n",
      "330/330 [==============================] - 0s 602us/sample - loss: 0.2979 - mean_absolute_error: 0.2641\n",
      "Epoch 9/10\n",
      "330/330 [==============================] - 0s 622us/sample - loss: 0.1423 - mean_absolute_error: 0.2468\n",
      "Epoch 10/10\n",
      "330/330 [==============================] - 0s 599us/sample - loss: 0.2271 - mean_absolute_error: 0.2445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ab84c87b8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 429us/sample\n"
     ]
    }
   ],
   "source": [
    "y_predval = newmodel.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11243512839995.229\n",
      "2.2487945520899596e+27\n",
      "47421456663518.46\n",
      "R2 Score\n",
      "-3.227945152544792e+27\n"
     ]
    }
   ],
   "source": [
    "# Print result of MAE\n",
    "from sklearn import metrics\n",
    "print(metrics.mean_absolute_error(y_val, y_predval))\n",
    "\n",
    "# Print result of MSE\n",
    "print(metrics.mean_squared_error(y_val, y_predval))\n",
    "\n",
    "# Print result of RMSE\n",
    "print(np.sqrt(metrics.mean_squared_error(y_val, y_predval)))\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "accuracy=r2_score(y_val,y_predval)\n",
    "\n",
    "print('R2 Score')\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 = -3227945152544792057185566720.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the Decision Tree Regression Results\n",
    "# Loading Packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "from scipy.integrate import simps\n",
    "\n",
    "# Function for Regression Error Characteritic Curve\n",
    "\n",
    "def REC(y_val , y_predval):\n",
    "    \n",
    "    # initilizing the lists\n",
    "    Accuracy = []\n",
    "    \n",
    "    # initializing the values for Epsilon\n",
    "    Begin_Range = 0\n",
    "    End_Range = 1.5\n",
    "    Interval_Size = 0.01\n",
    "    \n",
    "    # List of epsilons\n",
    "    Epsilon = np.arange(Begin_Range , End_Range , Interval_Size)\n",
    "    \n",
    "    # Main Loops\n",
    "    for i in range(len(Epsilon)):\n",
    "        count = 0.0\n",
    "        for j in range(len(y_val)):\n",
    "            if np.linalg.norm(y_val[j] - y_predval[j]) / np.sqrt( np.linalg.norm(y_val[j]) **2 + np.linalg.norm(y_predval[j])**2 ) < Epsilon[i]:\n",
    "                count = count + 1\n",
    "        \n",
    "        Accuracy.append(count/len(y_val))\n",
    "    \n",
    "    # Calculating Area Under Curve using Simpson's rule\n",
    "    AUC = simps(Accuracy , Epsilon ) / End_Range\n",
    "        \n",
    "    # returning epsilon , accuracy , area under curve    \n",
    "    return Epsilon , Accuracy , AUC\n",
    "\n",
    "# finding the deviation and accuracy, and area under curve for plotting\n",
    "Deviation, Accuracy, AUC = REC(y_val, y_predval)\n",
    "\n",
    "# Calculating R^2 of the true and predicted values\n",
    "RR = r2_score(y_val, y_predval)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(20 , 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_val, y_predval,color = \"darkorange\")\n",
    "plt.xlabel(\"Real Data\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.figure(figsize=(20 , 10))\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'k--', lw=4)\n",
    "print(\"R^2 = %0.4f\" %RR)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Regression Error Characteristic (REC)\")\n",
    "plt.plot(Deviation, Accuracy, \"--b\",lw =3)\n",
    "plt.xlabel(\"Deviation\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.text(1.1, 0.07, \"AUC = %0.4f\" %AUC , fontsize=15)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
